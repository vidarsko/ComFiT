--- Start of file: docs\ClassBaseSystem.md ---
# Class: Base system

This class simply initiates a system, defines the grid and contains the basic functionality for evolving in time.

See the ComFiT Library Reference below for a complete list of class methods and their usage.

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
    <a href="https://comfitlib.com/library_reference/core/" class="card" style="min-width: 160px; flex: 0 1 calc(100.00% - 10px); margin: 5px;">
        <div style="text-align: center;">
            <strong> ComFiT Library Reference </strong>
        </div>
    </a>
</div>

## Types of functions

There are five different types of functions:

1. `conf_`-functions: Configures the state of the system, for instance by setting an initial condition. Output nothing.
2. `evolve_`-functions: Evolves the state in time according to some equation of motion.
3. `calc_`-functions: Calculates something from the state, returns that which has been calculated.
4. `plot_`-functions: Functions tailored to plot specific things. Output the axes and figure.
5. `get_`-functions: Functions that return a component of a tensor field. Relevant for symmetric and antisymmetric tensors where it is not convenient to save all elements.

## General keywords and parameters

The only required input argument to the BaseSystem class is the `dim` argument, which specifies the dimension of the system.
In some cases, default values of other parameter depend on the value of `dim`, and are represented by curly brackets:

$$
\left \lbrace \begin{array}{l} \textrm{default value if } \texttt{dim }= 1 \\ \textrm{default value if } \texttt{dim }= 2  \\ \textrm{default value if } \texttt{dim }= 3  \\ \end{array} \right \rbrace
$$

These are the optional keywords for the `BaseSystem` class.

| Keyword | Definition | Default value|
|---------|------------|--------------|
| `xmin`  | Minimum value of $x$ of the simulation domain | $0$ |
| `ymin`  | Minimum value of $y$ of the simulation domain | $0$ |
| `zmin`  | Minimum value of $z$ of the simulation domain | $0$ |
| `xmax`  | Maximum value of $x$ of the simulation domain. | $100$ |
| `ymax`  | Maximum value of $y$ of the simulation domain | $\left \lbrace \begin{array}{c} 1 \\ 100 \\ 100 \\ \end{array} \right \rbrace$ |
| `zmax`  | Maximum value of $z$ of the simulation domain | $\left \lbrace \begin{array}{c} 1 \\ 1 \\  100 \\ \end{array} \right \rbrace$ |
| `xRes`  | Resolution of the $x$ axis | $101$ |
| `yRes`  | Resolution of the $y$ axis | $\left \lbrace \begin{array}{c} 1 \\ 101 \\  101 \\ \end{array} \right \rbrace$ |
| `zRes`  | Resolution of the $z$ axis | $\left \lbrace \begin{array}{c} 1 \\ 1 \\  101 \\ \end{array} \right \rbrace$ |
| `dx`    | Spacing between points on the $x$-axis. Trumps `xRes` if provided. `xmax` will be modified to match. | $\frac{\texttt{xmax}-\texttt{xmin}}{\texttt{xRes}} = 1$ |
| `dy`    | Spacing between points on the $y$-axis. Trumps `yRes` if provided. | $\frac{\texttt{ymax}-\texttt{ymin}}{\texttt{yRes}} = 1$ |
| `dz`    | Spacing between points on the $x$-axis. Trumps `zRes` if provided. | $\frac{\texttt{zmax}-\texttt{zmin}}{\texttt{zRes}} = 1$ |
| `xlim`  | List or tuple consisting of the lower and upper limit for the simulation domain in the $x$-direction. Trumps `xmin` and `xmax` if provided. | $(\texttt{xmin},\texttt{xmax}) = (0,101)$ |
| `ylim`  | List or tuple consisting of the lower and upper limit for the simulation domain in the $y$-direction. Trumps `ymin` and `ymax` if provided. | $(\texttt{ymin},\texttt{ymax}) = \left \lbrace \begin{array}{c} (0,1) \\ (0,101) \\  (0,101) \\ \end{array} \right \rbrace$|
| `zlim`  | List or tuple consisting of the lower and upper limit for the simulation domain in the $z$-direction. Trumps `zmin` and `zmax` if provided. | $(\texttt{xmin},\texttt{xmax}) = \left \lbrace \begin{array}{c} (0,1) \\ (0,1) \\  (0,101) \\ \end{array} \right \rbrace$|
| `time` | Float specifying the time of initialization | $0$ |
| `a0` | Characteristic length scale associated with the system, in units of which all plots will be scaled. This is also the default width used with the coarse-graining operation. | $1$ |
| `X` | 2D numpy array with position coordinates. Typically used when the coordinates are not a regular grid. | `None` |
| `Y` | 2D numpy array with position coordinates. Typically used when the coordinates are not a regular grid. | `None` |
| `Z` | 2D numpy array with position coordinates. Typically used when the coordinates are not a regular grid. | `None` |

From these keywords, a number of useful parameters are constructed, given in the table below.

| Parameter      | Definition   | Value |
| -------------- | --------------| ----- |
| `x`            | Numpy array with dimensions $\left \lbrace \begin{array}{l} \texttt{xRes} \\ \texttt{xRes}\times 1  \\ \texttt{xRes}\times 1 \times 1  \\ \end{array} \right \rbrace$ consisting of the grid points from `xmin` to (including) `xmax-dx`. |
| `y`            | Numpy array with dimensions $\left \lbrace \begin{array}{l} 1 \\ 1 \times \texttt{yRes}  \\ 1 \times \texttt{yRes} \times 1  \\ \end{array} \right \rbrace$ consisting of the grid points from `ymin` to (including) `ymax-dy`. |
| `z`            | Numpy array with dimensions $\left \lbrace \begin{array}{l} 1 \\ 1  \\ 1 \times 1 \times \texttt{zRes} \\ \end{array} \right \rbrace$ consisting of the grid points from `zmin` to (including) `zmax-dz`. |
| `xmidi`        | Index of the mid $x$-value. In the case of an odd `xRes`, this midpoint index will not hit the middle exactly but undershoot by `dx/2`. |
| `xmid`         | The $x$ value given by `xmidi`. |
| `ymidi`        | Index of the mid $y$-value. In the case of an odd `yRes`, this midpoint index will not hit the middle exactly but undershoot by `dy/2`. |
| `ymid`         | The $y$ value given by `ymidi`. |
| `zmidi`        | Index of the mid $z$-value. In the case of an odd `zRes`, this midpoint index will not hit the middle exactly but undershoot by `dz/2`. |
| `zmid`         | The $z$ value given by `zmidi`. |
| `size_x` | Size of the $x$-axis | $\texttt{xmax} - \texttt{xmin}$ |
| `size_y` | Size of the $y$-axis |  $\texttt{ymax} - \texttt{ymin}$ (1 if `dim` $<2$) |
| `size_z` | Size of the $z$-axis |  $\texttt{zmax} - \texttt{zmin}$ (1 if `dim` $<3$)|
| `size_min` | Minimum value of the simulation domain | $\left \lbrace \begin{array}{c} \texttt{size_x} \\ \texttt{min}(\texttt{size_x}, \texttt{size_y})\\ \texttt{min}(\texttt{size_x}, \texttt{size_y}, \texttt{size_z}) \\ \end{array} \right \rbrace$ |
| `size_max` | Maximum value of the simulation domain | $\left \lbrace \begin{array}{c} \texttt{size_x} \\ \texttt{max}(\texttt{size_x}, \texttt{size_y})\\ \texttt{max}(\texttt{size_x}, \texttt{size_y}, \texttt{size_z}) \\ \end{array} \right \rbrace$ |
| `dV`          | Volume element of the grid. | $\left \lbrace \begin{array}{l} \texttt{dx} \\ \texttt{dx} \times \texttt{dy}  \\ \texttt{dx} \times \texttt{dy} \times \texttt{dz}  \\ \end{array} \right \rbrace$.|
| `volume` | Volume of the simulation domain | $\texttt{size_x} \times \texttt{size_y} \times \texttt{size_z}$ |

Note that even though variables like `yRes`, `zRes` etc. are defined in cases where they are not relevant, such as for a $1$-dimensional system, they play no significant role in any calculations in such situations.

![](img/base_system_x_axis_illustration.png#only-light)
![](img/base_system_x_axis_illustration-colorinverted.png#only-dark)


Periodic boundary conditions means that `xmax` and `xmin` are identified as the same point. 

## Fourier transformations

ComFiT is based on so-called spectral methods, which means using Fourier transformations to solve differential equations. 
There are some subtleties to how the Fourier transformations work, which we will explain here.
If you prefer a video explanation, you can watch the following video.

<iframe width="560" height="315" src="https://www.youtube.com/embed/E_s9DN4ZUWA?si=ae0lGyXJLOaloLQn" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### Infinite system

For an infinite system, the Fourier transformation of a function $g(\mathbf{r})$ is given by

!!! equation "The Fourier transform"
    $$
    g_{\mathfrak f}(\mathbf{k}) = \mathcal F[g] = \frac{1}{(2 \pi)^d} \int d^d r e^{-\mathfrak i \mathbf{k}\cdot \mathbf{r}} g(\mathbf{r}),
    $$

and the inverse Fourier transformation is given by

!!! equation "The inverse Fourier transform"
    $$
    g(\mathbf{r}) = \mathcal  F^{-1}[g_\mathfrak f] = \int d^d k e^{\mathfrak i \mathbf{k}\cdot \mathbf{r}} g_{\mathfrak f}(\mathbf{k}).
    $$

The factor $\frac{1}{(2\pi)^d}$ in the definition of $g_{\mathfrak f}$ is a convention.
It is useful when thinking of $g_{\mathfrak f}(\mathbf k)$  as the *weight* of the corresponding different Fourier components.
If $g(\mathbf r)$ is a real function, then $g_{\mathfrak f}(-\mathbf k) = g_{\mathfrak f}^*(\mathbf k)$.
Thus, in principle, to calculate a derivative of a function, one can take the Fourier transformation, multiply by $\mathfrak i \mathbf k$, and then take the inverse Fourier transformation.

$$
\frac{\partial }{\partial x} g(\mathbf r) = \mathcal F^{-1}[\mathfrak i k_x \mathcal F[g]],
$$

which is why we can calculate derivatives of a field `g` in ComFiT using

!!! equation "Numerical derivative"
    ```python
    dxg = bs.ifft(1j*bs.k[0]*bs.fft(g))
    ```

where `1j` is how to write the imaginary unit in Python.
In fact, the combination `1j*bs.k[0]` is used so often that it is saved in its own property `bs.dif[0]`, so it is more common to see the derivative calculated as

```python
dxg = bs.ifft(bs.dif[0]*bs.fft(g))
```

In reality, however, we are working with a periodic grid, which means that the Fourier transformation is not exactly the same as the one defined above.
We will cover this next.

### Periodic grid

In this section, we will show why we can calculate a numerical derivative as given above.
In one dimension, on a periodic grid, a function is defined on a grid with $N$ points, where it is assumed that the $N+1$th point (`x_n`) would be the same as the first point (`x_0`).

$$
g_n = g(x_n) \quad \texttt{on} \quad x_0, x_1,..., x_{N-1}
$$

Numerically, the Discrete Fourier transformation as

$$
g_{\mathfrak f m} = \sum_{n=0}^{N-1} g(x_n) \exp\left (-\mathfrak i \frac{2\pi m n}{N}\right )
$$

and the inverse discrete Fourier transformation is given by

$$
g(x_n) = \frac{1}{N} \sum_{m=0}^{N-1} g_{\mathfrak f m} \exp \left (\mathfrak i \frac{2\pi m n}{N} \right ).
$$

!!! note "Difference between $g_{\mathcal f}$ and $g_{\mathcal f m}$"
    The Fourier transform $g_{\mathfrak f}$ is a function of the wavenumber $\mathbf k$, while $g_{\mathfrak f m}$ is a function of the index $m$.

$n$ is related to the values $x_n$ by

$$
x_n = x_0 + n\Delta x
$$

so

$$
n = \frac{x_n-x_0}{\Delta x}.
$$

Inserting this into the Fourier transform, we get

$$
g_{\mathfrak f m} = \sum_{n=0}^{N-1} g(x_n) \exp\left (-\mathfrak i \frac{2\pi m }{N} \frac{x_n-x_0}{\Delta x}\right )
$$

Now, we define

$$
k_m = \frac{2\pi m}{N \Delta x} \quad \texttt{where} \quad m=0,1,...,N-1,
$$

i.e,

$$
k_m = 0, \frac{2 \pi}{N\Delta x}, \frac{4 \pi}{N\Delta x}, ... , \frac{(N-1) 2 \pi}{N\Delta x}.
$$

So we see that $g_{\mathfrak f k}$ can be thought of as a function $g_{\mathfrak f}$, the Fourier transform of $g$ evaluated at the points $k_n$

!!! equation "The discrete Fourier transformation"
    $$
    g_{\mathfrak f m} = g(k_m) = \sum_{n=0}^{N-1} g(x_n) \exp\left (-\mathfrak i k_m (x_n-x_0)\right )
    $$

So we can write the inverse Fourier transform as

!!! equation "The inverse discrete Fourier transformation"
    $$
    g(x_n) = \frac{1}{N} \sum_{m=0}^{N-1} g_{\mathfrak f m} \exp \left (\mathfrak i k_m (x_n-x_0) \right )
    $$

From this expression, we see that if we multiply $g_{\mathfrak f m}$ with $\mathfrak i k_m$, we get

$$
\frac{1}{N} \sum_{m=0}^{N-1} \mathfrak i k_m g_{\mathfrak f m} \exp \left (\mathfrak i k_m (x_n-x_0) \right )
= (\partial_x g)(x_n)
$$

which justifies the numerical derivative given in the previous section.

### The Nyquist frequency

The function `calc_wavenums` calculates the wavenumbers corresponding to the input position vectors given by `x`.

```python
# In ComFiT 1.8.7
def calc_wavenums(
            self, 
            x: np.ndarray
            ) -> np.ndarray:
        """Calculates the wavenumbers corresponding to the input position vectors given by x.

        Parameters
        ----------
        x : numpy.ndarray
            1D array of x-positions.

        Returns
        -------
        numpy.ndarray
            1D array of wavenumbers with all the modes for the given x-array,
            assuming periodicity from x[0] to x[0] over n intervals.

        Examples
        --------
        >>> x = np.array([-10, -5, 0, 5, 10])
        >>> k = instance_of_BaseSystem.calc_wavenums(self, x)
        >>> print(k)
        [ 0.          0.25132741  0.50265482 -0.50265482 -0.25132741]
        """
        n = len(x)

        high = (n - 1) // 2
        low = - (n // 2)

        l = n * (x[1] - x[0])

        k = np.concatenate((np.arange(0, high + 1), np.arange(low, 0))) * 2 * np.pi / l

        return k
```

However, there is a slight difference between the wavenumbers calculated here and $k_m$ in the previous section.
The wavenumbers are the same up to $k_{N/2}$ (which correspond to the so-called Nyquist frequency), but then the wavenumbers are negative, the reason for this is that for a function defined on a grid with $N$ points, the highest wavenumber that can be resolved is $k_{N/2}$, and wavenumbers $k_m$ above are effective the same as negative wavenumbers.
We will explain this next.

The Nyquist frequency is given by

$$
f_{NQ} = \frac{1}{2\Delta x},
$$

which corresponds to the wavenumber

$$
k_{NQ} = 2\pi f_{NQ} = \frac{\pi}{\Delta x}
$$

The value of $m$ corresponding to this frequency is

$$
\frac{2\pi m}{N\Delta x} = \frac{\pi}{\Delta x}
$$

$$
m = \frac{N}{ 2 }
$$

Insert $- k_m$, where $k_m< k_{NQ}$ into the Fourier transform, we get

$$
g_{\mathfrak f (-m)} = g(-k_m) = \sum_{n=0}^{N-1} g(x_n) \exp\left (-\mathfrak i (-k_m) (x_n-x_0)\right )
$$

$$
 =  \sum_{n=0}^{N-1} g(x_n) \exp\left (-\mathfrak i (2k_{NQ} -k_m) (x_n-x_0)\right ),
$$

where we have used that

$$
\exp(-\mathfrak i 2 k_{NQ} (x_n-x_0)) = \exp(-\mathfrak i 2 \frac{\pi}{\Delta x} (x_n-x_0)) = 1.
$$

This shows that finding the Fourier spectrum above the Nyquist frequency corresponds to finding the amplitude to negative wavenumbers.
So, in the `calc_wavenum`  function, we set the first $N/2$ k-values to  $[ k_m ]_{m=1}^{N/2} = [0,..., N/2] \cdot \frac{2\pi}{N \Delta x}$ and  then the following wavenumbers to $[k_m]_{N/2}^{N} = [-N/2,...,-1]\cdot \frac{2\pi}{N \Delta x}$

### Plotting a Fourier field

From a numerical point of view, in calculating derivatives, we can use the discrete Fourier transformations directly, as outline above.
For physical applications, however, the Fourier transformation defined on an infinite domain is more useful.
In plotting the Fourier fields (passing the `fourier=True` parameter to the relevant plot function), therefore, we slightly modify `g_f`.
We will detail this next.

We can write the inverse discrete Fourier transformation as follows

$$
g(x_n) =  \sum_{m=0}^{N-1} \left ( g_{\mathfrak f m} \frac{1}{N \Delta k} e^{-\mathfrak i k_m x_0} \right ) \exp \left (\mathfrak i k_m x_n \right ) \Delta k,
$$

The sum is a numerical approximation of the infinite inverse Fourier transform of $g_{\mathfrak f}(\mathbf k)$, if we make the connection

!!! equation "Connection between the discrete and infinite Fourier transformation"
    $$
    g_{\mathfrak f}(\mathbf k) \approx g_{\mathfrak f m} \frac{1}{N \Delta k} e^{-\mathfrak i k_m x_0}.
    $$

This is why, when passing the `fourier=True` parameter to the plot functions, the field is modified in the `_check_if_fourier_and_adjust` function in `base_system_plot` according by

```python
# In ComFiT 1.9.0
dkx = self.k[0][1]-self.k[0][0]
phase_shift = 1/(self.xRes*dkx)*np.exp(1j*self.k[0]*self.xmin)
if self.dim > 1:
    dky = self.k[1][0,1]-self.k[1][0,0]
    phase_shift = phase_shift*1/(self.yRes*dky)*np.exp(1j*self.k[1]*self.ymin)
if self.dim > 2:
    dkz = self.k[2][0,0,1]-self.k[2][0,0,0]
    phase_shift = phase_shift*1/(self.zRes*dkz)*np.exp(1j*self.k[2]*self.zmin)

field = np.fft.fftshift(phase_shift*field, axes=range(-self.dim, 0))
```

before passing the field to be plotted.
This adjusts the discrete transform to approximate the continuous Fourier transform.
The ``fftshift`` function is used to shift the zero frequency component to the center of the array.

??? example "Example"
    ```python
    # In ComFiT 1.9.0

    import comfit as cf
    import numpy as np

    bs = cf.BaseSystem(1, xlim=[-10,10], xRes=101)

    field = 0.5*bs.calc_Gaussian(position=1)
    field_f = bs.fft(field)

    fig, ax = bs.plot_subplots(1,2)
    bs.plot_field(field, ax=ax[0], fig=fig, title='Real field')
    bs.plot_complex_field(field_f, fourier=True, ax=ax[1], fig=fig, title='Fourier transform')

    bs.plot_save(fig)
    ```

    ![](img/base_system_fourier_transform_illustration.png#only-light)
    ![](img/base_system_fourier_transform_illustration-colorinverted.png#only-dark)

    Notice that since the field is real, the Fourier transform is symmetric in amplitude and opposite in phase around the zero frequency.

## Coarse-graining

A common and useful method is that of coarse-graining, which is defined as

$$
\rho = \langle \tilde \rho \rangle
\equiv \int d^d r' \mathcal K(\mathbf r-\mathbf r')
\tilde \rho(\mathbf r') ,
$$

where $\mathcal K(\mathbf r'-\mathbf r)$ is a Gaussian kernel given by

$$
\mathcal K(\mathbf r- \mathbf r') = \frac{1}{(2\pi w^2)^{d/2}} \exp\left (-\frac{(\mathbf r-\mathbf r')^2}{2w^2}
\right ),
$$

From a numerical point of view, this is done in Fourier space since, by the convolution theorem,

$$
\rho_{\mathfrak f} = \mathcal K_{\mathfrak f} \tilde \rho_{\mathfrak f}.
$$

Thus, we need the Fourier transform of $\mathcal K$, which is

$$
\mathcal K_{\mathfrak f} = \int d^d r e^{-i \mathbf k \cdot \mathbf r} \frac{1}{(2\pi w^2)^{d/2}} \exp\left (-\frac{\mathbf r^2}{2w^2} \right )
$$

$$
= \frac{1}{(2\pi w^2)^{d/2}} \prod_{n=1}^d \int dr_n e^{-\frac{1}{2 w^2} r_n^2 - \mathfrak i k_n r_n}
$$

$$
= \frac{1}{(2\pi w^2)^{d/2}} \prod_{n=1}^d \int dr_n e^{-\frac{1}{2 w^2} (r_n^2 + 2 \mathfrak i w^2 k_n r_n)}  
$$

$$
= \frac{1}{(2\pi w^2)^{d/2}} \prod_{n=1}^d e^{-\frac{1}{2} w^2 k_n^2} \int dr_n e^{-\frac{1}{2 w^2} (r_n + \mathfrak i w^2 k_n)^2}
$$

$$
= e^{-\frac{1}{2} w^2 \mathbf k^2}.
$$

This is why we have the following function

```python
calc_Gaussian_filter_f
```

which calculates $\mathcal K_{\mathfrak f}$.

Typically, a field is coarse-grained with a width using the following piece of code

```python
field = bs.ifft(bs.fft(field) * self.calc_Gaussian_filter_f(width))
```

The Gaussian function is actually so useful that is given by can be calculated using

```python
Gaussian = bs.calc_Gaussian()
```

## Vortex fields

A general feature that will be reused is that of vortex fields.
An angle field is a field where each point in space corresponds to an angle $\theta \in \mathcal S^n$.
A vortex is a topological defect in an angle field, around which the circulation is some integer multiple of the covering of $\mathcal S^n$.

### Angle field of a single vortex in two dimensions

In two dimensions, the angle field takes values $\theta \in [-\pi,\pi \rangle$ and a vortex is a point $\mathbf r_0$.
The angle field produced by the vortex has a circulation which is a multiple integer of $2\pi$, i.e.,

$$
\oint d\theta = 2\pi s_n,
$$

where $s_n$ is the integer charge of the vortex.
A possible angle field for a vortex positioned at $(x_0,y_0)$ is given by

$$
\theta_n = s_n \textrm{atan2}(y-y_0,x-x_0)
$$

### Angle field of a vortex ring in three dimensions

For a ring vortex in three dimensions centered at $\mathbf{r_0}$ with radius $R$, an angle field with the correct topological charge is given by first calculating the auxiliary quantities

$$
m_2 = (\mathbf{r}-\mathbf{r_0})\cdot \mathbf{n},
$$

$$
m_1 = |(\mathbf{r}-\mathbf{r_0}) - m_2\mathbf{n}|.
$$

and then calculating

$$
\theta_1 = \textrm{atan2}\left (m_2,m_1+R\right )
$$

$$
\theta_2 = \textrm{atan2}\left (m_2,m_1-R\right ) .
$$

These expressions are based on the geometry depicted in the following figure.

![Vortex ring angle field explanation](img/base_system_vortex_ring_angle_field_explanation.png#only-light)
![Vortex ring angle field explanation](img/base_system_vortex_ring_angle_field_explanation-colorinverted.png#only-dark)


*Vortex ring angle field explanation:* Geometry of a vortex ring in the plane given by $\vec n$.
$\mathcal N'$ is the plane normal to the tangent vector $\vec t'$ at $\vec r'$ upon which we impose a Cartesian coordinate system to determine the angles $\theta_1$, $\theta_2$ that are used to construct the (inset) initial angle field.
Figure reprinted from Ref.[^skogvollPhaseFieldCrystal2022] with permission.

The angle field is then given by

$$
\theta(\mathbf{r}) = \textrm{mod}(\theta_1+\theta_2,[-\pi,\pi \rangle)
$$

and is implemented in the function `calc_angle_field_vortex_ring`.

### Periodic boundary conditions: Numerical implementation of angle fields

Apart from the angle field of a single vortex, the other fields are compatible with periodic boundary conditions.
The expressions for these fields, however, are really only valid for an infinite region.
When this is imposed on periodic boundary conditions, it results in spurious boundary effects, especially if either of the vortices is placed near the edge of the simulation domain.
By simply inserting the vortices directly, we get what is shown in the following figure (a).

![Numerical implementation of periodic angle fields](img/base_system_numerical_implementation_of_periodic_angle_fields.png#only-light)
![Numerical implementation of periodic angle fields](img/base_system_numerical_implementation_of_periodic_angle_fields-colorinverted.png#only-dark)

*Numerical implementation of periodic angle fields:*
The angle field of panel (a) has been filtered by the field $F$ with $w=0.2x_{\textrm{max}}$ to produce the periodic field given in panel (c).
This field is simply rolled to produce a different position for the dipole in panel (d).

This field is not periodic on the domain. This typically causes the unintentional nucleation of vortices and strain on the boundary. We therefore seek to modify the fields so that they don't "see" the periodic boundary conditions.

In order to produce a field that is periodic on the domain, we transform the field $\theta$ to a complex field $\eta = e^{i \theta}$. The argument of this complex field has the correct winding configuration of the vortex dipole. However, we want to smooth this field so that it goes to $1$ ($\theta=0)$ at the borders. To do so, we introduce the filter function

$$
F = \frac{1}{2} \left ( \tanh((r^2-R^2)/w^2) - 1 \right ),
$$

where $r^2 = (x-x_{\textrm{mid}})^2 + (y-y_{\textrm{mid}})^2$, which is a function that is zero in the center region and goes to $1$ at infinity over a width of $w$. The filtered field $\eta$ is then obtained by making a smooth function that goes from the previous angle field according to

$$
\tilde \eta = F \cdot \eta + (F-1) \cdot 1.
$$

$\tilde \eta$ is shown in Figure (c). The value of $w$ and $R$ can be adjusted and are found in the source code as `width` and `radius`, respectively.

From this section, it is clear that the initial vortex dipole should not be too large. Thus, we have included a warning in case it is attempted to initiate a dipole with a larger distance than a certain threshold.

## Numerical integration scheme

The systems of interest for this code are those that can be written on the form

$$
\partial_t \psi = \omega \psi + N
$$

where $\omega$ is a linear differential operator and $N$ is a non-linear operator (function of $\psi$).
The following table shows some examples from the models that we will discuss in the following chapters.

| Model | $\omega$ | $\omega_{\mathfrak f}(\mathbf{k})$ | $N$ |
| --- | --- | --- | --- |
| Quantum Mechanics | $\frac{1}{2}i \nabla^2 $ | $-\frac{1}{2} i \mathbf{k}^2$ | $- i V$ |
| BEC | $(i+\gamma) (1+\frac{1}{2}\nabla^2)$ | $(i+\gamma) (1-\frac{1}{2}\mathbf k^2)$ | $- (i + \gamma) (V_{ext} + \psi \psi^*)\psi$ |
| Active Nematic | $\frac{K}{\gamma} \nabla^2 +\frac{AB}{\gamma}$ | $-\frac{K}{\gamma} k^2 +\frac{AB}{\gamma}$ | $- \mathbf{u}\cdot \nabla Q + Q \Omega -\Omega Q - \frac{2A}{\gamma}Q^2_{kk}Q$ |

*Table: Examples of time evolution operators, non-conserved.*

In the following, we will explain the method of evolution of exponential time differencing for stiff systems[^coxExponentialTimeDifferencing2002].
This will result in two integration schemes, the exponential time differencing second order Runge-Kutta 2 (ETD2RK) scheme and the forth order ETD4RK scheme. As in Ref. [coxExponentialTimeDifferencing2002], we will show an intuitive way to obtain the former and only recite the expressions for the latter.

### The ETD2RK scheme

To see how we obtain the ETD2RK scheme, we take the Fourier transformation of the time evolution equation, and get:

$$
\partial_t \psi_{\mathfrak f} = \omega_{\mathfrak f} \psi_{\mathfrak f} + N_{\mathfrak f} .
$$

$$
(\partial_t \psi_{\mathfrak f})e^{- \omega_{\mathfrak f} t}  -  \omega_{\mathfrak f} \psi_{\mathfrak f}  e^{- \omega_{\mathfrak f} t} = N_{\mathfrak f} e^{- \omega_{\mathfrak f} t} .
$$

$$
\partial_t (\psi_{\mathfrak f} e^{-\omega_{\mathfrak f} t} ) =  e^{-\omega_{\mathfrak f} t} N_{\mathfrak f}
$$

Where $\psi_{\mathfrak f}(\mathbf{k})$ is the Fourier transform of $\psi(\mathbf{r})$. Integrating from $t$ to $t+ \Delta t$, one finds:

$$
\psi_{\mathfrak f} (t+\Delta t) e^{- \omega_{\mathfrak f}(t+ \Delta t)} - \psi_{\mathfrak f} (t) e^{- \omega_{\mathfrak f} t} = \int_t^{t+\Delta t} e^{- \omega_{\mathfrak f} \tau} N_{\mathfrak f} d\tau
$$

we multiply by $e^{ \omega_{\mathfrak f}(t+ \Delta t)}$ and get:

$$
\psi_{\mathfrak f} (t+\Delta t) = \psi_{\mathfrak f} (t) e^{\omega_{\mathfrak f} \Delta t} + e^{ \omega_{\mathfrak f} (t+\Delta t)} \int_t^{t+\Delta t} e^{- \omega_{\mathfrak f} \tau} N_{\mathfrak f} d\tau
$$

This is an exact result, however, the last integral is unknown. In order to calculate the last integral here, we approximate it by $N (t+\tau) \approx N_{\mathfrak f 0} +  \frac{\Delta N_{\mathfrak f}}{\Delta t} \tau$ where $N_{\mathfrak f 0} = (N(\psi(t))_{\mathfrak f}$ and $\Delta N_{\mathfrak f} = N_{\mathfrak f}(t+\Delta t)-N_{\mathfrak f}(t)$. We also change the integration limits from $\tau \in [t,t+\Delta t]$ to $\tau \in [0,\Delta t]$, which gives:

$$
\psi_{\mathfrak f} (t+\Delta t) = \psi_{\mathfrak f} (t) e^{ \omega_{\mathfrak f} \Delta t}
$$

$$
+ e^{\omega_{\mathfrak f} \Delta t} \frac{1}{- \omega_{\mathfrak f}} [e^{- \omega_{\mathfrak f} \tau}]_0^{\Delta t} N_{\mathfrak f 0} + e^{ \omega_{\mathfrak f} \Delta t} \frac{1}{\Delta t} [\frac{\tau e^{-\omega_{\mathfrak f} \tau}}{-\omega_{\mathfrak f}} - \frac{e^{-\omega_{\mathfrak f} \tau}}{\omega_{\mathfrak f}^2}]_0^{\Delta t} \Delta N_{\mathfrak f}
$$

To find $\psi_{\mathfrak f} (t+\Delta t)$, we would need to know the value $N_{\mathfrak f} (t+\Delta t)$ before finding the state at $\psi(t+\Delta t)$. To do this, we first find a predicted state $\psi_a$ by assuming $\Delta N_{\mathfrak f}=0$ and calculating $\psi(t)$ according to the equation above. This lets us calculate an approximate $\Delta N_{\mathfrak f} = N_{\mathfrak f a} - N_{\mathfrak f 0}$ and we use this in order to evolve $\psi$. This is the ETD2RK scheme.

---
$$
\psi_{\mathfrak f a} = I_{\mathfrak f 0} \psi_{\mathfrak f 0} + I_{\mathfrak f 1} N_{\mathfrak f 0}
$$

$$
\psi_{\mathfrak f} (t+\Delta t) = \psi_{\mathfrak f a} + I_{\mathfrak f 2} (N_{\mathfrak f a} - N_{\mathfrak f 0})
$$

$$
\textrm{where}
$$

$$
I_{\mathfrak f 0} = e^{\omega_{\mathfrak f} \Delta t}
$$

$$
I_{\mathfrak f 1} = \frac{1}{\omega_{\mathfrak f}} (e^{ \omega_{\mathfrak f} \Delta t} - 1)
$$

$$
I_{\mathfrak f 2} = \frac{1}{\omega_{\mathfrak f}^2 \Delta t} (e^{ \omega_{\mathfrak f} \Delta t} -1  -\omega_{\mathfrak f} \Delta t)
$$

$$
N_{\mathfrak f 0} = (N(\psi(t),t))_{\mathfrak f}
$$

$$
N_{\mathfrak f a} = (N(\psi_a,t+\Delta t))_{\mathfrak f}
$$

---

Note that $N_{\mathfrak f}$ is a non-linear function of the field variable $\psi$, but can also be an explicit variable of time $t$, i.e. $N_{\mathfrak f}(\psi,t)$.
Therefore, in the code, it has to be encoded as a function of these two variables `calc_nonlinear_evolution_function_f(self, psi, t)`.

For numerical purposes, it is useful to calculate the small $\omega_{\mathfrak f}$ limit. We expand the exponential in its Taylor series and keep the leading order term to get:

$$
I_{\mathfrak f 0} \approx 1
$$

$$
I_{\mathfrak f 1} \approx   \frac{1}{\omega_{\mathfrak f}} (1 + \omega_{\mathfrak f} \Delta t - 1) = \Delta t
$$

$$
I_{\mathfrak f 2} \approx \frac{1}{\omega_{\mathfrak f}^2 \Delta t}
 \left ( 1 + \omega_{\mathfrak f} \Delta t + \frac{1}{2} ( \omega_{\mathfrak f} \Delta t )^2
 -1 - \omega_{\mathfrak f} \Delta t
\right ) = \frac{1}{2} \Delta t
$$

In $I_{\mathfrak f 1}$, and $I_{\mathfrak f 2}$ there is a division by $0$ when $\omega_{\mathfrak f} = 0$. To avoid numerical issues related to this we use the above limits when $|\omega_{\mathfrak f}|$ is smaller than a tolerance. We don't use the limit for $I_{\mathfrak f 0}$ since it doesn't contain a division by $0$. The function `evolve_ETD2RK_loop` defined in the base system class performs an ETD2RK step. This function is called by the evolvers discussed in the model chapter if the method is defined as `method = "ETD2RK"`. This is the default solver if `method` is not set. The integrating factors for a given $\omega_{\mathfrak f}(\mathbf{k})$ can be found with the function `calc_evolution_integrating_factors_ETD2RK` where the variable `tol` gives when the factors should be replaced by their leading order Taylor expansion.
Note that all solvers defined in the  class `BaseSystem` updates the time variable
`self.t` to allow for time-dependents in the non-linear term.

### The ETD4RK scheme

Following Ref.[^coxExponentialTimeDifferencing2002], we may generalize the method to a fourth order Runge-Kutta as follows

---
$$
\begin{aligned}
\psi_{\mathfrak f a} &= I_{\mathfrak f 0} \psi_{\mathfrak f 0} +  I_{\mathfrak f 1} N_{\mathfrak f 0} \\
\psi_{\mathfrak f b} &= I_{\mathfrak f 0} \psi_{\mathfrak f 0} + I_{\mathfrak f 1} N_{\mathfrak f a} \\
\psi_{\mathfrak f c} &= I_{\mathfrak f 0} \psi_{\mathfrak f a} + I_{\mathfrak f 1} (2 N_{\mathfrak f b} - N_{\mathfrak f 0}) \\
\psi_{\mathfrak f} (t+\Delta t) &= I_{\mathfrak f 2} \psi_{\mathfrak f 0} + I_{\mathfrak f 3} N_{\mathfrak f 0} + I_{\mathfrak f 4} (N_{\mathfrak f a} + N_{\mathfrak f b}) + I_{\mathfrak f 5} N_{\mathfrak f c}
\end{aligned}
$$

where

$$
\begin{aligned}
I_{\mathfrak f 0} &= e^{\omega_{\mathfrak f} \Delta t/2} \\
I_{\mathfrak f 1} &= \frac{1}{\omega_{\mathfrak f}}
( e^{ \omega_{\mathfrak f} \Delta t/2} - 1) \\
I_{\mathfrak f 2} &= e^{\omega_{\mathfrak f} \Delta t} \\
I_{\mathfrak f 3} &= \frac{1}{ \omega_{\mathfrak f}^3\Delta t^2}
\left ( -4 -  \omega_{\mathfrak f} \Delta t  + e^{\omega_{\mathfrak f} \Delta t}(4-3\omega_{\mathfrak f} \Delta t + \omega_{\mathfrak f}^2 \Delta t^2 )  \right ) \\
I_{\mathfrak f 4} &= \frac{2}{ \omega_{\mathfrak f}^3\Delta t^2}
\left ( 2 + \omega_{\mathfrak f} \Delta t + e^{\omega_{\mathfrak f} \Delta t}(-2 + \omega_{\mathfrak f} \Delta t) \right ) \\
I_{\mathfrak f 5} &= \frac{1}{ \omega_{\mathfrak f}^3\Delta t^2}
\left ( -4 - 3 \omega_{\mathfrak f} \Delta t -  \omega_{\mathfrak f}^2 \Delta t^2 + e^{\omega_{\mathfrak f} \Delta t}(4-\omega_{\mathfrak f} \Delta t) \right )
\end{aligned}
$$

---

**Algorithm:** The ETD4RK scheme

In the small $\omega_{\mathfrak f}$ limit, we have

$$
I_{\mathfrak f 0} \approx 1
$$

$$
I_{\mathfrak f 1} \approx \frac{1}{2} \Delta t
$$

$$
I_{\mathfrak f 2} \approx 1
$$

$$
I_{\mathfrak f 3} \approx
\frac{1}{ \omega_{\mathfrak f}^3\Delta t^2} \times
\left ( -4 - \omega_{\mathfrak f} \Delta t + (1 + \omega_{\mathfrak f} \Delta t + \frac{1}{2} (\omega_{\mathfrak f} \Delta t)^2 + \frac{1}{6} (\omega_{\mathfrak f} \Delta t)^3 )(4-3\omega_{\mathfrak f} \Delta t + \omega_{\mathfrak f}^2 \Delta t^2 )
\right ) $$

$$
= \frac{1}{ \omega_{\mathfrak f}^3\Delta t^2}
\left ( \frac{4}{6} (\omega_{\mathfrak f} \Delta t)^3 - \frac{3}{2} (\omega_{\mathfrak f} \Delta t)^3 + (\omega_{\mathfrak f} \Delta t)^3
\right )
= \frac{1}{6} \Delta t
$$

$$
I_{\mathfrak f 4} \approx \frac{2}{ \omega_{\mathfrak f}^3\Delta t^2}
\left (2 + \omega_{\mathfrak f} \Delta t +(1 + \omega_{\mathfrak f} \Delta t + \frac{1}{2} (\omega_{\mathfrak f} \Delta t)^2 + \frac{1}{6} (\omega_{\mathfrak f} \Delta t)^3 )(-2 + \omega_{\mathfrak f} \Delta t)
\right )
$$

$$
= \frac{2}{ \omega_{\mathfrak f}^3\Delta t^2}
\left ( \frac{1}{2} (\omega_{\mathfrak f} \Delta t)^3-\frac{2}{6}(\omega_{\mathfrak f} \Delta t)^3
\right ) = \frac{1}{3} \Delta t
$$

$$
I_{\mathfrak f 5} =
\frac{1}{ \omega_{\mathfrak f}^3\Delta t^2} \times
\left (
-4 - 3 \omega_{\mathfrak f} \Delta t -  \omega_{\mathfrak f}^2 \Delta t^2 + (1 + \omega_{\mathfrak f} \Delta t + \frac{1}{2} (\omega_{\mathfrak f} \Delta t)^2 + \frac{1}{6} (\omega_{\mathfrak f} \Delta t)^3 )(4-\omega_{\mathfrak f} \Delta t)
\right )  
$$

$$
=\frac{1}{ \omega_{\mathfrak f}^3\Delta t^2}
\left ( \frac{4}{6} (\omega_{\mathfrak f} \Delta t)^3 - \frac{1}{2} (\omega_{\mathfrak f} \Delta t)^3
\right ) = \frac{1}{6} \Delta t
$$

Similar as for the EDT2RK case $I_{\mathfrak f 1}$, $I_{\mathfrak f 3}$, $I_{\mathfrak f 4}$, and $I_{\mathfrak f 5}$ contains a division by $0$ when $\omega_{\mathfrak f} = 0$.  
We therefore replace these coefficients with their limits when $|\omega_{\mathfrak f}|$ is smaller than a tolerance.
This has been important in order to make the the code stable for some of the systems.
In the same way as the EDT2RK scheme this is implemented as the function
`self.evolve_ETD4RK_loop(self, integrating_factors_f, non_linear_evolution_function, field, field_f)`
This function is called by the evolvers discussed in the model chapter if the method is defined as ```method = "ETD4RK"```, the integrating factors are found with
`self.calc_evolution_integrating_factors_ETD4RK(self, omega_f, tol=10**(-4))`.

### The fully non-linear limit
It is both interesting and enlightening to see the fully non-linear limit of these equations, i.e., the limit in which $\omega_{\mathfrak f} =0$, $N_{\mathfrak f} = \partial_t \psi \equiv \dot{\psi}_{\mathfrak f}$ and the small $\omega_{\mathfrak f}$ approximations are exact.
For the ETD2RK scheme, we get

$$
\psi_{\mathfrak f a} = \psi_{\mathfrak f 0} +  \dot{\psi}_{0_f} \Delta t
$$

$$
\psi(t+\Delta t)_f = \psi_{\mathfrak f 0} + \dot{\psi}_{\mathfrak f 0} \frac{\Delta t}{2} + \dot{\psi}_{\mathfrak f a} \frac{\Delta t}{2},
$$

which is a two-stage Runge-Kutta method called Heun's method.

The ETD4RK scheme becomes

$$
\psi_{\mathfrak f a} = \psi_{\mathfrak f 0} +  \dot{\psi}_{\mathfrak f 0} \frac{\Delta t}{2}
$$

$$
\psi_{\mathfrak f b} =  \psi_{\mathfrak f 0} +  \dot{\psi}_{\mathfrak f a} \frac{\Delta t}{2}
$$

$$
\psi_{\mathfrak f c} = \psi_{\mathfrak f a} + ( 2 \dot{\psi}_{\mathfrak f b} - \dot{\psi}_{\mathfrak f 0}) \frac{\Delta t}{2}
$$

$$
\psi_{\mathfrak f} (t+\Delta t) = \psi_{\mathfrak f 0} + \frac{1}{6} ( \dot{\psi}_{\mathfrak f 0} + 2 \dot{\psi}_{\mathfrak f a} + 2 \dot{\psi}_{\mathfrak f b} + \dot{\psi}_{\mathfrak f c} ) \Delta t.
$$

Note that this is not the typical Runge-Kutta 4 method, due to the differences in calculating $\psi_{\mathfrak f c}$.
The reason is that a straight-forward generalization of the Runge-Kutta 4 method will not produce a fourth-order method in the general case [^coxExponentialTimeDifferencing2002].

### The fully linear limit

If $N=0$, the evolution equation changes to

$$
\psi_{\mathfrak f}(t+\Delta t) = e^{\omega_{\mathfrak f} \Delta t} \psi_{\mathfrak f}.
$$

An example of this is the schrödinger equation, for which $\omega_{\mathfrak f} = -\frac{1}{2}  i \mathbf k^2$, so we get

$$
\psi_{\mathfrak f}(t+\Delta t) = e^{- i \frac{1}{2} \mathbf k^2 \Delta t} \psi_{\mathfrak f}.
$$

This is an exact equation, of course, so you may evolve this free particle solution to any time.

## Testing

In order to test the numerical methods, study the simplest model of a field equation with a (non-linear) forcing term, namely the heat equation

$$
\partial_t T = \nabla^2 T + f(\mathbf r),
$$

where $T$ is the temperature in celsius, and $f(\mathbf r)$ is a forcing term, which we model as

$$
f(\mathbf r) = A (T_0-T) \exp\left (-\frac{(\mathbf r-\mathbf r_0)^2}{2\sigma^2}\right ),
$$

which represents a heating element with temperature $T_0$ placed at $\mathbf r_0$.

As a benchmark, we use the `solve_ivp` of the `scipy` library `sp.integrate` to solve the equation using a finite difference method.
The solutions match to a satisfactory degree, but a more thorough investigation into how the accuracy of the framework and integration methods scale with spatial and temporal resolution will be performed in the future.
Tests are included in `test_base_system.py`, but for visual examination, here are animations of the initial condition $T=0$ in all three dimensions

![Testing of the evolution code in 1 dimension](img/base_system_evolution_test_1D.gif#only-light)
![Testing of the evolution code in 1 dimension](img/base_system_evolution_test_1D-colorinverted.gif#only-dark)

![Testing of the evolution code in 2 dimensions](img/base_system_evolution_test_2D.gif#only-light)
![Testing of the evolution code in 1 dimension](img/base_system_evolution_test_2D-colorinverted.gif#only-dark)

![Testing of the evolution code in 3 dimensions](img/base_system_evolution_test_3D.gif#only-light)
![Testing of the evolution code in 1 dimension](img/base_system_evolution_test_3D-colorinverted.gif#only-dark)

## Algorithms for tracking defects

To be written

## Calculating the velocity

The equations for the velocity are taken from Ref.[^skogvollUnifiedFieldTheory2023], simplified using Mathematica and then
substituted for python code using chatGPT.


[^coxExponentialTimeDifferencing2002]: Cox, S. M., & Matthews, P. C. (2002). Exponential Time Differencing for Stiff Systems. Journal of Computational Physics, 176(2), 430–455. [https://doi.org/10.1006/jcph.2002.6995](https://doi.org/10.1006/jcph.2002.6995)

[^skogvollUnifiedFieldTheory2023]: Skogvoll, V., Rønning, J., Salvalaglio, M., & Angheluta, L. (2023). A unified field theory of topological defects and non-linear local excitations. Npj Computational Materials, 9(1), Article 1. [https://doi.org/10.1038/s41524-023-01077-6](https://doi.org/10.1038/s41524-023-01077-6)

[^skogvollPhaseFieldCrystal2022]: Skogvoll, V., Angheluta, L., Skaugen, A., Salvalaglio, M., & Viñals, J. (2022). A phase field crystal theory of the kinematics of dislocation lines. Journal of the Mechanics and Physics of Solids, 166, 104932. https://doi.org/10.1016/j.jmps.2022.104932

--- End of file: docs\ClassBaseSystem.md ---

--- Start of file: docs\ClassBoseEinsteinCondensate.md ---
# Class: Bose-Einstein Condensate

There are two types of particles in the world: fermions and bosons.
Whereas fermions can never occupy the same quantum state due to the Pauli Exclusion principle, the same is not true for bosons.
A Bose-Einstein condensate (BEC) is a state of matter consisting of ultra-cold bosons that undergo a phase transition at a low critical temperature in which most bosons occupy the ground state of the system.
It was theorized by Einstein and Bose in the 1920s as a new state of matter and produced for the first time in 1995 by Eric Cornell and Carl Wieman[^andersonObservationBoseEinsteinCondensation1995].

In this class, we simulate a Bose-Einstein condensate in 1, 2 and 3 dimensions using the Gross-Pitaevski equation (GPE).

```python
file: comfit/models/bose_einstein_condensate.py 
class: BoseEinsteinCondensate
```

See the ComFiT Library Reference below for a complete list of class methods and their usage.

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
    <a href="https://comfitlib.com/library_reference/bose_einstein_condensate/" class="card" style="min-width: 160px; flex: 0 1 calc(100.00% - 10px); margin: 5px;">
        <div style="text-align: center;">
            <strong> ComFiT Library Reference </strong>
        </div>
    </a>
</div>

## Variables and Parameters

The primary field in the Bose-Einstein condensate model is the complex wave function $\psi$:

```python
bec.psi
```

The `BoseEinsteinCondensate` class accepts the same keyword arguments as the `BaseSystem` class, with the addition of the following specific parameters:

| Keyword | Definition           | Default Value |
|---------|----------------------|---------------|
| `gamma` | Dissipative factor   | $0.01$        |

These parameters allow for the customization and fine-tuning of the Bose-Einstein condensate simulation.


## Model

The BEC is in the mean field regime described by the GPE[^dalfovo1999theory] [^kevrekidis2007emergent]. 
This is a non-linear Schrödinger equation which reads

$$
i\hbar \partial_t\psi = \left[-\frac{\hbar^2}{2m} \nabla^2+ V_{ext} -\mu +g|\psi|^2 \right]\psi.
$$

Here, $\mu$ is the chemical potential, $m$ is the mass of the bosons, $g$ is an interaction parameter and $\hbar$ is the Planc constant. 
$\psi$ is the wave function describing the condensate phase and $V_{ext}$ is an external potential. 
The GPE can be obtained from the variational principle [^kevrekidis2007emergent][^pitaevskiiBook]

$$
\mathfrak i \hbar \partial_t \psi = \frac{\delta K}{\delta \psi^*}
$$

with the Hamiltonian

$$
K = \int d \mathbf r \left[\frac{\hbar^2}{2m}|\nabla\psi|^2 +(V_{ext} -\mu)|\psi|^2 +\frac{g}{2}|\psi|^4 \right].
$$

We introduce dimensionless units for length $\xi = \hbar/\sqrt{m\mu}$, time $\tau = \xi/c$ and energy $E=\eta$ and rescaling the wave function to $\psi \rightarrow \sqrt{\frac{g}{\mu}}\psi$, in addition we include a dissipative factor $\gamma$.
This results in the dGPE on dimensionless form as
[^gardiner2003stochastic] [^rooney2012stochastic] [^bradley2012energy] [^skaugenUnifiedPerspectiveTwodimensional2018]

<!-- $$
\mathfrak i \partial_t \psi = (1-\mathfrak i\gamma) \left[-\frac{1}{2}\nabla^2 + V_{ext} -1 +|\psi|^2 \right]\psi.
$$

$$
\partial_t \psi =-\mathfrak i (1-\mathfrak i\gamma) \left[-\frac{1}{2}\nabla^2 + V_{ext} -1 +|\psi|^2 \right]\psi.
$$

$$
\partial_t \psi =-(\mathfrak i+\gamma) \left[-\frac{1}{2}\nabla^2 + V_{ext} -1 +|\psi|^2 \right]\psi.
$$ -->

!!! equation "The damped Gross-Pitaevski equation (`evolve_dGPE`)"
    $$
    \partial_t \psi =-(\mathfrak i+\gamma) \left[-\frac{1}{2}\nabla^2 + V_{ext} -1 +|\psi|^2 \right]\psi.
    $$

So we see that we can split into its linear and non-linear parts as

$$
\omega = (\mathfrak{i}+\gamma) (1 + \frac{1}{2}\nabla^2), \quad N = - (\mathfrak{i} + \gamma) (V_{ext} + |\psi|^2)\psi
$$

The Hamiltonian and its density in dimensionless units are calculated by the functions

```python
bec.calc_hamiltonian(self)
bec.calc_hamiltonian_density(self)
```

## Approximation of Ground States

In simulations, it is often convenient to start in a configuration that is close to the ground state. 
We can estimate this ground state by noticing that the GPE dissipates energy when it is evolved in imaginary time $t \rightarrow it$
[^minguzzi2004numerical] [^kevrekidis2007emergent].
We refer to this as *evolving the dGPE in imaginary time*.
Given an external potential $V_{ext}$ we can therefore find an approximation to the ground state by starting with a guess and then removing energy from the guessed state by evolving the equations in imaginary time.

To get a guess of the ground state for a given potential $V_{ext}$ we use the Thomas-Fermi approximation [^dalfovo1999theory] [^kevrekidis2007emergent], where we assume that $\psi$ is slowly varying so that we can neglect the Laplacian term.
Looking for stationary solutions to the dGPE we obtain the equation

$$
0 = (V_{ext} - 1 +|\psi|^2 )\psi.
$$

This has two solutions, $\psi = 0$
and

$$
|\psi|^2 = 1-V_{ext}.
$$

In the case where $V_{ext} > 1$ there is only one possibility, namely $\psi = 0$. 
In the case of $V_{ext}  < 1$, both the stationary solutions exist, so we need to evaluate their energy. 
We can do this by considering the Hamiltonian

$$
K_{TF} = \int d\mathbf r \left[(V_{ext}  -1)|\psi|^2 + \frac{1}{2} |\psi|^4 \right].
$$

Inserting the anzats $\psi =0$ we see that this vanishes, while if we insert the anzats $|\psi|^2 = 1-V_{ext}$, we get something negative. 
We therefore conclude that the Thomas-Fermi ground state is given as

$$
\psi = \begin{cases}
     0 & \text{if} \quad V_{ext}  > 1 \\
     \sqrt{1 -V_{ext}}  & \text{if}\quad V_{ext}  < 1
    \end{cases}
$$

This ground state can be initialized as

```python
bec.conf_initial_condition_Thomas_Fermi(self)
```

Once this guess is initialized we can propagate the wave function in imaginary time using the function

```python
bec.evolve_relax_BEC(self,number_of_steps,method='ETD2RK')
```

Note that the potential has to be a constant during this evolution.

## Potentials

A lot of the interesting dynamics of a BEC come about when it is interacting with an external potential. 
This is included as the function

```python
bec.V_ext(t) 
```

By default, this is assumed to be time-independent and returns the field

```python
bec.V_0 
```

The potential can be changed by the function

```{.python language="Python"}
bec.conf_external_potential(self, V_ext, additive=False)
```

which can be used both to set it as a function or to set it as a constant potential depending on whether `V_ext` is a function, a constant or an numpy array. 
If `additive =True` one add the constant `V_ext` to the allready existing potential.
If `V_ext` is a function it needs to be on the form

```{.python language="Python"}
def V(t)
     ...
     return ...
```

The evolver will then evaluate it using the `bec.time` variable which is updated on the run.
An example using a Gaussian stirring potential is provided in the example folder.

To make life easier we have provided a couple of popular potentials.
The harmonic potential is provided in the function

```python
bec.set_harmonic_potential(self,R_tf)
```

Here $R_{tf}$ is the Thomas-Fermi radius [^kevrekidis2007emergent], and the harmonic potential takes the form $$V_H = \frac{r^2}{R_{tf}^2}$$.
The Gaussian potential is provided through the function

```python
bec.gaussian_stirring_potential(self,size,strength,position)
```

giving the potential

$$
V_g = g e^{-|\mathbf{r} - \mathbf{r}_p|^2/\sigma^2}.
$$

Here
$g$ is the strength, $\sigma$ is the size and $\mathbf{r}_p$ is the position.

Much of the interesting physics happens when the potential is time-dependent. 
For this one can define a function as

```python
def Func():
    ...
```

and update the external potential to this function by calling

## Hydrodynamics

The dGPE can be transformed to a hydrodynamic description of the BEC.
The first step in doing this is to introduce the Madelung transformation $\psi = \sqrt{\rho} e^{i\theta}$, where $\rho = |\psi|^2$ is the superfluid density [^kevrekidis2007emergent]. 
For $\gamma = 0$ this density is conserved and satisfies the conservation equation

$$
\partial_t \rho + \nabla\cdot \mathbf{J}_s = 0,
$$

with the superfluid current given by

$$
\mathbf{J}_s = \Im(\psi^* \nabla \psi) = \rho \nabla \theta = \rho \mathbf{v}_s.
$$

Here the superfluid velocity is introduced as
$\mathbf{v}_s = \nabla \theta$. 
The superfluid current can be found with the function

```python
bec.calc_superfluid_current(self)   
```

We can also put the Madelung transformation into the Hamiltonian to get [^bradley2012energy] [^nore1997kolmogorov]

$$
K = \int d \mathbf r \left[\frac{1}{2}\rho v_s^2 +\frac{1}{8} \frac{|\nabla \rho|^2}{\rho} + (V_{ext}-1)\rho +\frac{1}{2}\rho^4 \right].
$$

The first term here is the kinetic energy of the condensate.
To calculate this it is convenient to introduce the density weighted velocity $\mathbf{u} = \sqrt{\rho}\mathbf{v}_s$[^bradley2012energy].
This have the advantage of not being singular at the centre of the topological defects. 
Using this we can write the kinetic energy as $$E_k =\int d \mathbf r \frac{1}{2}u^2.$$ 
The density weighted velocity and the kinetic energy can be calculated by the functions

```python
bec.calc_velocity(self)
bec.calc_kinetic_energy(self)
```

Further, if we insert the Madelung transformation into the dGPE and do some work we can map it into the Navier-Stokes equations [^kevrekidis2007emergent] [^bradley2012energy]

$$
\begin{aligned}
    \partial_t \rho + \nabla\cdot(\rho \mathbf v) =2\gamma \rho (1-V_{eff}),
    \\
    \partial_t \mathbf v-\mathbf v\cdot\nabla \mathbf v =  - \nabla(V_{ext} +\rho) +\frac{\gamma}{2}\nabla^2 \mathbf v.
\end{aligned}
$$

Notice that the condensate density is only conserved when $\gamma = 0$.

## Forces on external potential

To study how the BEC interacts with impurities, one can model the impurity as a Gaussian potential and measure the forces that are acting
on it [^ronning2020classical] [^astrakharchik2004motion] [^pinsker2017gaussian].
From the Ehrenfest theorem the forces on the condensate from the stirrer is given as

$$
\mathbf{F} = -\langle \nabla V_{ext}\rangle,
$$

which means that the force acting on the stirrer is $\mathbf{F} = \langle \nabla V_{ext}\rangle$. 
Written explicitly, this is

$$
\mathbf{F} = \int d\mathbf r |\psi^2| \nabla V_{ext} = -\int d\mathbf r V_{ext}\nabla|\psi^2|,
$$

and is calculated by the function

```python
bec.calc_force_on_external_potential(self)
```

Note that this calculates the average force on all of the external potential.

## Quantized vortices

The topological defects in the BEC take the form of quantized vortices.
This is because the velocity is given by the gradient of the phase $\mathbf{v}_s = \nabla \theta$. 
This has the consequence that the circulation $$\Gamma = \oint d\mathbf{l} \cdot \mathbf{v} = \oint d\mathbf{l} \cdot \nabla \theta = \int d\theta$$
is quantized in units of $2\pi$, since the field $\psi$ is single-valued.
In two dimensions this vortex is a point defect, while in three dimensions it is a line defect.
For the BEC this method is given by the function

```python
bec.calc_vortex_nodes( dt_psi=None)
```

which finds the vortex nodes in two or three dimensions. 
If $\partial_t \psi$ is put in as the field `dt_psi`, then the velocity of the defects are also found.

The defects can be created in multiple ways. In addition to putting them in by hand, one can create them by stirring the condensate with a potential or by relaxing a disordered initial state.

## Comoving frame

When studying a BEC that is stirred by a potential it is in some cases convenient to consider the potential as stationary with the BEC flowing around. 
This can be done by boosting the dGPE so that it reads

$$
\partial_t \psi = \mathbf V_p \cdot \nabla \psi +(\mathfrak i+\gamma) (1+\frac{1}{2}\nabla^2) \psi - (\mathfrak i + \gamma) (\mathcal U + |\psi|^2)\psi,
$$

where $\mathbf{V_p}$ is the velocity of the boost. Note that a Galilean boost of the GPE is often accompanied by a phase shift of the wave
function
$\psi \rightarrow \psi \exp{(\mathfrak i\mathbf V_p \cdot \mathbf r + \frac i 2 V_p^2 t)}$, which transforms the superfluid velocity to the new reference frame[^Pismen], leaving the GPE unchanged after the Galilean transformation.
However, the equation with $\gamma \neq 0$ is not Galilean invariant and we therefore do not include the phase factor in the transformation.
This has the consequence that the superfluid velocity obtained from $\psi$ is measured in the lab frame and not the comoving frame[^ronning2020classical].

To reduce the recycling of excitations into the incoming flow, we introduce a buffer region around the computational domain where $\gamma$ is large, similar to the one used in Ref. [^reeves2015identifying]. 
The dissipative factor becomes a function of space and is given by

$$
\gamma(\mathbf{r}) = \max[\gamma_x(x),\gamma_y(y),\gamma_z(z)]
$$ 

in three dimensions and

$$
\gamma(\mathbf{r}) =
\max[\gamma_x(x),\gamma_y(y)
$$ 

in two dimensions. Here

$$
\begin{aligned}
\gamma_x(x)= \frac{1}{2}\big(2 + \tanh{[(x-w_x)/d]}
-\tanh{[(x+w_x)/d]}\big) + \gamma_0.
\end{aligned}
$$

and similar for $\gamma_y(y)$ and $\gamma_z(z)$.
The constant $\gamma_0$ is the value in the bulk, $d$ is the size of the interface between the bulk and the buffer and $w_x$ is the distance from the centre of the domain to the buffer in the $x$ direction.
Note that when $\gamma$ is a function of space we can no longer put it into the non-linear differential operator $\omega$, and we have to move it into the
non-linear part.
This is taken care of in the evolver

```python
bec.evolve_comoving_dGPE(self, number_of_steps, velx,method='ETD2RK')
```

Here it is assumed that the boost is in the $x$-direction, and that the dissipative factor is spatially dependent.

[^andersonObservationBoseEinsteinCondensation1995]: Anderson, M. H., Ensher, J. R., Matthews, M. R., Wieman, C. E., & Cornell, E. A. (1995). Observation of Bose-Einstein Condensation in a Dilute Atomic Vapor. Science, 269(5221), 198–201. [https://doi.org/10.1126/science.269.5221.198](https://doi.org/10.1126/science.269.5221.198)
[^dalfovo1999theory]: Dalfovo, F., Giorgini, S., Pitaevskii, L. P. and Stringari, S. (1999). Theory of Bose-Einstein condensation in trapped gases. Reviews of Modern Physics. 71, 3, 463. [https://doi.org/10.1103/RevModPhys.71.463](https://doi.org/10.1103/RevModPhys.71.463)
[^kevrekidis2007emergent]: Kevrekidis, P. G.,  Frantzeskakis, D. J. and  Carretero-González, R. (2008). Emergent nonlinear phenomena in Bose-Einstein condensates: theory and experiment. Springer Science & Business Media. Berlin.
[^pitaevskiiBook]: Pitaevskii, L. and Stringari, S. (2016). Bose-Einstein Condensation and Superfluidity. Oxford University Press. [https://doi.org/10.1093/acprof:oso/9780198758884.001.0001](https://doi.org/10.1093/acprof:oso/9780198758884.001.0001})
[^gardiner2003stochastic]: Gardiner, C. W. and Davis, M. J. (2003). The stochastic Gross-Pitaevskii equation: II. Journal of Physics B: Atomic, Molecular and Optical Physics. 36, 23, 4731. [https://doi.org/10.1088/0953-4075/36/23/010](https://doi.org/10.1088/0953-4075/36/23/010)
[^rooney2012stochastic]: Rooney, S. J., Blakie, P. B. and Bradley, A. S. (2012). Stochastic projected Gross-Pitaevskii equation. Physical Review A. 86, 5, 053634. [https://doi.org/10.1103/PhysRevA.86.053634](https://doi.org/10.1103/PhysRevA.86.053634)
[^bradley2012energy]: Bradley, A. S. and Anderson, B. P. (2012). Energy spectra of vortex distributions in two-dimensional quantum turbulence. Physical Review X. 2, 4, 041001 [https://doi.org/10.1103/PhysRevX.2.041001](https://doi.org/10.1103/PhysRevX.2.041001)
[^skaugenUnifiedPerspectiveTwodimensional2018]: Skaugen, A. (2018). A Unified Perspective on Two-Dimensional Quantum Turbulence and Plasticity. PhD Thesis, University of Oslo. [http://urn.nb.no/URN:NBN:no-69394](http://urn.nb.no/URN:NBN:no-69394)
[^minguzzi2004numerical]: Minguzzi, A., Succi, S., Toschi, F., Tosi, M. P. and Vignolo, P. (2004). Numerical methods for atomic quantum gases with applications to Bose-Einstein condensates and to ultracold fermions. Physics reports. 395, 4-5, 223-355. [https://doi.org/10.1016/j.physrep.2004.02.001](https://doi.org/10.1016/j.physrep.2004.02.001)
[^nore1997kolmogorov]: Nore, C., Abid, M. and Brachet, M. E. (1997). Kolmogorov turbulence in low-temperature superflows. Physical review letters. 78, 20, 3896. [https://doi.org/10.1103/PhysRevLett.78.3896](https://doi.org/10.1103/PhysRevLett.78.3896)
[^ronning2020classical]: Rønning, J., Skaugen, A., Hernández-García, E., López, C. and Angheluta, L. (2020). Classical analogies for the force acting on an impurity in a Bose-Einstein condensate. New Journal of Physics. 22, 7, 073018. [https://doi.org/10.1088/1367-2630/ab95de](https://doi.org/10.1088/1367-2630/ab95de)
[^astrakharchik2004motion]: Astrakharchik, G. E. and Pitaevskii, L. P. (2004). Motion of a heavy impurity through a {Bose-Einstein} condensate. Physical Review A. 70, 1, 013608. [https://doi.org/10.1103/PhysRevA.70.013608](https://doi.org/10.1103/PhysRevA.70.013608)
[^pinsker2017gaussian]: Pinsker, F. (2017). Gaussian impurity moving through a {Bose-Einstein} superfluid. Physica B: Condensed Matter. 521, 36-42. [https://doi.org/10.1016/j.physb.2017.06.038](https://doi.org/10.1016/j.physb.2017.06.038)
[^Pismen]: Pismen, L.M. (1999). Vortices in Nonlinear Fields: From Liquid Crystals to Superfluids, From Non-Equilibrium Patterns to Cosmic Strings. Oxford university press. Oxford
[^reeves2015identifying]: Reeves, M. T., Billam, T. P., Anderson, B. P. and Bradley, A. S. (2015). Identifying a superfluid Reynolds number via dynamical similarity. Physical Review Letters. 114, 15, 155302. [https://doi.org/10.1103/PhysRevLett.114.155302](https://doi.org/10.1103/PhysRevLett.114.155302)

--- End of file: docs\ClassBoseEinsteinCondensate.md ---

--- Start of file: docs\ClassNematicLiquidCrystal.md ---
# Class: Nematic Liquid Crystal

A nematic liquid crystal is a state of matter between a solid and a liquid. 
It is characterized by the orientation of the molecules, which is ordered, but not the position. 
The molecules are rod-like and the orientation is described by a unit vector, the nematic director. 
The nematic liquid crystal is the simplest form of liquid crystal, and is characterized by the nematic director being the only order parameter. 
The nematic liquid crystal is used to describe the behavior of many biological systems, such as the cytoskeleton, and is also used in many technological applications, such as in liquid crystal displays.

In this class, we simulate an active nematic liquid crystal using [framework].

```python
file: comfit/models/nematic_liquid_crystal.py 
class: NematicLiquidCrystal
```

See the ComFiT Library Reference below for a complete list of class methods and their usage.

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
    <a href="https://comfitlib.com/library_reference/nematic_liquid_crystal/" class="card" style="min-width: 160px; flex: 0 1 calc(100.00% - 10px); margin: 5px;">
        <div style="text-align: center;">
            <strong> ComFiT Library Reference </strong>
        </div>
    </a>
</div>

## Variables and parameters

The primary variables are the symmetric traceless tensor $Q$ and the
velocity field $\mathbf{u}$

```python
nem.Q 
nem.u
```

The NematicLiquidCrystal class takes the same keyword as the BaseSystem class in addition to

| Keyword | Definition | Default value|
|---------|------------|--------------|
| `alpha`  | The activity parameter. Negative is extensile | $-1$ |
| `K`  | Frank elastic constant  | $1$ |
| `A`  | Parameter in front of $\text{Tr}(Q^2)$ in the free-energy | $1$ |
| `B`  | Parameter in front of $\text{Tr}(Q^2)^2$ in the free-energy | $1$ |
| `C`  | Parameter in front of $\text{Tr}(Q^3)$ in the free-energy. 3D only | $0$ |
| `gamma`  | Rotational diffusion | $1$ |
| `Gamma`  | Friction  | $0$ |
| `eta`  | Viscosity | $1$ |

These parameters are discussed in more detail in the model section. 

### Note on the tensor parameters
The $Q$ tensor is given by the nematic director as

$$
Q_{ij} = S (n_i n_j - \frac{1}{d} \delta_{ij})
$$

in $d$ dimensions.
To take advantage of its
symmetric nature we have saved $Q$ as a vector field, which in two and three
dimensions takes the forms

$$
\begin{aligned}
\mathbf{Q} &= [ Q_{xx},Q_{xy} ] \\
\mathbf{Q} &= [ Q_{xx},Q_{xy},Q_{xz},Q_{yy},Q_{yz}]
\end{aligned}
$$

respectivly.
We can translate from tensor indexes to the right value stored in the vector by
using the function

```python
get_sym_tl(self,Q,i,j)
```

This returns the element $Q_{ij}$ of a symmetric and traceless tensor
field. In addition to this we also have the function

```python
get_anti_sym(self,omega,i,j)
```

so that we can optimally store the antisymetric tensors as well. In two
dimensions these only have one independent component, which is stored as
a scalar field,
while in three dimensions it is stored as

$$
\mathbf \Omega = [\Omega_{xy}, \Omega_{xz}, \Omega_{yz}]
$$

In order to calculate the director field $\mathbf n$ and the amount of order $S$ in two dimensions we use that we can map the orderparameter to the complex field $\psi = Q_{xx} +  iQ_{xy} =Se^{2i\theta}/2$, where $\theta$  is the angle of the director field.
In three dimensions we use that $S$ is given by the largest eigenvalue as $S = 3\lambda/2$ with the director being the coresponding eigenvector [^Schimming2022Thesis].
This is taken care of in the function

```python
calc_order_and_director(self)
```

Wich returns `S, n`, where `n` is the director field.
Note that a nematic liquid crystall can be biaxial and given as

$$
Q_{ij} = S (n_i n_j - \frac{1}{3} \delta_{ij}) + P (m_i m_j -l_i l_j)
$$

where $P$ is given by the difference between the smallest eigenvalues and $\mathbf m$ and $\mathbf l$ is the corresponding eigenvectors.

## Model

We model the active nematic using a set of coupled differential
equations, namely the Edvard-Beris equation coupled to the Stokes
equation
[^marchetti2013hydrodynamics] [^genkin2017topological] [^nejad2020memory] [^angheluta2021role]

!!! equation "The Edward-Beris equation (`evolve_nematic`)"
    $$
        \begin{aligned}
            \partial_t Q + \mathbf u\cdot \nabla Q +\Omega Q -Q \Omega &=\gamma^{-1}H,
            \\
            (\Gamma- \eta \nabla^2 )\mathbf u &= -\nabla P + \nabla \cdot \sigma^a(Q) + \nabla \cdot \sigma^p, \\
            \nabla \cdot \mathbf u &= 0.
        \end{aligned}
    $$

Here $2\Omega_{ij} = \partial_i u_j - \partial_j u_i$ is
the vorticity tensor, $P$ is the pressure, $\gamma$ is the rotational friction coefficient, $\sigma^p$ is the passive stress, $\Gamma$ is friction with a substrate, $\eta$ is viscosity and the active stress is given by $\sigma^a = \alpha Q$.
The vorticity tensor is calculated by the
function

```python
calc_vorticity_tensor(self)
```

Note that the velocity has to be updated before this function is called.
The calculation of the pressure and velocity is described furhter down.
Since the active stress is simply proportional to $Q$ we have not included any
function to calculate it, but calculate the force directly with the function

```python
calc_active_force_f(self,Q)
```

The molecular field $H$ is given as

$$H_{ij} =  -\frac{\delta \mathcal{F}}{\delta Q_{ij}} + \frac{\delta_{ij}}{d} \text{Tr}\left(\frac{\delta F}{\delta Q}\right)
$$

The last term is here to make it trace less.
For the free energy we use

$$\mathcal F = \int \left( K |\nabla Q|^2 - \frac{A}{2} \left[ B \text{Tr}(Q^2) -\text{Tr}(Q^2)^2   \right] -\frac{C}{3}\text{Tr}(Q^3) \right),
$$

where it is assumed that there is a single Frank elastic constant $K$.
Here $Q^2 = QQ$ denote a standard matrix multiplication, and similar for $Q^3$.
We therfore have that $\text{Tr}(Q^2)^2 = Q_{kj}Q_{jk}$.
The $\text{Tr}(Q^3)$ term only exists in three dimensons since it is zero for all symetric traceless matrices in two dimensions.
The molecular field is given as

$$
 H_{ij} =  K \nabla^2 Q_{ij} + A(B - 2Q^2_{kk})Q_{ij} +
 \begin{cases}
  0, & \text{dim} = 2 \\
 C Q^2_{ij} - \frac{C}{3}Q^2_{kk} \delta_{ij}, & \text{dim} = 3
\end{cases}
$$

For the passive stress we use
$$\sigma_{ij} = Q_{ik}H_{kj}-H_{ik}Q_{kj} - K (\partial_i Q_{kl})(\partial_jQ_{kl}).$$
Note that we use the convention that the dot product between a vector
and a tensor contracts the last component when calculating the
divergence of this. The first two terms is the asymmetric stress, while
the second term is the Ericksen stress. Terms due to flow allingment and
anisotropic viscosity are not included. The molecular field and the
passive stress  are calculated by the functions

```python
calc_molecular_field(self,Q)
calc_passive_stress_f(self,Q)
```

The linear and non-linear part of the evolution equation for $Q$,
eq. is
given as

$$
\begin{aligned}
\omega(\nabla) &= \frac{K}{\gamma} \nabla^2 +\frac{AB}{\gamma}, \\
N(Q,t) &= - \mathbf u\cdot \nabla Q + Q \Omega -\Omega Q - \frac{2A}{\gamma}Q^2_{kk}Q +\begin{cases}
  0, & \text{dim} = 2 \\
 C Q^2 - \frac{C}{3}Q^2_{kk} I, & \text{dim} = 3
\end{cases}
\end{aligned}
$$

The evolution of this is handled by the function

```python
nem.evolve_nematic(self,number_of_steps,method='ETD2RK')
```

## Disipative dynamics

Note that if we set the velocity field to zero the dynamics become
$$\partial_t Q=  \frac{K}{\gamma} \nabla^2 Q_{ij} +\frac{A}{\gamma}(B - 2Q^2_{kk})Q_{ij}.$$
This is used to relax the initial system before starting the simulation.
The linear and nonlinear part of this equation are

$$
\begin{aligned}
    \omega(\nabla) = \frac{K}{\gamma} \nabla^2 +\frac{AB}{\gamma},  \\
    N(Q) = - \frac{2A}{\gamma}Q^2_{kk}Q +\begin{cases}
  0, & \text{dim} = 2 \\
 C Q^2 - \frac{C}{3}Q^2_{kk} I, & \text{dim} = 3
\end{cases}.
\end{aligned}
$$

An evolver for this dissipative dynamics is included as

```python
nem.evolve_nematic_no_flow(self,number_of_steps,method='ETD2RK')
```

## The velocity field {#sec:nem_vel}

For a given orderparameter $Q$ the velocity field is calculated in
Fourier space using
eq (??).
We start by finding an expression for
the pressure by taking the divergence of this eq. (??) and then using the incompressibility
condition giving $$\nabla^2 P = \nabla \cdot \mathbf F,$$ where
$\mathbf F =  \nabla \cdot \sigma^a(Q) +\nabla \cdot \sigma^p(Q)$ is the
active and passive forces. This is solved in Fourier space as

$$
-k^2  {{P}_{\scriptscriptstyle  f}} =  i\mathbf k \cdot {{\mathbf F}_{\scriptscriptstyle  f}}.
$$

The above equation can be inverted in order to find all the modes of the
pressure except the zero mode, i.e the pressure is determined up to a
constant. We set this constant to zero. Once the pressure is found we
obtain the velocity from

$$
(\Gamma + \eta k^2){{\mathbf u}_{\mathfrak  f}} = - i\mathbf k {{P}_{\mathfrak  f}} + {{F}_{\mathfrak  f}}.
$$

Note that when $\Gamma = 0$ we need to set the zero mode of the velocity
by hand. This is set to zero. The pressure and velocity are
calculated/updated by the two functions

```python
calc_pressure_f(self,F_af,F_pf) 
conf_velocity(self,Q)
```

Note that `calc_pressure_f` only returns the Fourier transform of the
pressure. The function `conf_velocity` updates both the velocity field `self.u`
and its Fourier transform `self.u_f`. 
The arguments `F_af` and `F_pf` are the active and passive forces respectivly.  

## Minimum of the free energy

When starting a simulation it is often interesting to start from a configuration that is the minimum of the free energy pluss some perturbations or with a vortex dipole/fillament.
From the free energy we see that the minimum energy is given by a homogeneous nematic, and it is inedependent of the direction the nematogens are pointing.
Assuming that the unitvector $\mathbf n$ is homogeneous we can rewrite the free energy in terms of the parameter $S$.

### In two dimmensions

the free energy is only given by powers of $\text{Tr}(Q^2)$ which in two dimmensions is $S^2/2$ in terms of $S$.
The free-energy is therfore for a homogeneous two dimentional nematic given as

$$
\mathcal F =  \int \left( - \frac{A}{2} \left[ B \frac{S^2}{2} -\frac{S^4}{4}   \right] \right).
$$

The minimum of this is given as $S =\sqrt{B}$ when $B >0$ and $S = 0$ if $B<0$.

### In three dimensions

In three dimensions we have that $\text{Tr}(Q^2) = 2 S^2/3$ and $\text{Tr}(Q^3)= 2 S^3/9$.
Using this we find that there are a local minima at

$$
S = \frac{1}{8}\frac{C}{A} + \frac{1}{2} \sqrt{\frac{C^2}{16 A^2} + 3 B}
$$

when $B > -3 C^2/(16A^2)$.

## Topological defects and active turbulence

Because of the head-tail symmetry if the nematic director the
topological defects in the nematic phase can have half integer winding
number. We can see this by maping the $Q$ tensor to a complex field.
This is done by writing the nematic director as
$\\mathbf{n} = \cos{\theta} \hat x + \sin{\theta} \hat y$, with
$\hat x /\hat y$ being the unit vectors in $x /y$ direction, and mapping
the $Q$ tensor, see
eq. (??), to the complex field

$$
\psi = Q_{xx} +  iQ_{xy} = \frac{S}{2} e^{2 i\theta}.
$$

Using the same arguments as for the BEC we find that the allowed winding
numbers $$k = \int_C \nabla \theta \cdot d\\mathbf{l} = 2\pi q$$ with
$q$ being a half-integer. The defects of lowest absolute charge is the
$\pm 1/2$ defects, which are depicted below.

![Liquid crystal disclination dipole](img/nematic_liquid_crystal_disclination_dipole.png#only-light)
![Liquid crystal disclination dipole](img/nematic_liquid_crystal_disclination_dipole-colorinverted.png#only-dark)

*Liquid crystal disclination dipole:* The nematic director (head-less vectors) around a defect dipole. The $+1/2$ defect is marked with red, while the $-1/2$ defect is in blue.

For tracing the defect nodes one can use the function

```python
calc_vortex_nodes_nem(self, dt_Q=None,polarization = None)
```

If `dt_Q` is given this finds the defects velocity and if `polarization` is given the polarization of the $+1/2$ defects are
found.
This polarization is given by

$$
\mathbf{e}_+ = \left( \frac{\nabla \cdot Q}{|\nabla \cdot Q|}\right)_{\mathbf{r}= \mathbf{r}_+}
$$

where $\mathbf{r}_+$ is the defects position.
The field $\mathbf{e}_+$ can be found by the function

```python
calc_defect_polarization_field(self)
```

Note that this function does not include the normalization to avoid
division by zero.

## Initial States

A homogeneous nematic with random noise can be implemented with the
function

```python
conf_initial_condition_disordered(self, noise_strength=0.01)  
```

This gives a state where the nematogens are aligned with the $x$-axis.
The noise is in the angle $\theta$. If the activity is high enough this
state will after a while start to spontaneously generate topological
defects. In addition there is possible to insert defect dipoles using
the function

```python
conf_insert_vortex_dipole(self, dipole_vector=None, dipole_position=None) 
```

which works similarly as the one implemented for the BEC. This function
can be used either to initialize a homogeneous state with a dipole, or
it can be used to insert a dipole into an already existing nematic.
In three dimensions one can initialise two disclination lines paralel to the z-axis using the function 

```python
conf_initial_disclination_lines(self, position1=None,position2 = None)
```

This function intialises a wedge defect looking like the two dimensional $+1/2$ defect at `position1` and one 
looking like a $-1/2$ at `position2`. 
The positions are in the xy-plane.
If no positions are given the defects are placed at the positions 

```python
    position1 = [self.xmid+self.size_x/3, self.ymid]
    position2 = [self.xmid - self.size_x / 3, self.ymid]
```

## Spatially varying activity

The activity $\alpha$ is can be spatially varying. This can be used to
make active channels as shown in the following figure.

![Nematic liquid crystal active channel](img/nematic_liquid_crystal_active_channel.png#only-light)
![Nematic liquid crystal active channel](img/nematic_liquid_crystal_active_channel-colorinverted.png#only-dark)

*Nematic liquid crystal active channel:* Illustration of an active channel. `width= 20` and $d = 2$.

This simple channel with the activity $\alpha_0$ inside and $\alpha = 0$
outside is included as the function

```python
conf_active_channel(self,width,d=7)
```

Which sets the activity to
$$\alpha = \alpha_0 \left[1 -1/2 \left(\tanh([x-w/2]/d) -\tanh([x+w/2]/d) \right)\right].$$
$w$ is here the width of the channel, $\alpha_0$ is the activity in the
channel and $d$ is the width of the interface between the channel and
the bulk. More complicated structures can be created if one wish.

## Three dimensions

In three dimensions, the $Q$-tensor can be characterized as

$$
Q_{ij} = S (n_i n_j - \frac{1}{3} \delta_{ij} ) + P (m_i m_j - l_i l_j),
$$

where $(\mathbf n, \mathbf m, \mathbf l )$ is an orthornmal triad.
It is five parameters: $S$, the two defining angles of $\mathbf n$, $P$ and the angle of $\mathbf m$ in the plane orthogonal to $\mathbf n$.
$S$ can always be determined from the highest eigenvalue $\lambda_{\textrm{max}}$ of $Q$ by [^Schimming2022Thesis]

$$
S = \frac{3}{2} \lambda_{\textrm{max}}
$$

## Topological defects

Topological defects in nematic liquid crystals are called disclinations and are characterized the orientation of the rod-like particles having rotated after following a path around the dislocation.
From [^schimming2023kinematics],

$$
D_{\gamma i} = \epsilon_{\gamma \mu \nu} \epsilon_{ikl} \partial_k Q_{\mu \alpha} \partial_l Q_{\nu \alpha}.
$$

We can write this as

$$
D_{\gamma i} = \delta_{\gamma i} ( \partial_k Q_{k\alpha} \partial_l Q_{l\alpha} - \partial_k Q_{l\alpha}\partial_l Q_{k\alpha}) + 2( \partial_\gamma Q_{k\alpha} \partial_k Q_{i\alpha} - \partial_\gamma Q_{i\alpha} \partial_k Q_{k\alpha})
$$

to reduce the number of sums preformed.

In two dimensions, where $\mathbf n = (\cos \theta,\sin \theta)$, we have

$$
Q = S\begin{pmatrix}
\cos \theta \cos \theta - \frac{1}{2} & \cos \theta \sin \theta \\
\cos \theta \sin \theta & \sin \theta \sin \theta - \frac{1}{2}\\
\end{pmatrix}
= \frac{S}{2}
\begin{pmatrix}
\cos (2\theta) &  \sin(2\theta) \\
\sin(2\theta) & - \cos (2\theta)\\
\end{pmatrix},
$$

$$
= \frac{1}{2}
\begin{pmatrix}
\psi_1 &  \psi_2 \\
\psi_2 & - \psi_1\\
\end{pmatrix},
$$

where $\psi_1,\psi_2$ are the components of an $\mathcal D^2$ order parameter.
We get only one component of $D_{\gamma i}$, which is $D_{33}$ which is

$$
D_{33} = \epsilon_{\mu \nu} \epsilon_{kl} \partial_k Q_{\mu \alpha} \partial_l Q_{\nu \alpha}
$$

$$
= \epsilon_{\mu \nu} \epsilon_{kl} \partial_k Q_{\mu 1} \partial_l Q_{\nu 1}
+ \epsilon_{\mu \nu} \epsilon_{kl} \partial_k Q_{\mu 2} \partial_l Q_{\nu 2}
$$

We have $Q_{\mu1} = \frac{1}{2} \psi_\mu$ and $Q_{\mu 2} = \frac{1}{2} \epsilon_{\mu q} \psi_q$, so

$$
D_{33} = \frac{1}{4} \epsilon_{\mu \nu} \epsilon_{kl} (\partial_k \psi_\mu )(\partial_l \psi_\nu)
+ \frac{1}{4} \epsilon_{\mu \nu} \epsilon_{kl} (\partial_k  \epsilon_{\mu q} \psi_q) (\partial_l \epsilon_{\nu r} \psi_r)
$$

And using that

$$
\epsilon_{\mu \nu} \epsilon_{\mu q} \epsilon_{\nu r} = \epsilon_{qr},
$$

we get

$$
D_{33} = \frac{1}{2} \epsilon_{\mu \nu} \epsilon_{kl} (\partial_k \psi_\mu )(\partial_l \psi_\nu).
$$

This is the same determinant as we would get using the coarse grain density of [^skogvoll2023Topological], only with $\psi_0$, so, the disclination density should be

$$
\rho_{\gamma i} = \frac{1}{\pi S_0^2} D_{\gamma i}
$$

This fiel is found by the function 

```python
calc_disclination_density_nematic(self)
```
which returns a tensorfield in three dimensions and a scalar field ($\rho_{33}$) in two. 
Since we have tensor in three dimenstions, the story is more complicated than usual. 
This tensor contains two pieces of information, namely which direction the disclination is pointing, and around which axis $\boldsymbol \Omega$, near the disclination, the rods are rotating.
In that way, it is similar to a dislocation density in a crystal structure, only that it allows for the orientation the "Burgers vector" to be any direction.
It can be written like this [^schimming2023kinematics]

$$
\rho_{\gamma i} = \omega \Omega_\gamma t_{i} ,
$$

where the unit vectors are $\boldsymbol t$ is tangent vector and $\boldsymbol\Omega$ is the rotational vector.
From this, we see that

$$
\omega^2 =|\rho|^2 = \rho_{\gamma i} \rho_{\gamma i} 
$$

so $\omega$ is the quantity we should integrate to find the nodes of the defects. 
The unitvectors $\boldsymbol t$ and $\boldsymbol \Omega$ is found as the eigenvectors of the matrices $\rho^T \rho$ and $\rho \rho^T$ respectivly.
Since the eigenvectors are determined up to a sign one have to make sure that $\boldsymbol t$ is continous along the defect and impose the condition $\text{sign}(\boldsymbol \Omega \cdot \boldsymbol t) = \text{sign}(\text{Tr}(\rho))$.
The $\rho$ tensor field is calculated decomposed into the above mentioned vectors by the function

```python
calc_disclination_density_decoupled(self)
```
which returns $\omega, \Omega, T,$ and $\text{Tr}(\rho)$. 


From Ref.[^schimming2023kinematics], we have

$$
t_i \delta^{(2)}(\mathbf r_{\perp}) = \delta^{(2)}(\mathbf Q_\perp) \Omega_\gamma D_{\gamma i}
$$

replacing the delta function, which we may generalize to

$$
\mathbf \rho = \Omega_{\gamma} \frac{1}{\pi (S_0-P_0)^2} D_{\gamma i}.
$$

### Inserting topological defects

How do we insert topological defects of a given character?

We can generate an initial state of $Q_{ij}$ by writing

$$
Q_{ij} = S_0 \left (\frac{1}{2} n_i n_j - \frac{1}{d} \delta_{ij} \right ),
$$

and then simply impose an orientation field corresponding to an angle field on the $\mathbf n$ fields.

[^Schimming2022Thesis]:Schimming, C. D. (2022). Theoretical and Computational Methods for Mesoscopic Textures in Nematic Liquid Crystals with Anisotropic Elasticity. PhD Thesis. The University of Minnesota. [https://hdl.handle.net/11299/241713](https://hdl.handle.net/11299/241713)
[^marchetti2013hydrodynamics]: Marchetti, M. C., Joanny, J-F., Ramaswamy, S., Liverpool, T. B., Prost, J., and Rao, M. and Simha, R. A. (2013). Hydrodynamics of soft active matter. Reviews of Modern Physics. 85, 3, 1143. [https://doi.org/10.1103/RevModPhys.85.1143](https://doi.org/10.1103/RevModPhys.85.1143)
[^genkin2017topological]: Genkin, M. M., Sokolov, A., Lavrentovich, O. D. and Aranson, I. S. (2017). Topological defects in a living nematic ensnare swimming bacteria. Physical Review X. 7, 1,011029. [https://doi.org/10.1103/PhysRevX.7.011029](https://doi.org/10.1103/PhysRevX.7.011029)
[^nejad2020memory]: Nejad, M. R., Doostmohammadi, A. and Yeomans, J. M. (2021). Memory effects, arches and polar defect ordering at the cross-over from wet to dry active nematics. Soft Matter. 17, 9, 2500-2511. [https://doi.org/10.1039/D0SM01794A](https://doi.org/10.1039/D0SM01794A)
[^angheluta2021role]:Angheluta, L., Chen, Z., Marchetti, M. C. and Bowick, Mark J. (2021). The role of fluid flow in the dynamics of active nematic defects. New Journal of Physics. 23, 3, 033009. [https://doi.org/10.1088/1367-2630/abe8a8](https://doi.org/10.1088/1367-2630/abe8a8)
[^schimming2023kinematics]: Schimming, C. D. and Viñals, J. (2023). Kinematics and dynamics of disclination lines in three-dimensional nematics. Proceedings of the Royal Society A. 479, 2273, 20230042. [https://doi.org/10.1098/rspa.2023.0042](https://doi.org/10.1098/rspa.2023.0042)
[^skogvoll2023Topological]: Skogvoll, V., Rønning, J., Salvalaglio, M., Angheluta, L. (2023). A unified field theory of topological defects and non-linear local excitations. npj Comput Mater, 9, 122. [https://doi.org/10.1038/s41524-023-01077-6](https://doi.org/10.1038/s41524-023-01077-6)

--- End of file: docs\ClassNematicLiquidCrystal.md ---

--- Start of file: docs\ClassPhaseFieldCrystal.md ---
# Class: Phase Field Crystal

In this class, we simulate a crystal using the phase-field crystal methodology. 
The phase-field crystal (PFC) model is a mesoscopic model that describes the dynamics of a crystal.
The model is based on a free energy functional, which is minimized to find the equilibrium state of the system.
The free energy functional is a function of the phase field $\psi$, which is a real-valued field that describes the local density of the crystal.
The PFC model is a powerful tool for studying the dynamics of crystals, and it has been used to study a wide range of phenomena, including the formation of defects, the dynamics of grain boundaries, and the growth of crystals.

```python
file: comfit/models/phase_field_crystal.py 
class: PhaseFieldCrystal
```

See the ComFiT Library Reference below for a complete list of class methods and their usage.

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
    <a href="https://comfitlib.com/library_reference/phase_field_crystal/" class="card" style="min-width: 160px; flex: 0 1 calc(100.00% - 10px); margin: 5px;">
        <div style="text-align: center;">
            <strong> ComFiT Library Reference </strong>
        </div>
    </a>
</div>

## Variables and parameters

The phase field $\psi$.

```python
pfc.psi
```

## Basic model

The PFC methodology is based on postulating a free energy

!!! equation "The PFC free energy"
    $$
    \mathcal F = \int d\boldsymbol{r} \tilde f(\psi, \nabla \psi, ...)
    $$

with the goal of the state that minimizes $\mathcal F$ has a certain symmetry.   
In this documentation, we will present six such models to represent different crystalline structures in 1, 2 and 3 dimensions, all of which are on the form

!!! equation "The PFC free energy density"
    $$
    \tilde f( \psi, \nabla \psi, ...) = \frac{1}{2} (\mathcal L(\nabla) \psi)^2 + \frac{1}{2} \texttt{r} \psi^2  + \frac{1}{3} \texttt t \psi^3 + \frac{1}{4} \texttt v \psi^4,
    $$

where $\mathcal L (\nabla)$ is a gradient operator dependent on the dimension and target symmetry, listed below

|Model| Derivative operator $\mathcal L$|
|-----|---------------------------------|
|1D periodic       |$\mathcal L_1 = (1+\nabla^2)$|
|2D triangular     |$\mathcal L_1 = (1+\nabla^2)$|
|2D square         |$\mathcal L_1 \mathcal L_2 = (1+\nabla^2) (2+\nabla^2)$|
|3D bcc            |$\mathcal L_1 = (1+\nabla^2)$|
|3D fcc            |$\mathcal L_1 \mathcal L_{4/3} = (1+\nabla^2) (4/3+\nabla^2)$|
|3D simple cubic   |$\mathcal L_1 \mathcal L_2 \mathcal L_3 = (1+\nabla^2) (2+\nabla^2) (3+\nabla^2)$|

**Table:** Phase-field crystal models. $\mathcal L_X = (X+\nabla^2)$.

Of particular interest is the PFC chemical potential, given by 

!!! equation "The PFC chemical potential"
    $$
    \tilde \mu_c =
    \frac{\delta \mathcal F}{\delta \psi} =
    \left ( \mathcal L^2 \psi + \texttt r \psi + \texttt t \psi^2 + \texttt v \psi^3 \right )
    $$

The PFC model was introduced inin Ref.[^elderModelingElasticPlastic2004].
The primary field is $\psi$, a real valued field

```python
pfc.psi 
```

## Crystal symmetry

The way in which this field can model a crystalline lattice is by the ground state having that particular symmetry.
For instance, the figure below shows the (real) field $\psi$ for a (a) 2D triangular, and a (b) 2D square lattice.

![PFC symmetries](img/phase_field_crystal_ground_state.png#only-light)
![PFC symmetrie](img/phase_field_crystal_ground_state-colorinverted.png#only-dark)

**Figure:** Ground state of the PFC model for (a) 2D triangular and (b) 2D square lattice.

The crystalline symmetry is described by a Bravais lattice, which consists of vectors that point to peaks on the lattice.
The Fourier transform of a field that a Bravais lattice symmetry will itself have a lattice symmetry, which is called the reciprocal lattice, and is useful to express the field in terms of a Fourier series.

![PFC Bravais and reciprocal lattice vectors](img/phase_field_crystal_bravais_and_reciprocal_lattices.png#only-light)
![PFC Bravais and reciprocal lattice vectors](img/phase_field_crystal_bravais_and_reciprocal_lattices-colorinverted.png#only-dark)

**Figure:** Bravais lattices $\mathcal B$ and their reciprocal lattices $\mathcal R$ for square and triangular symmetry.
In each case, $\{\mathbf a^{(n)}\}_{n=1}^2$ are primitive lattice vectors and $\{ \mathbf q^{(n)}\}_{n=1}^2$ primitive reciprocal lattice vectors (RLVs) that satisfy $\mathbf a^{(n)} \cdot \mathbf q^{(m)} = 2\pi \delta_{nm}$.
Amended and reprinted from Ref. [^skogvollSymmetryTopologyCrystal2023] with permission.

Using the reciprocal lattice, one can express a field which has a Bravais lattice symmetry as a Fourier series in terms of the reciprocal lattice vectors

$$
\psi (\mathbf r) = \sum_{\mathbf q^{(n)} \in \mathcal R} \eta_n e^{\mathfrak i \mathbf q^{(n)} \cdot \mathbf r},
$$

the reciprocal lattice is $d$ dimensions generated by $d$ *primitive* RLVs $\lbrace\boldsymbol{q}^{(n)}\rbrace_{n=1}^d$, satisfying

!!! equation "The primitive BLV-RLV orthogonality relation."
    $$
    \boldsymbol{q}^{(n)} \cdot \boldsymbol{a}^{(m)} = 2\pi \delta_{nm}, \quad n,m \leq d.
    $$


There are infinitely many BLVs and RLVs, but of particular interest are those with the smallest magnitude; which are sometimes named *primary* RLVs/BLVs.
These values are encoded in the instance properties `a,q`, e.g.,

```python
import comfit as cf

pfc = cf.PhaseFieldCrystal2DTriangular(1,1)
print(pfc.a)
print(pfc.q)
>> 
[[3.627, 6.283], [7.255, 0.0], [3.627, -6.283]]
[[0, 1], [0.866, -0.5], [-0.866, -0.5]]
```

---

??? example "Example: The 1D PFC - Crystal symmetry"
    The simplest example of a PFC model is the 1D periodic model, which simply looks like a sine wave.

    ![1D PFC](img/phase_field_crystal_1d_periodic.png#only-light)
    ![1D PFC](img/phase_field_crystal_1d_periodic-colorinverted.png#only-dark)

    The crystal symmetry in this case refers to $\psi$ having a periodicity of $a_0=2\pi$, and so the Bravais lattice is simply $\{ a^{(n)} \} = \{...,-2\pi,-\pi,0,\pi,2\pi,... \}$.
    The primary BLVs are thus given by

    $$
    \mathcal B_{\textrm{per}}^{(1)} = \{ a^{(1)} = 2\pi,~ a^{(-1)} = -2\pi \}
    $$

    The reciprocal lattice is in this case simply $\{ q^{(n)} \} = \{...,q^{(-2)} =-2,~ q^{(-1)} = -1,~ q^{(0)} = 0,~ q^{(1)} = 1,~ q^{(2)} =2,... \}$, the primary set being 
    
    $$
    \mathcal R_{\textrm{per}}^{(1)} = \{ q^{(1)} = 1,~ q^{(-1)} = -1 \}
    $$
    
    and any field with that periodicity can be expressed as a Fourier series in terms of these RLVs by

    $$
    \psi(x) = \psi_0 + A (e^{\mathfrak iq^{(1)} x} + e^{\mathfrak i q^{(-1)} x}) + B (e^{\mathfrak iq^{(2)} x} + e^{\mathfrak i q^{(-2)} x}) + ...,
    $$

Cutting the Fourier series off at the primary RLVs mode is called the *one-mode approximation*

$$
\psi^{\textrm{eq}} \approx \psi_0 + A \sum_{q^{(n)} \in \mathcal R^{(1)}} e^{\mathfrak i q^{(n)} x},
$$

where $\mathcal R_{\textrm{per}}^{(1)}$ as the primary RLVs.

!!! info "Primitive vs primary LV"
    Note the subtle difference between a *primitive* LV and a *primary* LV.
    The primitive BLVs generate the lattice and satisfy the orthogonal relationship with the primitive RLVs which generate the reciprocal lattice.
    There are only $d$ primitive LVs in $d$ dimensions whereas there may be any number of primary lattice vectors.
    For instance, there are six primary BLVs for the triangular lattice and four primary lattice vectors for the 2D square lattice.
    In the following, the primary BLVs and RLVs have been chosen so that the first $d$ primary LVs are primitive LVs that satisfy the orthogonality relation.

Below are all the lattice constants and primary RLVs and BLVs for the models we consider.

=== "1D periodic"

    Lattice constant

    $$
    a_0 = 2\pi
    $$

    Primary RLVs

    $$
    \mathcal R_{\textrm{per}}^{(1)} =
    \left \lbrace
    \begin{array}{l}
        q^{(1)} = 1  \\
        q^{(-1)}= - q^{(1)}
    \end{array}
    \right \rbrace
    $$

    Primary BLVs

    $$
    \mathcal B_{\textrm{per}}^{(1)} =
    \left \lbrace
    \begin{array}{l}
        a^{(1)} = a_0  \\
        a^{(-1)} = -\mathbf a^{(1)}
    \end{array}
    \right \rbrace
    $$

=== "2D Triangular"

    Lattice constant

    $$
    a_0 = \frac{4\pi}{\sqrt 3}
    $$

    Primary RLVs

    $$
    \mathcal R_{\textrm{tri}}^{(1)} = {
    \left \lbrace
    \begin{array}{l}
        \mathbf q^{(1)} = (\sqrt 3/2,-1/2)  \\
        \mathbf q^{(2)} = (0,1) \\
        \mathbf q^{(3)} = (-\sqrt 3/2,-1/2) \\
        \mathbf q^{(-n)} = - \mathbf q^{(n)}|_{n=1,2,3} \\
    \end{array}
    \right \rbrace
    }
    $$

    Primary BLVs

    $$
    \mathcal B_{\textrm{tri}}^{(1)} = {
    \left \lbrace
    \begin{array}{l}
        \mathbf a^{(1)} = a_0(1,0)  \\
        \mathbf a^{(2)} = a_0(1/2,\sqrt 3/2) \\
        \mathbf a^{(3)} = a_0(1/2,-\sqrt 3/2) \\
        \mathbf a^{(-n)}=-\mathbf a^{(n)}|_{n=1,2,3}  \\
    \end{array}
    \right \rbrace }
    $$

=== "2D square"

    Lattice constant
    $$
    a_0 = 2\pi
    $$

    Primary RLVs

    $$
    \mathcal B_{\textrm{sq}}^{(1)} =
    \left \lbrace
    \begin{array}{l}
        \mathbf a^{(1)} = a_0(1,0)  \\
        \mathbf a^{(2)} = a_0(0,1)  \\
        \mathbf a^{(-1)},\mathbf a^{(-2)}
    \end{array}
    \right \rbrace
    $$

    Primary Bravais Lattice vectors

    $$
    \mathcal R_{\textrm{sq}}^{(1)} = {
    \left \lbrace
    \begin{array}{l}
        \mathbf q^{(1)} = (1,0)  \\
        \mathbf q^{(2)} = (0,1) \\
        \mathbf q^{(-n)} = - \mathbf q^{(n)} |_{n=1,2} \\
    \end{array}
    \right \rbrace}
    $$

    $$
    \mathcal R_{\textrm{sq}}^{(2)} =
    \left \lbrace
    \begin{array}{l}
        \mathbf q^{(3)} = (1,-1)  \\
        \mathbf q^{(4)} = (1,1) \\
        \mathbf q^{(-n)} = - \mathbf q^{(n)} |_{n=3,4} \\
    \end{array}
    \right \rbrace
    $$

=== "3D body-centered cubic"

    Lattice constant

    $$
    a_0 = 2\pi \sqrt {2}
    $$

    Primary BLVs

    $$
    \mathcal B_{\textrm{bcc}}^{(1)} =
    {
    \left \lbrace
    \begin{array}{l}
        \mathbf a^{(1)} = a_0(-1,1,1)/2  \\
        \mathbf a^{(2)} = a_0(1,-1,1)/2 \\
        \mathbf a^{(3)} = a_0(1,1,-1)/2\\
        \mathbf a^{(4)} = a_0(1,1,1)/2\\
        \mathbf a^{(-n)}=-\mathbf a^{(n)}|_{n=1,...,4} \\
    \end{array}
    \right \rbrace
    }
    $$

    Primary RLVs

    $$
    \mathcal R_{\textrm{bcc}}^{(1)} =
    {
    \left \lbrace
    \begin{array}{l}
        \mathbf q^{(1)} = (0,1,1)/\sqrt 2  \\
        \mathbf q^{(2)} = (1,0,1)/\sqrt 2 \\
        \mathbf q^{(3)} = (1,1,0)/\sqrt 2\\
        \mathbf q^{(4)} = (0,-1,1)/\sqrt 2\\
        \mathbf q^{(5)} = (-1,0,1)/\sqrt 2\\
        \mathbf q^{(6)} = (-1,1,0)/\sqrt 2\\
        \mathbf q^{(-n)} = - \mathbf q^{(n)}|_{n=1,...6} \\
    \end{array}
    \right \rbrace
    }
    $$

=== "3D face-centered cubic"

    Lattice constant

    $$
    a_0 = 2\pi \sqrt 3
    $$

    Primary BLVs

    $$
    \mathcal B_{\textrm{fcc}}^{(1)} =
    {
    \left \lbrace
    \begin{array}{l}
        \mathbf a^{(1)} = a_0(0,1,1)/2  \\
        \mathbf a^{(2)} = a_0(1,0,1)/2 \\
        \mathbf a^{(3)} = a_0(1,1,0)/2\\
        \mathbf a^{(4)} = a_0(0,-1,1)/2\\
        \mathbf a^{(5)} = a_0(-1,0,1)/2\\
        \mathbf a^{(6)} = a_0(-1,1,0)/2\\
        \mathbf a^{(-n)}=-\mathbf a^{(n)}|_{n=1,...,6} \\
    \end{array}
    \right \rbrace
    }
    $$

    Primary RLVs

    $$
    \mathcal R_{\textrm{fcc}}^{(1)} =
    {
    \left \lbrace
    \begin{array}{l}
        \mathbf q^{(1)} = (-1,1,1)/\sqrt 3  \\
        \mathbf q^{(2)} = (1,-1,1)/\sqrt 3 \\
        \mathbf q^{(3)} = (1,1,-1)/\sqrt 3\\
        \mathbf q^{(4)} = (1,1,1)/\sqrt 3\\
        \mathbf q^{(-n)} = - \mathbf q^{(n)}|_{n=1,...,4}\\
    \end{array}
    \right \rbrace
    }
    $$

    $$
    \mathcal R_{\textrm{fcc}}^{(4/3)} =
    {
    \left \lbrace
    \begin{array}{l}
        \mathbf q^{(5)} = (2,0,0)/\sqrt 3  \\
        \mathbf q^{(6)} = (0,2,0)/\sqrt 3 \\
        \mathbf q^{(7)} = (0,0,2)/\sqrt 3\\
        \mathbf q^{(-n)} = - \mathbf q^{(n)} |_{n=5,6,7} \\
    \end{array}
    \right \rbrace
    }
    $$

=== "3D simple cubic"

    Lattice constant

    $$
    a_0 = 2\pi
    $$

    Primary BLVs

    $$
    \mathcal B_{\textrm{sc}}^{(1)} =
    {
    \left \lbrace
    \begin{array}{l}
        \mathbf a^{(1)} = a_0(1,0,0)  \\
        \mathbf a^{(2)} = a_0(0,1,0) \\
        \mathbf a^{(3)} = a_0(0,0,1)\\
        \mathbf a^{(-n)} = - \mathbf a^{(n)}|_{n=1,2,3} \\
    \end{array}
    \right \rbrace
    }
    $$

    Primary RLVs

    $$
    \mathcal R_{\textrm{sc}}^{(1)} =
    {
    \left \lbrace
    \begin{array}{l}
        \mathbf q^{(1)} = (1,0,0)  \\
        \mathbf q^{(2)} = (0,1,0) \\
        \mathbf q^{(3)} = (0,0,1)\\
        \mathbf q^{(-n)} = - \mathbf q^{(n)} |_{n=1,2,3}\\
    \end{array}
    \right \rbrace
    }
    $$

    $$
    \mathcal R_{\textrm{sc}}^{(2)} =
    {
    \left \lbrace
    \begin{array}{l}
        \mathbf q^{(4)} = (0,1,1)  \\
        \mathbf q^{(5)} = (1,0,1) \\
        \mathbf q^{(6)} = (1,1,0)\\
        \mathbf q^{(7)} = (0,-1,1)  \\
        \mathbf q^{(8)} = (-1,0,1) \\
        \mathbf q^{(9)} = (-1,1,0)\\
        \mathbf q^{(-n)} = - \mathbf q^{(n)}|_{n=4,...,9} \\\\
    \end{array}
    \right \rbrace
    }
    $$

    $$\mathcal R_{\textrm{sc}}^{(3)} =
    {
    \left \lbrace
    \begin{array}{l}
        \mathbf q^{(10)} = (-1,1,1)  \\
        \mathbf q^{(11)} = (1,-1,1) \\
        \mathbf q^{(12)} = (1,1,-1)\\
        \mathbf q^{(13)} = (1,1,1)\\
        \mathbf q^{(-n)} = - \mathbf q^{(n)}|_{n=10,...,13} \\
    \end{array}
    \right \rbrace
    }
    $$

## The ground state 

To find the ground state of a PFC, one inserts a particular mode approximation into the free energy density, average over a unit cell ([coarse-grain](ClassBaseSystem.md)) and minimizes it with respect to the amplitudes.

??? example "Example: The 1D PFC - Ground state"
    To find the ground state of the 1D PFC, we assume that we can express the field in the one-mode approximation, i.e.,

    $$
    \psi^{\textrm{eq}}(x) = \psi_0 + A (e^{\mathfrak i q x} + e^{\mathfrak i q x}),
    $$

    where $q$ is, for now, an arbitrary wave vector which we will show to be the primary RLV of the lattice. 
    We want to insert this into the free energy density $\tilde f$ and integrate over a unit cell (UC), which in this case is simply $[0,2\pi]$
    
    $$
    \frac{1}{2\pi} \mathcal F_{UC} =  \frac{1}{2\pi} \int_0^{2\pi} \tilde f(\psi^{\textrm{eq}}) dx \equiv \langle \tilde f(\psi^{\textrm{eq}}) \rangle_{UC} = \frac{1}{2} \langle (\mathcal L {\psi^{\textrm{eq}}})^2 \rangle_{UC} + \frac{1}{2} \texttt{r} \langle {\psi^{\textrm{eq}}}^2 \rangle_{UC} + \frac{1}{4} \langle {\psi^{\textrm{eq}}}^4 \rangle_{UC}
    $$
    
    To insert this into the free energy density, we need to calculate some auxiliary quantities.

    $$
    \mathcal L \psi^{\textrm{eq}} = (1+\nabla^2) \psi^{\textrm{eq}} = \psi_0 + (1-q^2) A (e^{\mathfrak i q x} + e^{\mathfrak i q x})
    $$ 

    so 

    $$
    \langle (\mathcal L \psi^{\textrm{eq}})^2 \rangle_{UC} = \langle (\psi_0 + (1-q^2) A (e^{\mathfrak i q x} + e^{\mathfrak i q x})(\psi_0 + (1-q^2) A (e^{\mathfrak i q x} + e^{\mathfrak i q x})) \rangle_{UC}
    $$

    Now, to calculate this, we need to make use of a condition of resonance, which is that under the coarse-graining operation, terms with periodicity average to zero[^skogvollSymmetryTopologyCrystal2023].
    So we get 

    $$
    \langle (\mathcal L \psi^{\textrm{eq}})^2 \rangle_{UC} = \psi_0^2 + 2 A^2 (1-q^2)^2
    $$

    Similarly, the other terms give

    $$
    \langle {\psi^{\textrm{eq}}}^2 \rangle_{UC} = \psi_0^2 + 2 A^2
    $$

    $$
    \langle {\psi^{\textrm{eq}}}^3 \rangle_{UC} = \psi_0^3 + 6 \psi_0 A^2
    $$

    $$
    \langle {\psi^{\textrm{eq}}}^4 \rangle_{UC} = \psi_0^4 + 12 \psi_0^2 A^2 + 6 A^4
    $$

    which gives 

    $$
    \mathcal F_{UC} = 2\pi \left( \frac{1}{2} (\psi_0^2 + 2 A^2 (1-q^2)^2)  + \frac{1}{2} \texttt{r} (\psi_0^2 + 2 A^2) + \frac{1}{3} \texttt t (\psi_0^3 + 6 \psi_0 A^2) + \frac{1}{4} \texttt v (\psi_0^4 + 12 \psi_0^2 A^2 + 6 A^4) \right )
    $$

    First of all, we see that the equilibrium value must have $q=1$, since the free energy is minimized by this choice.
    Now, if the PFC is evolving according to conservative dynamics $\partial_t \psi = \nabla^2 (\delta \mathcal F/\delta \psi)$ (which is the standard PFC evolution equation as explained further down in the document), the average value $\psi_0$ will be conserved and therefore considered a simulation constant. 
    In this case, we find the equilibrium value of $A$, by differentiating wrt. $A$ and setting to zero.

    $$
    \partial_A \mathcal F_{UC} =  2 \texttt{r} A + 4 \texttt t \psi_0 A + 6 \texttt v \psi_0^2 A + 6\texttt v A^3 = 0,
    $$
    
    which gives $A=0$ or

    $$
     \texttt{r} + 2 \texttt t \psi_0 + 3 \texttt v \psi_0^2 + 3 \texttt v A^2 = 0,
    $$

    $$
    A^2 = \frac{1}{3\texttt v} (-\texttt{r}  - 2 \texttt t \psi_0 - 3\texttt v \psi_0^2) 
    $$

    $$
    A = \pm \frac{1}{\sqrt{3\texttt v}} \sqrt{- \texttt{r} - 2 \texttt t \psi_0 - 3 \psi_0^2}
    $$

    The sign does not matter in the case of the 1D PFC, since it will only affect the global sign of the amplitude, flipping the cosine wave.
    In higher dimensions, however, it requires more subtle treatment, and typically, one inserts both solutions into the free energy $\mathcal F_{UC}$ to see which is lower

    If instead, we are evolving the PFC under not conserved dynamics $\partial_t \psi = - \delta \mathcal F/\delta \psi$, also the zero mode $\psi_0$ will reach an equilibrium value.
    In this case, then, we need to solve the system of equations given by

    $$
    \left \lbrace
            \begin{array}{lrl}
            \partial_{\psi_0} \mathcal F_{UC} = 0: & \psi_0 + \texttt r \psi_0 + \texttt t \psi_0^2 + 2 \texttt t A^2 + \texttt v \psi_0^3 + 6\texttt v \psi_0 A^2 &=0 \\
            \partial_{A} \mathcal F_{UC} = 0: &  \texttt{r} + 2 \texttt t \psi_0 + 3 \texttt v \psi_0^2 + 3 \texttt v A^2 &= 0\\
            \end{array}
    \right \rbrace
    $$

    

The `pfc` instance will be initialized with a list called `eta0`, which consists of the equilibrium values of the amplitudes to begin with.

=== "1D periodic"

    Default resolution:

    Default model parameters $(r,\psi_0)$: $(-0.3,-0.3)$

    Free energy per unit cell ([calculation document](https://github.com/vidarsko/ComFiT/blob/main/docs/calculations/phase_field_crystal_1D_periodic_equilibrium_amplitudes.nb)):

    $$
    \mathcal F_{UC} = \frac{1}{2} \psi_0^2 + \frac{1}{2} \texttt{r} (\psi_0^2 + 2 A^2) + \frac{1}{3} \texttt t (\psi_0^3 + 6 \psi_0 A^2) + \frac{1}{4} \texttt v (\psi_0^4 + 12 \psi_0^2 A^2 + 6 A^4)
    $$

    Equilibrium amplitude  (conserved)

    $$
    \partial_{A} \mathcal F_{UC} = 0: \quad A =\pm \frac{1}{\sqrt {3\texttt v}} \sqrt{ -\texttt r - 2 \texttt t \psi_0 - 3 \texttt v \psi_0^2}
    $$

    Equilibrium amplitude equations (unconserved)

    $$
    \left \lbrace
            \begin{array}{lrl}
            \partial_{\psi_0} \mathcal F_{UC} = 0: & 2 A^2 (\texttt t + 3 \texttt v \psi_0) + \psi_0 (1 + \texttt r + \texttt t \psi_0 + \texttt v \psi_0^2) &=0 \\
            \partial_{A} \mathcal F_{UC} = 0: & \texttt r + 3 A^2 \texttt v + \psi_0 (2 \texttt t + 3 \texttt v \psi_0)  &= 0\\
            \end{array}
    \right \rbrace
    $$

    <!-- Verified by calculation above (Vidar 21.03.24) -->

=== "2D triangular"

    Default resolution: $[7,12]^{-1}a_0$

    Default model parameters $(r,\psi_0)$: $(-0.3,-0.3)$

    Free energy per unit cell ([calculation document.](https://github.com/vidarsko/ComFiT/blob/main/docs/calculations/phase_field_crystal_2D_triangular_equilibrium_amplitudes.nb)):

    $$
    \mathcal F_{UC} = \frac{\pi^2}{3\sqrt 3} \left (270 A^4 \texttt v + 48 A^3 (\texttt t + 3 \texttt v \psi_0) + \psi_0^2 (6 + 6 \texttt r + 4 \texttt t \psi_0 + 3 \texttt v \psi_0^2) + 36 A^2 (\texttt r + \psi_0 (2 \texttt t + 3 \texttt v \psi_0))\right)
    $$

    Equilibrium amplitude equations (conserved)

    $$
    \left \lbrace \partial_{A} \mathcal F_{UC} = 0: A=0 ~ \textrm{or} ~ \quad  A= \frac{1}{15\texttt v} \left ( -\texttt t - 3 \texttt v \psi_0 \pm \sqrt{ \texttt t^2 - 15 \texttt r \texttt v - 24 \texttt t \texttt v \psi_0 - 36 \texttt v^2 \psi_0^2} \right ) \right \rbrace
    $$

    Equilibrium amplitude equations (unconserved) 

    $$
    \left \lbrace
            \begin{array}{lrl}
            \partial_{\psi_0} \mathcal F_{UC} = 0: & 12 A^3 \texttt v + 6 A^2 (\texttt t + 3 \texttt v \psi_0) + \psi_0 (1 + \texttt r + \texttt t \psi_0 + \texttt v \psi_0^2) &=0 \\
            \partial_{A} \mathcal F_{UC} = 0: & A(\texttt r + 15 A^2 \texttt v + 2 A (\texttt t + 3 \texttt v \psi_0) + \psi_0 (2 \texttt t + 3 \texttt v \psi_0))  &= 0\\
            \end{array}
    \right \rbrace
    $$

    <!-- Verified against the previous version of the documentation. (Vidar 21.03.24) -->

=== "2D square"

    Default resolution: $[7,7]^{-1}a_0$

    Default model parameters $(\texttt r,\psi_0)$: $(-0.3,-0.3)$

    Free energy per unit cell ([calculation document](https://github.com/vidarsko/ComFiT/blob/main/docs/calculations/phase_field_crystal_2D_square_equilibrium_amplitudes.nb)):

    $$
    \mathcal F_{UC} = \frac{\pi^2}{3} (108 A^4 \texttt v + 108 B^4 \texttt v + \psi_0^2 (24 + 6 \texttt r + 4 \texttt t \psi_0 + 3 \texttt v \psi_0^2) + 24 B^2 (\texttt r + \psi_0 (2 \texttt t + 3 \texttt v \psi_0)) + 24 A^2 (\texttt r + 18 B^2 \texttt v + 4 B (t + 3 \texttt v \psi_0) + \psi_0 (2 \texttt t + 3 \texttt v \psi_0)))
    $$    

    Equilibrium amplitude equations

    $$
    \left \lbrace
            \begin{array}{lrl}
            \partial_{\psi_0} \mathcal F_{UC} = 0: & 4 B^2 (\texttt t + 3 \texttt v \psi_0) + \psi_0 (4 + \texttt r + \texttt t \psi_0 + \texttt v \psi_0^2) + 4 A^2 (\texttt t + 3 \texttt v (2 B + \psi_0)) &= 0 \\
            \partial_{A} \mathcal F_{UC} = 0: & A (\texttt r + 9 A^2 \texttt v + 18 B^2 \texttt v + 2 \texttt t \psi_0 + 3 \texttt v \psi_0^2 + 4 B (\texttt t + 3 \texttt v \psi_0)) &= 0 \\
            \partial_{B} \mathcal F_{UC} = 0: & 9 B^3 \texttt v + 2 A^2 (t + 3 \texttt v \psi_0) + B (\texttt r + 18 A^2 \texttt v + 2 \texttt \texttt t \psi_0 + 3 \texttt v \psi_0^2) &= 0\\
            \end{array}
    \right \rbrace
    $$

    <!-- Verified against the previous version of the documentation. (Vidar 21.03.24) -->

=== "3D body-centered cubic"

    Default resolution: $[7,7,7]^{-1}a_0$

    Default model parameters $(\texttt r,\psi_0)$: $(-0.3,-0.325)$

    Free energy per unit cell ([calculation document](https://github.com/vidarsko/ComFiT/blob/main/docs/calculations/phase_field_crystal_3D_bcc_equilibrium_amplitudes.nb)):

    $$
    \mathcal F_{UC} = \frac{4 \sqrt 2 \pi^3}{3} \left (1620 A^4 \texttt v + 192 A^3 (t + 3 \texttt v \psi_0) + \psi_0^2 (6 + 6 \texttt r + 4 t \psi_0 + 3 \texttt v \psi_0^2) + 72 A^2 (\texttt r + \psi_0 (2 t + 3 \texttt v \psi_0)) \right )
    $$

    Equilibrium amplitude (conserved)

    $$
    \left \lbrace \partial_{A} \mathcal F_{UC} = 0:  A=0 ~ \textrm{or} ~ \quad A = \frac{1}{45\texttt v} \left ( -2 \texttt t - 6 \texttt v \psi_0 \pm \sqrt{
    4 \texttt t^2 - 45 \texttt r \texttt v - 66 \texttt t \texttt v \psi_0 - 99 \texttt v^2 \psi_0^2} \right) \right \rbrace
    $$

    Equilibrium amplitude equations (unconserved)

    $$
    \left \lbrace
            \begin{array}{lrl}
            \partial_{\psi_0} \mathcal F_{UC} = 0: & 48 A^3 \texttt v + 12 A^2 (\texttt t + 3 \texttt v \psi_0) + \psi_0 (1 + \texttt r + \texttt t \psi_0 + \texttt v \psi_0^2) &=0 \\
            \partial_{A} \mathcal F_{UC} = 0: & A (\texttt r + 45 A^2 \texttt v + 4 A (\texttt t + 3 \texttt v \psi_0) + \psi_0 (2 \texttt t + 3 \texttt v \psi_0)) &= 0\\
            \end{array}
    \right \rbrace
    $$

    <!-- Verified against the previous version of the documentation. (Vidar 21.03.24) -->

=== "3D face-centered cubic"

    Default resolution: $[11,11,11]^{-1}a_0$

    Default model parameters $(\texttt r,\psi_0)$: $(-0.3,-0.325)$

    Free energy per unit cell ([calculation document](https://github.com/vidarsko/ComFiT/blob/main/docs/calculations/phase_field_crystal_3D_fcc_equilibrium_amplitudes.nb)):

    $$
    \mathcal F_{UC} = \frac{2 \pi^3}{\sqrt 3} (1944 A^4 \texttt v + 810 B^4 \texttt v + \psi_0^2 (32 + 18 \texttt r + 12 \texttt t \psi_0 + 9 \texttt v \psi_0^2) + 108 B^2 (r + \psi_0 (2 \texttt t + 3 \texttt v \psi_0)) + 144 A^2 (\texttt r + 36 B^2 \texttt v + 6 B (t + 3 \texttt v \psi_0) + \psi_0 (2 \texttt t + 3 \texttt v \psi_0)))
    $$

    Equilibrium amplitude equations 

    $$
    \left \lbrace
            \begin{array}{lrl}
            \partial_{\psi_0} \mathcal F_{UC} = 0: & 54 B^2 (t + 3 \texttt v \psi_0) + \psi_0 (16 + 9 \texttt r + 9 t \psi_0 + 9 \texttt v \psi_0^2) + 72 A^2 (t + 3 \texttt v (3 B + \psi_0)) &= 0 \\
            \partial_{A} \mathcal F_{UC} = 0: & A (\texttt r + 27 A^2 \texttt v + 36 B^2 \texttt v + 2 t \psi_0 + 3 \texttt v \psi_0^2 + 6 B (t + 3 \texttt v \psi_0)) &= 0 \\
            \partial_{B} \mathcal F_{UC} = 0: & 15 B^3 \texttt v + 4 A^2 (t + 3 \texttt v \psi_0) + B (\texttt r + 48 A^2 \texttt v + 2 t \psi_0 + 3 \texttt v \psi_0^2) &= 0\\
            \end{array}
    \right \rbrace
    $$

    <!-- Verified against the previous version of the documentation. (Vidar 21.03.24) -->

=== "3D simple cubic"

    Default resolution: $[5,5,5]^{-1}a_0$

    Default model parameters $(\texttt r,\psi_0)$: $(-0.3,-0.325)$

    Free energy per unit cell ([calculation document](https://github.com/vidarsko/ComFiT/blob/main/docs/calculations/phase_field_crystal_3D_simple_cubic_equilibrium_amplitudes.nb)):

    $$
    \mathcal F_{UC} = \frac{2\pi^3}{3} \left (48 C^2 \texttt r + 270 A^4 \texttt v + 1620 B^4 \texttt v + 576 A^3 C \texttt v + 648 C^4 \texttt v + 96 C^2 \texttt t \psi_0 + 6 (36 + \texttt r + 24 C^2 \texttt v) \psi_0^2 + 4 \texttt t \psi_0^3 + 3 \texttt v \psi_0^4 + 192 B^3 (\texttt t + 3 \texttt v \psi_0) + 576 A B C (t + 3 \texttt v (3 B + \psi_0)) + 36 A^2 (\texttt r + 96 B^2 \texttt v + 36 C^2 \texttt v + 2 \texttt t \psi_0 + 3 \texttt v \psi_0^2 + 8 B (\texttt t + 3 \texttt v \psi_0)) + 72 B^2 (r + 54 C^2 \texttt v + \psi_0 (2 \texttt t + 3 \texttt v \psi_0)) \right )
    $$

    Equilibrium amplitude equations:

    $$
    \left \lbrace
            \begin{array}{lrl}
            \partial_{\psi_0} \mathcal F_{UC} = 0: & 8 C^2 \texttt t + 48 B^3 \texttt v + 144 A B C \texttt v + 36 \psi_0 + \texttt r \psi_0 + 24 C^2 \texttt v \psi_0 + \texttt t \psi_0^2 + \texttt v \psi_0^3 + 12 B^2 (t + 3 \texttt v \psi_0) + 6 A^2 (t + 3 \texttt v (4 B + \psi_0)) &= 0 \\
            \partial_{A} \mathcal F_{UC} = 0: & 15 A^3 \texttt v + 24 A^2 C \texttt v + 8 B C (t + 3 \texttt v (3 B + \psi_0)) + A (\texttt r + 96 B^2 \texttt v + 36 C^2 \texttt v + 2 \texttt t \psi_0 + 3 \texttt v \psi_0^2 + 8 B (t + 3 \texttt v \psi_0)) &= 0 \\
            \partial_{B} \mathcal F_{UC} = 0: & 45 B^3 \texttt v + 4 B^2 (t + 3 \texttt v \psi_0) + 2 A (A + 2 C) (t + 3 \texttt v \psi_0) + B (\texttt r + 48 A^2 \texttt v + 72 A C \texttt v + 54 C^2 \texttt v + 2 \texttt t \psi_0 + 3 \texttt v \psi_0^2) &= 0\\
            \partial_{C} \mathcal F_{UC} = 0: & 27 C^3 \texttt v + C (\texttt r + 27 A^2 \texttt v + 81 B^2 \texttt v + 2 \texttt t \psi_0 + 3 \texttt v \psi_0^2) + 6 A (A^2 \texttt v + 9 B^2 \texttt v + B (t + 3 \texttt v \psi_0)) &= 0\\
            \end{array}
    \right \rbrace
    $$

    <!-- Verified against the previous version of the documentation. (Vidar 21.03.24) -->

We refer to these amplitudes $A,B,C$ as *proto amplitudes* and they are calculated by the functions `calc_proto_amplitudes_conserved` (by default) and `calc_proto_amplitudes_unconserved` in the `pfc` class.
The proto amplitudes are saved in the `pfc` instance as `eta0`.
The function `calc_free_energy_from_proto_amplitudes` calculates the free energy $\mathcal F_{UC}$ from the proto amplitudes, including $\psi_0$.

### Straining the ground state to equilibrium
While the q-vector given above and the proto amplitudes are good approximations to the ground state, they are not exact.
In fact, if the PFC is initialized with these values, it will experience a slight residual stress [^punkeEvaluationElasticField2023].
To account for this, when initializing a PFC, the code will automatically strain the field to find the optimal value of $q_0$, which is typically a few percent off the primary RLV.
This is done numerically by simulating a $1\times 1$ unit cell and using the function `self.conf_strain_to_equilibrium` in the `pfc` class.

In this function, we apply the following distortion

$$
\mathcal u_{ij} = \epsilon \delta_{ij}
$$



Given the equilibrium configuration, we can find more accurate estimates for the equilibrium amplitudes, but evolving the PFC for a few time steps and calculating the amplitudes from the demodulation of the field with the primary RLVs.
This is done in the `calc_strained_amplitudes` function in the `pfc` class, which also calculates new values for the elastic constants (see below).

## The amplitude approximation - deviations from the ground state

So far, we have only looked at the equilibrium state of the PFC, which has a specific symmetry, and the few-mode approximations that can be used to describe the PFC in this state.
For small deviations from the equilibrium state, like in the presence of few dislocations and small strains, we can use the amplitude approximation, in which we assume that the field can be written as

!!! equation "The amplitude approximation"

    $$
    \psi \approx \bar \psi + \sum_{\mathbf q^{(n)} \in \mathcal R^{(1)}} \eta_n(\mathbf r) e^{\mathfrak i \mathbf q^{(n)} \cdot \mathbf r},
    $$

where $\eta_n$ are slowly varying complex fields.
These fields can be found by demodulating the field $\psi$ with the primary RLVs, i.e.,

!!! equation "Demodulation"

    $$
    \eta_n = \langle \psi e^{- \mathfrak i \boldsymbol{q}^{(n)} \cdot \boldsymbol{r}} \rangle
    $$

The figure below shows an example of the evolution of the PFC for a triangular lattice and the corresponding amplitude fields.

![](img/phase_field_crystal_amplitude_approximation.png#only-light)
![](img/phase_field_crystal_amplitude_approximation-colorinverted.png#only-dark)

**Figure:** Snapshots of an example evolution of the 2D triangular PFC model at (top row) $t=0$ and (bottom row) $t=600$. Parameters used were $(r,\psi_0) = (-0.3,-0.3)$. The columns show the demodulated fields $\bar \psi$ and $\{ \eta_n \}_{n=1}^{3}$, where the complex fields are shown by their phase $\theta_n$ and brightness corresponding to the magnitude $|\eta_n|$. Taken from Ref. [^skogvollSymmetryTopologyCrystal2023] with permission.


## Elasticity

This quantity is the Poisson ratio, under some conditions. I think. 
To be fixed. 
$$\nu = \frac{\lambda}{(d-1)\lambda + 2\mu + \gamma}$$

Elastic constants are saved in these quantities

```python
pfc.el_mu
pfc.el_lambda
pfc.el_gamma
pfc.el_nu
```

### Stress tensor
The equations for calculating the stress tensor are found in Ref.
[^skogvollStressOrderedSystems2021], but we list them below, together
wtih the elastic constants for each of the models.
The stress tensor $h_{ij}$ and its associated elastic constants interms of amplitudes ($A,B,C$) of the mode expansion for different PFCmodels. Here, $\mathcal L_X = X+\nabla^2$. The elastic constants canbe expressed in Voigt notation by $C_{11} = \lambda+2\mu+\gamma$,$C_{12} = \lambda$, $C_{44}=\mu$.

??? example "Example: The 1D PFC - Stress tensor"
    In order to derive the stress tensor, suppose we have a state of the PFC given by $\psi$.
    We may deform this state in a mass-conserving fashion by a displacement field $u$ (which is a scalar field in one dimension) as follows

    $$
    \psi' = \psi - \partial_x (\psi u)
    $$

    We insert this into the expression for the free energy giving a new free energy $\mathcal F'$.

    $$
    \mathcal F' = \int dx \left ( \frac{1}{2} ((1+\partial_x^2) \psi'))^2 + \frac{1}{2} \texttt r \psi'^2 + \frac{1}{3} \texttt t \psi'^3 + \frac{1}{4} \texttt v \psi'^4 \right ) 
    $$

    If we take $u$ to be an infinitesimal exploratory field, we can expand in $u$, which gives

    $$
    \mathcal F' = \mathcal F[\psi] - \int dx (1+\partial_x^2)\psi (1+\partial_x^2) \partial_x (\psi u_x) - \texttt r \psi \partial_x (\psi u_x) - \texttt t \psi^2 \partial_x (\psi u_x) - \texttt v \psi^3 \partial_x (\psi u_x) 
    $$
    
    $$
    = \mathcal F[\psi] - \int dx (1+\partial_x^2)\psi (1+\partial_x^2) \partial_x (\psi u_x) + (\tilde \mu_c - \mathcal L^2) \partial_x (\psi u_x) 
    $$

$$
\nabla \cdot  h  =
\left \langle \tilde \mu_c \nabla \psi - \nabla \tilde f \right \rangle
$$

=== "1D periodic"

    Stress tensor

    Elastic constants

    $$
    \lambda =
    $$

    $$
    \mu =
    $$

    $$
    \gamma =
    $$

=== "2D triangular"

    Stress tensor

    $$
    h_{ij} = -2\left \langle (\mathcal L_1 \psi) \partial_{ij} \psi \right \rangle
    $$

    Elastic constants

    $$\lambda = 3A^2$$

    $$\mu = 3A^2$$

    $$\gamma = 0$$

=== "2D square"

    Stress tensor
    $$ h_{ij} = -2\left \langle (\mathcal L_1 \mathcal L_2 \psi)(\mathcal L_1 + \mathcal L_2) \partial_{ij} \psi \right \rangle$$

    Elastic constants

    $$\lambda = 16B^2$$

    $$\mu = 16B^2$$

    $$\gamma = 8A^2-32B^2$$

=== "3D body-centered cubic"

    Stress tensor

    $$h_{ij} = -2\left \langle (\mathcal L_1 \psi) \partial_{ij} \psi \right \rangle$$

    Elastic constants

    $$\lambda = 4 A^2$$

    $$\mu = 4 A^2$$

    $$\gamma = -4A^2$$

=== "3D face-centered cubic"

    Stress tensor

    $$h_{ij} = -2\left \langle (\mathcal L_1 \mathcal L_{\frac 4 3} \psi)(\mathcal L_1 + \mathcal L_{\frac 4 3}) \partial_{ij} \psi \right \rangle$$

    Elastic constants

    $$\lambda = \frac{32}{81} A^2$$

    $$\mu = \frac{32}{81} A^2$$

    $$\gamma = \frac{32}{81} (2B^2 - A^2)$$

=== "3D simple cubic"

    Stress tensor

    $$h_{ij} = -2\left \langle (\mathcal L_1 \mathcal L_2 \mathcal L_3 \psi)(\mathcal L_2 \mathcal L_3 + \mathcal L_1 \mathcal L_3 + \mathcal L_1 \mathcal L_2) \partial_{ij} \psi \right \rangle$$

    Elastic constants

    $$\lambda = 16 B^2 + 128 C^2$$

    $$\mu = 16 B^2 + 128 C^2$$

    $$\gamma = 32 A^2 - 16 B^2 - 256 C^2$$

As one sees, the expressions for the stress tensor all on the format

$$
h_{ij} = -2\left \langle (\mathcal L \psi)(\mathcal L_{\sum} \partial_{ij} \psi \right \rangle,
$$

where $\mathcal L$ is as defined previously (as the product $\mathcal L_1 ...$), and $\mathcal L_{\sum}$ is a particular sum of $\mathcal L_i$ operators.
$\mathcal L$ is calculated (in Fourier space) by the function `calc_L_f`, and the $\mathcal L_{\sum}$ is calculated by the function `calc_L_sum_f` in the `pfc` class.
The stress tensor is then calculated by the function `calc_microscopic_stress_tensor` in the `pfc` class. 

### Equilibrium elastic constants

As mentioned above, the equilbrium state of the PFC is not exactly given by $q_0=1$, and the proto amplitudes are not exact.
However, in the process of deriving the equilibrium amplitudes after straining, we can also use the $1\times 1$ unit cell to calculate the elastic constants.
This is done numerically by deforming the unit cell and calculating the increase in the elastic energy. 
To illustrate this, consider a distortion of pure shear, i.e., 

$$
\mathfrak u = \begin{pmatrix} 0 & \epsilon & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix}.
$$

The corresponding strain is given by

$$
\varepsilon = \begin{pmatrix} 0 & \frac 1 2 \epsilon & 0 \\ \frac 1 2 \epsilon & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix}.
$$

Under this deformation, the elastic energy 

$$
F_{el} = \frac{1}{2} \mathcal C_{ijkl} \varepsilon_{ij} \varepsilon_{kl}
$$

is given by

$$
F_{el} =  \mu e_{ij} e_{ij} = \frac{1}{2} \mu \epsilon^2.
$$

We can apply the distortion $\mathfrak u$ with the function `conf_apply_distortion` in the `pfc` class.
The result of this procedure for a $4\times 4$ square PFC is shown in the figure below

![](img/phase_field_crystal_strain_elastic_constants.png#only-light)
![](img/phase_field_crystal_strain_elastic_constants-colorinverted.png#only-dark)

**Figure:** The elastic constants of a 2D square PFC model as a function of the strain $\epsilon$ in the $x$-direction. The fit shows the numerical fit of the elastic constant $\mu$ to the applied strain, showing excellent agreement.

While this works for the elastic constant $\mu$, the full elastic free energy is determined by three elastic constants, $\lambda$, $\mu$, and $\gamma$

$$
F_{el} = F_{el} = \frac{1}{2} \lambda (\varepsilon_{kk})^2 + \mu \varepsilon_{ij} \varepsilon_{ij} + \frac{1}{2} \gamma (\varepsilon_{11}^2 + \varepsilon_{22}^2 + \varepsilon_{33}^2).
$$

To find these, we apply a series of deformations to the unit cell and use `scipy.optimize.curve_fit` to fit the elastic energy to the applied strain.
This is done in the `calc_strained_amplitudes` and set to the `pfc` instance as `el_lambda`, `el_mu`, and `el_gamma` upon initialization. 
The values are also printed to the terminal at initialization.

The expression for the elastic constants in terms of the proto amplitudes were derived by inserting the amplitude approximation into the expression for the stress tensor.
It is interesting to see that elastic constants obtained by using the equilibrium values of amplitudes match the elastic constants obtained by straining the PFC to equilibrium and performing the fit. 



### Strains

In order to calculate the strain of a PFC configuration, we follow a generalized procedure as that outlined in Ref. [^skogvollSymmetryTopologyCrystal2023]. 
The ground state of the PFC can be written as 

$$
\psi = \psi_0 + \eta_1 \sum_{\mathbf q^{(n)} \in \mathcal R^{(1)}} e^{i \mathbf q^{(n)} \cdot \mathbf r} +  \eta_2 \sum_{\mathbf q^{(n)} \in \mathcal R^{(2)}} e^{i \mathbf q^{(n)} \cdot \mathbf r} +...,
$$

where $\mathcal R^{(n)}$ is the nth closest modes, i.e., the full reciprocal lattice can be written as 

$$
\mathcal R = \{\mathbf 0 \} \cup \left (\cup_{n=1}^\infty \mathcal R^{(n)} \right)
$$

We define the following quantity

$$
\Phi = N_1q_1^2\eta_1^2 + N_2q_2^2\eta_2^2 + ... 
= \sum_{\mathbf q^{(n)} \in \mathcal R} \eta_{n,0}^2|\mathbf q^{(n)}|^2
$$

Assuming that the mode-approximations hold, we can calculate $\Phi$ from the equilibrium amplitudes which are stored in the `PhaseFieldCrystal` instance, which is done routinely in the initialization of the class and stored in `pfc.Phi`.
Consider now the structure function of the equilibrium state

$$
\mathcal S_{ij} 
= \langle \partial_i \psi \partial_j \psi\rangle
$$

$$
= \eta_1^2 \sum_{\mathbf q^{(n)} \in \mathcal R^{(1)}} q^{(n)}_iq^{(n)}_j +  \eta_2^2 \sum_{\mathbf q^{(n)} \in \mathcal R^{(2)}} q_i^{(n)}q_j^{(n)}+...
$$

$$
= \eta_1^2 \frac{N_1 q_1^2}{d} \delta_{ij} + \eta_2^2 \frac{N_2 q_2^2}{d} \delta_{ij}+... 
$$

$$
= \frac{\Phi}{d}\delta_{ij}
$$

The strain of the phase-field crystal can be calculated using the following formula
The strain of the phase-field crystal can be calculated using the following formula[^skogvollSymmetryTopologyCrystal2023]

$$
\varepsilon_{ij} = \frac{1}{2}\delta_{ij} - \frac{d}{2\Phi} \mathcal S_{ij},
$$

where $\mathcal S = \langle \nabla \psi \nabla \psi \rangle$ is called the structure function [^skogvollHydrodynamicPhaseField2022]
and is implemented in the `calc_strain_tensor` method of the `PhaseFieldCrystal` class.
It should be noted that there is some residual strain due to the equilibrium periodicity of the lattice not matching exactly the periodicity of the simulation domain [^punkeEvaluationElasticField2023].
It is therefore often useful to subtract the mean value for visualization purposes.

```python
strain = pfc.calc_strain_tensor()
strain = strain - np.mean(strain, axis=0)
```



## Dislocations

The Burgers vector is defined by

!!! equation "Burgers vector definition"

    $$
    \oint_{\partial \mathcal M} d \boldsymbol{u} = -\boldsymbol{b}.
    $$

The minus sign in this convention reflects the fact that we consider the
Burgers vector to be the disconnection error from the *ending* point to
the *starting* point, when going an oriented path around the
dislocation,

![Burgers vector definition](img/phase_field_crystal_burgers_vector_definition.png#only-light)
![Burgers vector definition](img/phase_field_crystal_burgers_vector_definition-colorinverted.png#only-dark)

*Burgers vector definition:* (a) The one-body density of a crystalline solid containing an edge dislocation in a 2D square lattice (superimposed), (b) a 3D simple cubic lattice with an edge dislocation ($\mathbf b \perp \mathbf t$), and (c) a 3D simple cubic lattice with a screw dislocation ($\mathbf b \parallel \mathbf t)$.
In all cases, a circulation (green) that is right-handed with respect to the tangent vector $\mathbf t$, i.e., following a path around the dislocation, gives rise to a connection error: the Burgers vector $\mathbf b$.  
Reprinted from Ref. [^skogvollSymmetryTopologyCrystal2023] with permission.

In three dimensions, the path defining the dislocation is given by the
direction of the dislocation line tangent $\boldsymbol{t}$. Multiplying
this equation by the reciprocal lattice vector $-\boldsymbol{q}^{(n)}$,
we get

$$\oint_{\partial \mathcal M} d (-\boldsymbol{q}^{(n)} \cdot \boldsymbol{u}) = (\boldsymbol{b} \cdot \boldsymbol{q}^{(n)}) \equiv 2\pi s_n,$$

where $s_n$ is the charge associated with the Burgers vector $\boldsymbol{b}$

!!! equation "Dislocation charge"

    $$
    s_n = \frac{1}{2\pi} \boldsymbol{b} \cdot \boldsymbol{q}^{(n)}.
    $$

Using the primary BLVs we get the charges summarized below

=== "2D triangular"

|Burgers vector $\mathbf b$ | $s_1$ | $s_2$ | $s_3$ |
|------------------------| ----- | ----- | ----- |
|$\mathbf a^{(1)} = a_0 (1,0)$               | $\color{red} 1$ | $0$ | $\color{blue}-1$|
|$\mathbf a^{(2)} = a_0 (1/2,\sqrt 3/2)$     | $0$ | $\color{red} 1$ | $\color{blue}-1$|
|$\mathbf a^{(3)} = a_0 (1/2,-\sqrt 3/2)$    | $\color{red} 1$ | $\color{blue}-1$ | $0$|

=== "2D square"

|Burgers vector $\mathbf b$ | $s_1$ | $s_2$ | | $s_3$ | $s_4$ |
|------------------------| ----- | ----- |-| ----- | ----- |
|$\mathbf a^{(1)} = a_0 (1,0)$ | $\color{red} 1$ | $0$ | |$\color{red} 1$ | $\color{red} 1$|
|$\mathbf a^{(2)} = a_0(0,1)$ | $0$ | $\color{red} 1$ | | $\color{blue}-1$ | $\color{red} 1$|

=== "3D body-centered cubic"

|Burgers vector $\mathbf b$ | $s_1$ | $s_2$ | $s_3$ | $s_4$ | $s_5$ | $s_6$ |
|------------------------| ----- | ----- | ----- | ----- | ----- | ----- |
|$\mathbf a^{(1)} = a_0/2 (-1,1,1)$ | $\color{red} 1$ | $0$ | $0$ | $0$ | $\color{red} 1$ | $\color{red} 1$|
|$\mathbf a^{(2)} = a_0/2 (1,-1,1)$ | $0$ | $\color{red} 1$ | $0$ | $\color{red} 1$ | $0$ | $\color{blue}-1$|
|$\mathbf a^{(3)} = a_0/2 (1,1,-1)$ | $0$ | $0$ | $\color{red} 1$ | $\color{blue}-1$ | $\color{blue}-1$ | $0$|
|$\mathbf a^{(4)} = a_0/2 (1,1,1)$ | $\color{red} 1$ | $\color{red} 1$ | $\color{red} 1$ | $0$ | $0$ | $0$|

=== "3D face-centered cubic"

|Burgers vector $\mathbf b$ | $s_1$ | $s_2$ | $s_3$ | $s_4$ | | $s_5$ | $s_6$ | $s_7$ |
|------------------------| ----- | ----- | ----- | ----- |-| ----- | ----- | ----- |
|$\mathbf a^{(1)} = a_0/2(0,1,1)$ | $\color{red} 1$ | $0$ | $0$ | $\color{red} 1$ | | $0$ | $\color{red} 1$ | $\color{red} 1$|
|$\mathbf a^{(2)} = a_0/2(1,0,1)$ | $0$ | $\color{red} 1$ | $0$ | $\color{red} 1$ | | $\color{red} 1$ | $0$ | $\color{red} 1$|
|$\mathbf a^{(3)} = a_0/2 (1,1,0)$ | $0$ | $0$ | $\color{red} 1$ | $\color{red} 1$ | | $\color{red} 1$ | $\color{red} 1$ | $0$|
|$\mathbf a^{(4)} = a_0/2(0,-1,1)$ | $0$ | $\color{red} 1$ | $\color{blue}-1$ | $0$ | |$0$ | $\color{blue}-1$ | $\color{red} 1$|
|$\mathbf a^{(5)} = a_0/2 (-1,0,1)$ | $\color{red} 1$ | $0$ | $\color{blue}-1$ | $0$ | |$\color{blue}-1$ | $0$ | $\color{red} 1$|
|$\mathbf a^{(6)} = a_0/2(-1,1,0)$ | $\color{red} 1$ | $\color{blue}-1$ | $0$ | $0$ | |$\color{blue}-1$| $\color{red} 1$ | $0$|

=== "3D simple cubic"

| Burgers vector $\mathbf b$ | $s_1$ | $s_2$ | $s_3$ | | $s_4$ | $s_5$ | $s_6$ | $s_7$ | $s_8$ | $s_9$ | | $s_{10}$  | $s_{11}$ | $s_{12}$ | $s_{13}$ |
|-------------------------|-------|-------|-------|-|-------|-------|-------|-------|-------|-------|-| ----------|----------|----------|----------|
|$\mathbf a^{(1)} = a_0(1,0,0)$ | $\color{red} 1$ | $0$ | $0$ | |$0$ | $\color{red} 1$ | $\color{red} 1$ | $0$ |  $\color{blue}-1$ | $\color{blue}-1$ | |$\color{blue}-1$ | $\color{red} 1$ | $\color{red} 1$ | $\color{red} 1$|
|$\mathbf a^{(2)} = a_0 (0,1,0)$ | $0$ | $\color{red} 1$ | $0$ | |$\color{red} 1$ | $0$ | $\color{red} 1$ | $\color{blue}-1$ |  $0$ | $\color{red} 1$ | | $\color{red} 1$ | $\color{blue}-1$ | $\color{red} 1$ | $\color{red} 1$|
|$\mathbf a^{(3)} = a_0(0,0,1)$ | $0$ | $0$ | $\color{red} 1$ | | $\color{red} 1$ | $\color{red} 1$ | $0$ | $\color{red} 1$ |  $\color{red} 1$ | $0$ | | $\color{red} 1$ | $\color{red} 1$ | $\color{blue}-1$ | $\color{red} 1$|

## The dislocation density tensor

Given a PFC configuration, the dislocation density tensor may be
calculated as [^skogvollPhaseFieldCrystal2022]

!!! equation "The dislocation density tensor"
    
    $$
    \alpha_{ij} = \frac{2d}{N\eta_0^2} \sum_{n=1}^N D_i^{(n)} q_j^{(n)}
    = \frac{2 \pi d}{N} \sum_{n=1}^N \rho_i^{(n)} q_j^{(n)}
    $$

where
$\boldsymbol{D}^{(n)}$ is calculated from
$\boldsymbol{\psi }= (\Re(\eta_n), \Im(\eta_n))$ from the $N$ primary
reciprocal lattice vectors $\boldsymbol{q}^{(n)}$ and

$$
\rho^{(n)}_i = \frac{1}{\pi \eta_0^2} D^{(n)}_i
$$

In the language of
this


## Equations of motion

### Conserved evolution

The basic equation motion presented in Ref.
[^elderModelingElasticPlastic2004] can be derived by postulating a
simple mechanism for free energy minimzation under the constraint of
mass conservation.

!!! equation "The PFC evolution equation (`evolve_PFC`)"

    $$
    \partial_t \psi = \nabla^2 \tilde \mu_c,
    $$

The linear part $\mathcal L^2  + \texttt r$ of the chemical potential (not multiplied by psi) is calculated by 

```python
pfc.calc_chemical_potential_linear_part_f()
```

The PFC chemical potential

which gives

$$
{{\omega }_{\mathfrak f}}= -\boldsymbol{k}^2 (\texttt r + {{\mathcal L}_{\mathfrak f}}^2)
$$

$$
N = \nabla^2 (\psi^3)
$$

### Unconserved dynamics

!!! equation "The unconserved PFC evolution equation (`evolve_PFC_unconserved`)"

    $$
    \partial_t \psi = - \tilde \mu_c
    $$  


### Evolution at mechanical equilibrium


!!! equation "The PFC evolution at mechanical equilibrium (`evolve_PFC_mechanical_equilibrium`)"


    Step 1:

    $$\psi(t+\Delta t) = \textrm{Integrate($\Delta t$):} (\partial_t \psi)$$

    Step 2:

    $$\psi(t + \Delta t, \boldsymbol{r}) \leftarrow \psi(t + \Delta t, \boldsymbol{r} - \boldsymbol{u}^\delta),$$

where $\boldsymbol{u}^\delta$ is the solution to

$$
\partial_{j} \mathcal C_{ijkl} \partial_l u_k = - g^\psi_i,
$$

where

$$
g^\psi_i = -\partial_j \mathfrak h_{ij}^\psi,
$$

and the elastic constants tensor $\mathcal C$ is given by

$$
\mathcal C_{ijkl} = \lambda \delta_{ij}\delta_{kl} + 2\mu \delta_{k(i} \delta_{j)l} + \gamma \delta_{ijkl}.
$$

This equation is solved in Fourier space by

$$
{u}_{\mathfrak f ~ i}^\delta = G_{\mathfrak f ~ ij} g_{\mathfrak f ~ j}^\psi,
$$

where the Greens function $G_{\mathfrak f ~ ij}$ is given in Ref. [^dederichsElasticGreenFunction1969] as

$$
{G_{\mathfrak f ~ij}} (\mathbf k) =\frac{1}{\mathbf k^2}\left ( \frac{\delta_{ij}}{\mu + \gamma \kappa_{(i)}^2} - \frac{\kappa_i \kappa_j}{(\mu +  \gamma \kappa_{(i)}^2 )(\mu +  \gamma \kappa_{(j)}^2 )} \frac{\mu+\lambda}{1+ \sum_{l=1}^3 \frac{\mu + \lambda}{\mu+\gamma \kappa_l^2} \kappa_l^2 }\right ),
$$

with $\boldsymbol \kappa = \mathbf k/|\mathbf k|$ there is no implicit summation over indices $(i),(j)$.  
By defining $k_3=0$, this equation is also valid for the triangular and square symmetry in two dimensions.

Note that due to the asymmetry of the elastic constants, this method can only be used for small deviations of the lattice orientation.

### Hydrodynamic PFC evolution

In Ref. [^skogvollHydrodynamicPhaseField2022], a hydrodynamic approach
was derived. 
A simplified two-parameter model was proposed


!!! equation "The hydrodynamic PFC model (`evolve_PFC_hydrodynamic`)"

    $$
    \partial_t \psi = \nabla^2 \tilde \mu_c - \boldsymbol{v} \cdot \nabla \psi
    $$

    $$
    \partial_t \boldsymbol{v} = \frac{1}{\rho_0} (\nabla \cdot  h + \Gamma_S \nabla^2 \boldsymbol{v} + \boldsymbol{f}^{\textrm(ext)})
    $$

We insert for $\tilde \mu_c$ and write it in matrix form to emphasize the
linear and non-linear parts

$$
\partial_t
\begin{pmatrix}  \psi \\  v_1 \\  v_2 \\  v_3
\end{pmatrix} =
\begin{pmatrix}  \nabla^2 (r + \mathcal L^2) \psi \\  \frac{1}{\rho_0}\Gamma_S \nabla^2 v_1 \\  \frac{1}{\rho_0}\Gamma_S \nabla^2 v_2 \\  \frac{1}{\rho_0}\Gamma_S \nabla^2 v_3
\end{pmatrix} +
\begin{pmatrix}  \nabla^2 ( \psi^3)  - \boldsymbol{v} \cdot \nabla \psi \\  \frac{1}{\rho_0} \left (  \left \langle \tilde \mu_c \partial_x \psi - \partial_x \tilde f \right \rangle  + f_x^{(ext)}\right )\\  \frac{1}{\rho_0} \left (  \left \langle \tilde \mu_c \partial_y \psi - \partial_y \tilde f \right \rangle  + f_y^{(ext)}\right ) \\  \frac{1}{\rho_0} \left (  \left \langle \tilde \mu_c \partial_z \psi - \partial_z \tilde f \right \rangle  +  f_z^{(ext)} \right )
\end{pmatrix}
$$

## Configurations

The PFC class has a number of methods for generating initial conditions.

### Dislocation dipoles and loops

The simplest setup for the PFC is to insert a dislocation dipole or dislocation loop.

### Polycrystal configurations

To set a polycrystal configuration, one typically calculates the PFC from a set of rotated reciprocal lattices.
This is done in the `calc_PFC_from_amplitudes` method, using the `rotation` keyword argument.
Then, one constructs a field with the desired orientation by setting the field in the regions corresponding to the rotated reciprocal lattice to the rotated field.
In order to avoid numerical artifacts with the interface, it is recommended to smooth the interface by evolving the PFC for a few time steps according to classical PFC dynamics.

??? example "Example: Creating a circular inclusion"
    To create a circular inclusion in 2 dimensions, you can run the following code.

    ```python
    import comfit as cf
    import numpy as np
    import matplotlib.pyplot as plt
    import scipy as sp

    pfc = cf.PhaseFieldCrystal2DSquare(30,30)
    pfc.dt=0.05

    # This creates a standard orientation of the crystal
    pfc.conf_PFC_from_amplitudes()

    # Create the rotated field
    psi_rotated = pfc.calc_PFC_from_amplitudes(rotation=np.pi/6)

    # Specify the region centered at the mid position with radius 6 a0.
    inclusion_region = pfc.calc_region_disk(pfc.rmid, 6*pfc.a0)

    # Set the rotated field in the inclusion region
    pfc.psi[inclusion_region] = psi_rotated[inclusion_region]
    pfc.psi_f = sp.fft.fftn(pfc.psi)

    #Smooth the interface
    tau = 10
    pfc.evolve_PFC(round(tau/pfc.dt)) 

    pfc.plot_field(pfc.psi)
    plt.show()
    ```

    This will produce the following image.

    ![Circular inclusion in a PFC](img/phase_field_crystal_circular_inclusion.png#only-light)
    ![Circular inclusion in a PFC](img/phase_field_crystal_circular_inclusion-colorinverted.png#only-dark)

The class comes with a variety of pre-configured setups for polycrystalline configurations, which are created using the `conf_create_polycrystal` method.
This function takes as argument a keyword argument `type`, which is a string specifying the type of polycrystal to create.
The available types are

=== "`circular`"
    This creates a circular inclusion valid in 2 and 3 dimensions. 
    The type opens for two additional keywords:

    - `radius` which specifies the radius of the inclusion (default `self.size_min/4`).

    - `position` which specifies the position of the center of the inclusion (default `self.rmid`).
    
    - `rotation` a float specifying the rotation of the inclusion wrt. the z-axis (default `np.pi/6`).

    If initialized in 3 dimensions, the inclusion will be a cylinder extended along the z-axis.

    ![Circular inclusion in a PFC](img/phase_field_crystal_circular_inclusion.png#only-light)
    ![Circular inclusion in a PFC](img/phase_field_crystal_circular_inclusion-colorinverted.png#only-dark)


=== "`four_grain`"
    This creates a four-grain configuration valid in 2 and 3 dimensions.
    The type allows for no additional keywords.

    If initialized in 3 dimensions, the four grains will be extended along the z-axis.

    ![Four grain configuration in a PFC](img/phase_field_crystal_four_grain_inclusion.png#only-light)
    ![Four grain configuration in a PFC](img/phase_field_crystal_four_grain_inclusion-colorinverted.png#only-dark)


### Calculating the orientation field

In many simulations with polycrystals, it is useful to calculate the orientation field.
This is a vector field that points in the direction of the crystal orientation.
To calculate the orientation field, we rely on the amplitude approximation of the PFC field, demodulate with respect to different orientations and estimate the orientation based on the magnitude of these amplitudes.

Consider the 2D case for a triangular PFC, in which the rotation angle $\theta$ is given with respect to the z-axis.
For a given rotation, we can demodulate the PFC with respect to a triplet of reciprocal lattice vectors.

$$
\{ R(\theta) \mathbf q^{(n)} \},
$$

where $R(\theta)$ is the rotation matrix and $\mathbf q^{(n)}$ is the primary reciprocal lattice vector of the unrotated PFC.
This will give three amplitudes $\eta_n$, the combined magnitude   

$$
\Phi^2 = \sum_{n=1}^3 |\eta_n|^2
$$

of which will indicate to which degree the orientation of the PFC aligns with that direction.


## Straining the PFC

In some simulations, it is useful to prescribe a strain to the PFC.
This is done by updating the grid on which the PFC is defined.

In one dimension, the only strain that can be applied is a compression or expansion of the grid, given by $\mathfrak e_{xx}$.

In this case, these variables are updated according to 

```python 
self.k[0] = self.k[0]/(1+strain)
self.dif[0] = self.dif[0]/(1+strain)
self.x = self.x*(1+strain)
```

In two dimensions, the strain tensor is given by three components $\mathfrak e_{xx}$, $\mathfrak e_{xy}$, and $\mathfrak e_{yy}$.
In principles, these components cannot be set arbitrarily, since the components must satisfy the compatibilit equations

$$
\partial_y^2 \mathfrak e_{xx} + \partial_x^2 \mathfrak e_{yy} = 2 \partial_x \partial_y \mathfrak e_{xy}.
$$

In this case, however, we are limiting ourselves to a constant strain, in which case the compatibility equation is automatically satisfied and the deformation is given by

$$
\begin{array}{ll}
u_x = \mathfrak e_{xx} x + \mathfrak e_{xy} y, \\
u_y = \mathfrak e_{xy} x + \mathfrak e_{yy} y.
\end{array}
$$

The coordinates will transform according to

$$
\begin{array}{ll}
x \rightarrow x + u_x, \\
y \rightarrow y + u_y.
\end{array}
$$

which is is given by 

$$
\begin{array}{ll}
x' \\
y'
\end{array}
=
\begin{array}{ll}
1 + \mathfrak e_{xx} & \mathfrak e_{xy} \\
\mathfrak e_{xy} & 1 + \mathfrak e_{yy} \\
\end{array}
\begin{array}{ll}
x \\
y
\end{array}
$$

We save the components of the strain matrix $T = \begin{array}{ll}
1 + \mathfrak e_{xx} & \mathfrak e_{xy} \\
\mathfrak e_{xy} & 1 + \mathfrak e_{yy} \\
\end{array}
\begin{array}{ll}$ in the `distortion_matrix` variable.
The wave vectors are updated according to

$$
\begin{array}{ll}
k_x' \\
k_y'
\end{array}
=
T^{-1}
\begin{array}{ll}
k_x \\
k_y
\end{array}
$$

!!! note "The grid components"

    Normally, the grid components `x`, `y`, and `z` are set as 1-dimensional arrays, and the same with `self.k[0]`, `self.k[1]`, and `self.k[2]`.
    When applying an external strain, however, the grid components will vary in the different directions and will become multi-dimensional arrays.
    This increases the memory usage of the simulation. 

The strain thus contains three components `strain[0]`, `strain[1]`, and `strain[2]`.

, and the grid is updated according to

```python

```


[^elderModelingElasticPlastic2004]: Elder, K. R., & Grant, M. (2004). Modeling elastic and plastic deformations in nonequilibrium processing using phase field crystals. Physical Review E, 70(5), 051605. [https://doi.org/10.1103/PhysRevE.70.051605](https://doi.org/10.1103/PhysRevE.70.051605)
[^skogvollSymmetryTopologyCrystal2023]: Skogvoll, V. (2023). Symmetry, topology, and crystal deformations: a phase-field crystal approach. Doctoral Thesis. University of Oslo [https://www.duo.uio.no/handle/10852/102731](https://www.duo.uio.no/handle/10852/102731)
[^emdadiRevisitingPhaseDiagrams2016]: Emdadi, A., Asle Z., Mohsen and Asadi, E. (2016). Revisiting Phase Diagrams of Two-Mode Phase-Field Crystal Models. Computational Materials Science. 123, 139-147. [https://doi.org/10.1016/j.commatsci.2016.06.018](https://doi.org/10.1016/j.commatsci.2016.06.018)
[^wuPhasefieldcrystalModelFcc2010]:Wu, K. A., Adland, A. and Karma, A. (2010). Phase-Field-Crystal Model for Fcc Ordering. Physical Review E. 81, 6, 06101. [https://doi.org/10.1103/PhysRevE.81.061601](https://doi.org/10.1103/PhysRevE.81.061601)
[^wuPhasefieldCrystalModeling2007]: Wu, K-A. and Karma, A. (2007). Phase-Field Crystal Modeling of Equilibrium Bcc-Liquid Interfaces. Physical Review B. 76, 18, 184107. [https://doi.org/10.1103/PhysRevB.76.184107](https://doi.org/10.1103/PhysRevB.76.184107)
[^skogvollStressOrderedSystems2021]: Skogvoll, V., Skaugen, A. and Angheluta, L. (2021). Stress in Ordered Systems: Ginzburg-Landau-type Density Field Theory. Physical Review B. 103, 22, 224107. [https://doi.org/10.1103/PhysRevB.103.224107](https://doi.org/10.1103/PhysRevB.103.224107)
[^skogvollHydrodynamicPhaseField2022]: Skogvoll, V., Salvalaglio, M. and Angheluta, L. (2022). Hydrodynamic Phase Field Crystal Approach to Interfaces, Dislocations and Multi-Grain Networks. Modelling and Simulation in Materials Science and Engineering. [https://doi.org/10.1088/1361-651X/ac9493](https://doi.org/10.1088/1361-651X/ac9493)
[^skogvollPhaseFieldCrystal2022]: Skogvoll, V., Angheluta, L., Skaugen, A., Salvalaglio, M. and Viñals, J. (2022). A Phase Field Crystal Theory of the Kinematics of Dislocation Lines. Journal of the Mechanics and Physics of Solids. 166, 104932. [https://doi.org/10.1016/j.jmps.2022.104932](https://doi.org/10.1016/j.jmps.2022.104932)
[^dederichsElasticGreenFunction1969]: Dederichs, P. H. and Leibfried, G. (1969). Elastic Green's function for anisotropic cubic crystals. Physical Review. 188, 3, 1175. [https://doi.org/10.1103/PhysRev.188.1175](https://doi.org/10.1103/PhysRev.188.1175)
[^punkeEvaluationElasticField2023]: Punke, M., Skogvoll, V., & Salvalaglio, M. (2023). Evaluation of the elastic field in phase-field crystal simulations. PAMM, 23(3), e202300213. [https://doi.org/10.1002/pamm.202300213](https://doi.org/10.1002/pamm.202300213)

--- End of file: docs\ClassPhaseFieldCrystal.md ---

--- Start of file: docs\ClassQuantumMechanics.md ---
# Class: Quantum Mechanics

Quantum mechanics is one of the most classic examples of field theories in physics.
The Schrödinger equation is a partial differential equation that describes how the quantum state of a physical system changes over time.

In this class, we simulate quantum mechanics through the evolution of the Schrödinger equation.

```python
file: comfit/models/quantum_mechanics.py 
class: QuantumMechanics
```

See the ComFiT Library Reference below for a complete list of class methods and their usage.

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
    <a href="https://comfitlib.com/library_reference/quantum_mechanics/" class="card" style="min-width: 160px; flex: 0 1 calc(100.00% - 10px); margin: 5px;">
        <div style="text-align: center;">
            <strong> ComFiT Library Reference </strong>
        </div>
    </a>
</div>




## Example

The following example demonstrates how to set up a 1D quantum system with a Gaussian wave packet and a potential barrier.
It runs smoothly with `comfit 1.8.4`.

```python
import comfit as cf
import matplotlib.pyplot as plt
import numpy as np

# Set up a 1D quantum system
qm = cf.QuantumMechanics(1, xlim=[-50,50], xRes=1001, dt=0.1)

# Initialize a Gaussian wavepacket at x=5 with velocity=1
qm.conf_initial_condition_Gaussian(position=5, width=1, initial_velocity=1)

# Add a potential barrier (optional)
qm.V_ext = 0.5 * (qm.x > 10) * (qm.x < 12)  # Barrier from x=10 to 12

height = np.max(abs(qm.psi))  # Get the maximum value of the wavefunction

# Optional: Animate it
for n in range(61):
    qm.evolve_schrodinger(5)
    fig, ax = qm.plot_complex_field(qm.psi)
    qm.plot_field(qm.V_ext, fig=fig, ax=ax, ylim=[0,height], xlim=[0,20])
    qm.plot_save(fig, n)
cf.tool_make_animation_gif(n)  # Creates animation.gif
```

![Quantum Mechanics](../img/quantum_mechanics_barrier_reflection.gif#only-light)
![Quantum Mechanics](../img/quantum_mechanics_barrier_reflection-colorinverted.gif#only-dark)

## The Schrödinger equation

Evolving according to the Schrödinger equation with electron mass

$$
\mathfrak i \hbar \partial_t \psi = \left [-\frac{\hbar^2}{2m_e} \nabla^2 + V \right ] \psi.
$$

Dividing by the Hartree energy $E_h = \frac{\hbar^2}{m_e a_0^2}$

$$
\mathfrak i \frac{\hbar}{E_h} \partial_t \psi = \frac{1}{E_h}\left [-\frac{\hbar^2}{2m_e} \nabla^2 + V \right ] \psi.
$$

When expressing time in units of $\frac{\hbar}{E_h}$, potential energy in units of $E_h$ and length squared in units of 

$$
\frac{\hbar^2}{E_h m_e} = \frac{\hbar^2}{\frac{\hbar^2}{m_e a_0^2} m_e} = a_0^2,
$$

we get the Schrödinger equation in its dimensionless form

$$
 \partial_t \psi = \mathfrak i\left [\frac{1}{2} \nabla^2 - V \right ] \psi.
$$

So 

$$
\omega = \mathfrak i\frac{1}{2} \nabla^2
\Rightarrow \omega_{\mathfrak f} = -\mathfrak i \frac{1}{2} \mathbf k^2
$$

| Atomic unit of | Value               |
|----------------|---------------------|
| Length         | 0.529 Å (Angstrom)  |
| Energy         | 27.2 eV (electron volts)  |
| Time           | 24.2 aS (atto seconds)    |


## The Born rule

The Born rule states that the probability $p$ of measuring a particle in the interval $[a,b]$ is given by 

$$
p = \int_a^b dx |\psi(x)|^2.
$$

## The Momentum representation

In quantum mechanics, the Fourier transform serves as the mathematical bridge between the position and momentum representations of a quantum state. 
This relationship reveals the wave-particle duality at the heart of quantum theory.

The same quantum state can alternatively be described in momentum space by the wave function $\psi(k)$, where $|\phi(k)|^2$, where $k$ is the wave number, gives the probability density of finding the particle with momentum $\hbar k$.
The momentum wave function $\phi(p)$ is related to the position wave function $\psi(x)$ through the Fourier transform:

$$\phi(k) = \sqrt{2\pi} \psi_{\mathfrak f} (k)$$

with the Fourier transform $\psi_{\mathfrak f} (k)$ defined as in [The Base System documentation](https://comfitlib.com/ClassBaseSystem/#fourier-transformations).
The extra factor of $\sqrt{2\pi}$ is a comes from our definition of the Fourier transform, see below.

### Normalization of the Fourier Transform

Consider the Fourier transform in $n$-dimensions as defined:

$$\psi_{\mathfrak f}(\mathbf{k}) = \mathcal F[\psi] = \frac{1}{(2\pi)^n} \int d^n r\, e^{-i\mathbf{k}\cdot\mathbf{r}} \psi(\mathbf{r}),$$

with the inverse:

$$\psi(\mathbf{r}) = \mathcal F^{-1}[\psi_{\mathfrak f}] = \int d^n k\, e^{i\mathbf{k}\cdot\mathbf{r}} \psi_{\mathfrak f}(\mathbf{k}),$$

where $d^n r$ and $d^n k$ denote integration over $n$-dimensional position and wave vector spaces, respectively. In quantum mechanics, the position-space wave function $\psi(\mathbf{r})$ is normalized such that:

$$\int d^n r\, |\psi(\mathbf{r})|^2 = 1,$$

ensuring the total probability is 1 across the $n$-dimensional space.

For the Fourier representation, substituting the inverse transform into the normalization condition and evaluating the inner integral yields a Dirac delta, $\int d^n r\, e^{i(\mathbf{k}-\mathbf{k'})\cdot\mathbf{r}} = (2\pi)^n \delta^n(\mathbf{k}-\mathbf{k'})$. This leads to:

$$\int d^n k\, (2\pi)^n |\psi_{\mathfrak f}(\mathbf{k})|^2 = 1,$$

or:

$$\int d^n k\, |\psi_{\mathfrak f}(\mathbf{k})|^2 = \frac{1}{(2\pi)^n}.$$

The factor $(2\pi)^n$ arises from the convention placing $\frac{1}{(2\pi)^n}$ in the forward transform.

To define a $\mathbf{k}$-space wave function $\phi(\mathbf{k})$ where $|\phi(\mathbf{k})|^2$ is the probability density per unit $\mathbf{k}$ in $n$-dimensions, satisfying:

$$\int d^n k\, |\phi(\mathbf{k})|^2 = 1,$$

set:

$$\phi(\mathbf{k}) = \sqrt{(2\pi)^n} \, \psi_{\mathfrak f}(\mathbf{k}).$$

Then:

$$|\phi(\mathbf{k})|^2 = (2\pi)^n |\psi_{\mathfrak f}(\mathbf{k})|^2,$$

and:

$$\int d^n k\, |\phi(\mathbf{k})|^2 = (2\pi)^n \int d^n k\, |\psi_{\mathfrak f}(\mathbf{k})|^2 = (2\pi)^n \cdot \frac{1}{(2\pi)^n} = 1.$$

Thus, $|\phi(\mathbf{k})|^2$ serves as the probability density in $\mathbf{k}$-space, adjusted for this Fourier transform convention.
In momentum space ($\mathbf{p} = \hbar \mathbf{k}$), additional scaling by $\hbar^n$ may apply, but $\phi(\mathbf{k}) = \sqrt{(2\pi)^n}  \psi_{\mathfrak f}(\mathbf{k})$ ensures proper normalization in $\mathbf{k}$-space.

### Physical Significance

1. **Complementarity**: The Fourier transform relationship embodies Heisenberg's uncertainty principle.
The more localized a wave function is in position space, the more spread out its Fourier transform is in momentum space, and vice versa.

2. **Operator Correspondence**: In the position representation, the momentum operator is $\hat{p} = -\mathfrak i\hbar\frac{d}{dx}$.
The Fourier transform converts this differential operator to a multiplication operator in momentum space.

3. **Energy Eigenstates**: For a free particle, the energy eigenstates are momentum eigenstates, which are plane waves in position space: $\psi(x) \propto e^{\mathfrak ikx/\hbar}$.


## A wave packet

A Gaussian wave function is often called a wave packet and can visualize the position and motion of a particle in a quantum mechanical system.
An initial wave function with a widt of $\sigma$ is given by

$$
\psi(\mathbf r) = \sqrt{( 2\pi \sigma )^{-d/2} \exp\left ({-\frac{(\mathbf r - \mathbf r_0)^2} {(2\sigma^2)}}\right )} ,
$$

so that $|\psi|^2$ is a Gaussian distribution.
An initial velocity $\mathbf v_0$ can be given to the wave packet by multiplying with a complex phase $e^{\mathfrak i \mathbf v_0 \cdot \mathbf r}$.
Such an initial condition can be configured by the function `qm.conf_initial_condition_Gaussian`.
--- End of file: docs\ClassQuantumMechanics.md ---

--- Start of file: docs\compiled_document.md ---
# Compiled Markdown Document

## Unnamed Section

Note that $N_{\mathfrak f}$ is a non-linear function of the field variable $\psi$, but can also be an explicit variable of time $t$, i.e. $N_{\mathfrak f}(\psi,t)$.
Therefore, in the code, it has to be encoded as a function of these two variables `calc_nonlinear_evolution_function_f(self, psi, t)`.

For numerical purposes, it is useful to calculate the small $\omega_{\mathfrak f}$ limit. We expand the exponential in its Taylor series and keep the leading order term to get:

$$
I_{\mathfrak f 0} \approx 1
$$

$$
I_{\mathfrak f 1} \approx   \frac{1}{\omega_{\mathfrak f}} (1 + \omega_{\mathfrak f} \Delta t - 1) = \Delta t
$$

$$
I_{\mathfrak f 2} \approx \frac{1}{\omega_{\mathfrak f}^2 \Delta t}
 \left ( 1 + \omega_{\mathfrak f} \Delta t + \frac{1}{2} ( \omega_{\mathfrak f} \Delta t )^2
 -1 - \omega_{\mathfrak f} \Delta t
\right ) = \frac{1}{2} \Delta t
$$

In $I_{\mathfrak f 1}$, and $I_{\mathfrak f 2}$ there is a division by $0$ when $\omega_{\mathfrak f} = 0$. To avoid numerical issues related to this we use the above limits when $|\omega_{\mathfrak f}|$ is smaller than a tolerance. We don't use the limit for $I_{\mathfrak f 0}$ since it doesn't contain a division by $0$. The function `evolve_ETD2RK_loop` defined in the base system class performs an ETD2RK step. This function is called by the evolvers discussed in the model chapter if the method is defined as `method = "ETD2RK"`. This is the default solver if `method` is not set. The integrating factors for a given $\omega_{\mathfrak f}(\mathbf{k})$ can be found with the function `calc_evolution_integrating_factors_ETD2RK` where the variable `tol` gives when the factors should be replaced by their leading order Taylor expansion.
Note that all solvers defined in the  class \lstinline{BaseSystem} updates the time variable
`self.t` to allow for time-dependents in the non-linear term.

### The ETD4RK scheme

Following Ref.[^coxExponentialTimeDifferencing2002], we may generalize the method to a fourth order Runge-Kutta as follows



--- End of file: docs\compiled_document.md ---

--- Start of file: docs\Conventions.md ---
# Conventions

In this section, we will describe the conventions used in the documentation and code.

## Folders and file types

* Documentation is written in markdown.
* Tutorials are written in markdown.

## File naming conventions

* Documentation files are named using CamelCase.
* Image files in the docs folder are named using `snake_case`

## Mathematical conventions

The imaginary unit will be denoted $\mathfrak i$, `\mathfrak i` to avoid confusion with the index $i$.
Index symmetrization $()$ and anti-symmetrization $[]$ will be used throughout.
They are defined for an tensor $A$ with two indices by

$$
A_{(ij)} = \frac{1}{2} (A_{ij} + A_{ji}),
$$

$$
A_{[ij]} = \frac{1}{2} (A_{ij} - A_{ji})
$$

The Fourier transform of a field $\psi$ will be denoted $\psi_{\mathfrak f}$, `\psi_{\mathfrak f}`, and is defined as

$$
\psi_{\mathfrak f} (\mathbf k) = \int d^d r e^{-\mathfrak i \mathbf k \cdot \mathbf r} f(\mathbf r),
$$

and the inverse is given by

$$
\psi(\mathbf r) = \frac{1}{(2\pi)^d} \int d^d k e^{\mathfrak i\mathbf k\cdot \mathbf r} \psi_{\mathfrak f}(\mathbf k),
$$

where $d$ is the spatial dimension.

Vectors $\mathbf a, \mathbf b, \mathbf c, \boldsymbol \Omega$ are denoted using boldfont (`\mathbf`, `\boldsymbol`) , while rank 2 tensors vary more.
Typical choices however are non-bold greek letters ($\sigma$) lower case Fraktur letters ($\mathfrak h$, `\mathfrak h`) or capital letters ($Q$).

The dot product ($\cdot$) is a contraction over the last index

```math
(\nabla \cdot \sigma)_i = \partial_j {\sigma}_{ij}
```

while the double dot product $\dot \cdot$ is a contraction over the last two indices

$$
(\mathcal C \dot \cdot \mathfrak e)_ {ij} = \mathcal C_ {ijkl} \mathfrak e_ {kl}
$$

## Programming notation conventions

* [PEP8](https://peps.python.org/pep-0008/) for python programming
* [NumPy docstring format](https://numpydoc.readthedocs.io/en/latest/format.html) for documentation strings
* Import ordering should follow this pattern:
  1. Standard library imports
  2. Third-party library imports
  3. Local application imports
  4. Each group should be separated by a blank line

Stand-alone functions are documented as follows:

```python
def function_name(
        arg1: arg1_type, 
        arg2: arg2_type, 
        arg3: Optional[arg3_type] = None,
        **kwargs: Any
        ) -> return_type:
    """Short description of the function (in the imperative mood).

    Optional longer description of the function.

    Parameters
    ----------
    arg1 : arg1_type
        Description of arg1. No need to state default values.
    arg2 : arg2_type
        Description of arg2.
    arg3 : arg3_type, optional
        Description of arg3. Defaults to None.
    kwargs : Any
        Description of additional keyword arguments.
    

    Returns
    -------
    return_type
        Description of the return value.

    Raises
    ------
    Exception
        Description of the exception.

    Examples
    --------
    >>> function_name(1, 2)
    3       
    """
    pass
```

If the function is a method of a `comfit` model, it should be documented as follows:

```python
from typing import TYPE_CHECKING # Import necessary typing packages

if TYPE_CHECKING:
    from comfit.core.base_system import BaseSystem

# General packages
# Import necessary packages from the standard library, e.g.
# import numpy as np

# Comfit packages
# Import necessary packages from comfit from the subpackages, e.g. 
# from comfit.core import BaseSystem

def function_name(
        self: 'BaseSystem',
        arg1: arg1_type, 
        arg2: arg2_type, 
        arg3: Optional[arg3_type] = None
        ) -> return_type:
    """Short description of the function (in the imperative mood).

    Optional longer description of the function.

    Parameters
    ----------
    arg1 : arg1_type
        Description of arg1. No need to state default values.
    arg2 : arg2_type
        Description of arg2.
    arg3 : arg3_type, optional
        Description of arg3. Defaults to None.
    kwargs : Any (use backslash to escape the asterisk)
        Description of additional keyword arguments.

    Returns
    -------
    return_type
        Description of the return value.

    Raises
    ------
    Exception
        Description of the exception.

    Examples
    --------
    >>> function_name(1, 2)
    3       
    """
    pass
```

* [markdownlint](https://github.com/DavidAnson/markdownlint) for markdown documents.

--- End of file: docs\Conventions.md ---

--- Start of file: docs\index.md ---
# <img src="img/logo.png" width="25" height="25"> ComFiT documentation

ComFiT ([Github](https://github.com/vidarsko/ComFiT)) is a versatile Python library for simulating field theories, including plotting and animation in an object-oriented manner.
If you use ComFiT in your research, please cite the following paper:

!!! quote ""
    Skogvoll, V., & Rønning, J. (2024). ComFiT: A Python library for computational field theory with topological defects. Journal of Open Source Software, 9(98), 6599. [https://doi.org/10.21105/joss.06599](https://doi.org/10.21105/joss.06599)

Below is a prepromt you can use with a language model to help you get started.

??? abstract "Preprompt for large language model (LLM)"
    ```python
    You are a helpful coding assistant who answers questions to the point.
    
    Gauge the understanding of the user before providing answers.

    Remind the user that you may not give completely correct answers and encourage the user to paste error messages if they encounter any.

    Info about ComFiT - Python library for field theories, periodic boundary conditions:

    import comfit as cf (general instance: cfi)

    Class BaseSystem: (instance: bs) (no dynamics)
    Models inheriting from BaseSystem: 
    QuantumMechanics (qm), BoseEinsteinCondensate (bec), NematicLiquidCrystal (nlc), PhaseFieldCrystal (pfc)
    Each model (e.g., qm) directly inherits BaseSystem's attributes, such as dim, dif, and others, accessible directly like, e.g., qm.dif

    Configurable vars:
    dim (1,2, or 3)
    dx
    xmin
    xmax
    xlim ([xmin, xmax])
    xRes
    similar vars for y, z in case bs.dim>1
    dt
    plot_lib ('matplotlib' or 'plotly')

    Other vars: 

    psi (field): primary order parameter (name varies between models)
    psi_f (Fourier transform of psi)
    x (coordinate array)
    xmid
    xmidi (index)
    size_x (xmax-xmin)
    similar vars for y, z in case bs.dim>1
    Res (total)
    dims (xRes if bs.dim=1, [xRes,yRes] if bs.dim=2 etc.)
    rmin = [xmin,ymin,zmin]
    rmid, rmax similar
    volume
    dV
    time (scalar)
    k (list, k[0] wave numbers for x etc.)
    dif (list, dif[i] = 1j*k[i], for differentiation)

    Broadcasting:

    x.shape = (xRes,) if bs.dim=1
    x.shape = (xRes,1) if bs.dim=2, y.shape = (1,yRes)
    similar for x,y,z if bs.dim=3

    Thus, `x+y` is a 2D array of shape `(xRes,yRes)` (no need for meshgrid)

    Functions types:

    calc_-calculates and returns output
    conf_-changes cfi, configures psi and psi_f, returns None
    evolve_-evolves cfi, returns None
    plot_-returns (fig,ax)
    get_-extracts variable 

    Fourier fields denoted `(field)_f`
    Fourier transformation (FT) given by `cfi.fft` and `cfi.ifft`.

    Derivatives using FT, examples:
    
    dxfield = cfi.ifft(bs.dif[0]*field_f)(.real() if field is real)
    Laplacian: cfi.ifft(-bs.calc_k2()*field_f)(.real() if field is real)

    Important functions:

    calc_k2() returns k^2 (for Laplacian)

    Time evolution:
    BaseSystem has no dynamics, but models inheriting BaseSystem have (see below)
    time incremented automatically by `dt` in time evolution loop

    Plotting:
    
    plot_field
    plot_complex_field
    plot_angle_field
    plot_vector_field
    plot_field_in_plane
    plot_complex_field_in_plane
    plot_angle_field_in_plane
    plot_vector_field_in_plane

    Plots (replace `plot_field` under with desired function)

    fig, ax = cfi.plot_field(field, title='title')
    cfi.show(fig) 


    Subplots (if either `number_of_(rows or columns)` is 1, `axs` is list, not 2D array)

    fig, axs = cfi.plot_subplots(2,2)
    cfi.plot_field(field1, fig=fig, ax=axs[0,0])
    cfi.plot_field(field2, fig=fig, ax=axs[0,1]) 
    #etc.

    fig, axs = cfi.plot_subplots(1,2)
    cfi.plot_field(field1, fig=fig, ax=axs[0])
    cfi.plot_field(field2, fig=fig, ax=axs[1]) 
    #etc.

    Animation:

    number_of_frames = 100
    for n in range(number_of_frames):
        #Evolve cfi
        fig, ax = cfi.plot_field(field) #replace with appropriate plot function
        cfi.plot_save(fig, n)
    cf.tool_make_animation_gif(number_of_frames-1)

    Creating custom model example:

    import comfit as cf
    import numpy as np
    import scipy as sp

    class LandauSystem(cf.BaseSystem):
        def __init__(self,dim, r, **kwargs):
            self.r = r
            super().__init__(dim, **kwargs)
        def calc_omega_f(self):
            return -self.calc_k2() - self.r
        def calc_nonlinear_evolution_function_f(self, field, t):
            return -sp.fft.fftn(field**3) 
        def evolve(self, number_steps):
            omega_f = self.calc_omega_f()
            integrating_factors_f, solver = self.calc_integrating_factors_f_and_solver(omega_f, method='ETD2RK')
            for n in range(number/_steps):
                self.psi, self.psi_f = solver(integrating_factors_f, 
                                            self.calc_nonlinear_evolution_function_f, 
                                            self.psi, self.psi_f)
                self.psi = np.real(self.psi)

    ls = LandauSystem(2, 0.5)
    ls.psi = np.random.rand(ls.xRes,ls.yRes)-0.5
    ls.psi_f = sp.fft.fftn(ls.psi)

    ls.evolve(200)
    fig, ax = ls.plot_field(ls.psi)
    ls.show(fig)

    Models inheriting BaseSystem 

    QuantumMechanics (instance: qm):
    evolve_schrodinger(number_of_steps) evolves qm.psi
    conf_initial_condition_Gaussian(position, width, initial_velocity)
    conf_wavefunction(psi) #sets wavefunction

    BoseEinsteinCondensate (bec)
    evolve_dGPE(number_of_steps) evolves bec.psi
    conf_initial_condition_Thomas_Fermi()
    conf_insert_vortex(charge,position)
    conf_dissipative_frame(interface_width)
    evolve_relax(number_of_steps)
    calc_vortex_nodes()
    plot_nodes(vortex_nodes)

    NematicLiquidCrystal (nlc) Contains 
    evolve_nematic evolves nlc.Q (tensor)
    conf_initial_condition_ordered
    conf_insert_disclination_dipole
    calc_nonlinear_evolution_function_f
    calc_active_force_f
    calc_passive_force_f
    calc_pressure_f
    calc_disclination_density_nematic
    calc_order_and_director
    plot_nodes

    PhaseFieldCrystal (pfc): 
    evolve_PFC
    pfc.psi (real scalar field representing crystalline structures)
    Evolves pfc.psi
    including evolve_PFC. Contains: conf_PFC_from_amplitudes
    calc_PFC_from_amplitudes
    calc_nonlinear_evolution_function_conserved_f
    calc_nonlinear_evolution_function_unconserved_f
    plot_field
    calc_dislocation_nodes
    calc_orientation_field, calc_free_energy
    ```

See the ComFiT Library Reference below for a complete list of class methods and their usage.

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
    <a href="https://comfitlib.com/library_reference/" class="card" style="min-width: 160px; flex: 0 1 calc(100.00% - 10px); margin: 5px;">
        <div style="text-align: center;">
            <strong> ComFiT Library Reference </strong>
        </div>
    </a>
</div>

## Tutorials

The best way to get to know ComFiT is by using it in one of the following tutorials.

###Base System

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
    <a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/base_system_basic_framework.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
        <div> <strong> Basic Framework</strong></div>
        <hr>
        <p>
        <img src="img/index_tutorial_base_system_basic_framework_demo.gif#only-light">
        <img src="img/index_tutorial_base_system_basic_framework_demo-colorinverted.gif#only-dark">
        </p>
        <p style="color: var(--md-default-fg-color)"> Understand the basics of ComFiT, how to calculate derivatives and produce plots and animations in 1, 2 and 3 dimensions. </p>
    </a>
    <a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/base_system_make_your_own_model.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
        <div> <strong>How to make your own model</strong></div>
        <hr>
        <p>
        <img src="img/index_tutorial_base_system_make_your_own_model.gif#only-light">
        <img src="img/index_tutorial_base_system_make_your_own_model-colorinverted.gif#only-dark">
        </p>
        <p style="color: var(--md-default-fg-color)">Learn how to implement, solve and animate your own partial differential equation.</p>
</a>
</div>

### Quantum Mechanics

Modules for learning quantum mechanics with ComFiT.
Author: [Carl Fredrik Nordbø Knutsen](https://www.mn.uio.no/fysikk/?vrtx=person-view&uid=cfknutse).

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/qm_assignment/module_1.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> Module 1 </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_qm_assignment_module_1.gif#only-light">
    <img src="img/index_tutorial_qm_assignment_module_1-colorinverted.gif#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
The Schrödinger equation for a single particle, in one and two dimensions.
    </p>
</a>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/qm_assignment/module_2.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> Module 2 </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_qm_assignment_module_2.png#only-light">
    <img src="img/index_tutorial_qm_assignment_module_2-colorinverted.png#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Operators and expectation values.
    </p>
</a>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/qm_assignment/module_3.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> Module 3 </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_qm_harmonic_oscillator.gif#only-light">
    <img src="img/index_tutorial_qm_harmonic_oscillator-colorinverted.gif#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    The Quantum Harmonic Oscillator and her eigenstates.
    </p>
</a>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/qm_assignment/module_4.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> Module 4 </strong></div>
    <hr>
    <p>
    <img src="img/quantum_mechanics_barrier_reflection.gif#only-light">
    <img src="img/quantum_mechanics_barrier_reflection-colorinverted.gif#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Quantum tunneling. 
    </p>
</a>
</div>

General tutorials.

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
    <a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/quantum_mechanics_1D_wave_packet.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
        <div> <strong> 1D wave packets </strong></div>
        <hr>
        <p>
        <img src="img/index_1D_Quantum_Mechanics_Gaussian.gif#only-light">
        <img src="img/index_1D_Quantum_Mechanics_Gaussian-colorinverted.gif#only-dark">
        </p>
        <p style="color: var(--md-default-fg-color)">
        Understand the basics of the Quantum Mechanics model.
        </p>
    </a>
    <a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/quantum_mechanics_2D_wave_packet.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
        <div> <strong> 2D wave packets </strong></div>
        <hr>
        <p>
        <img src="img/index_tutorial_qm_2D_wave_packet.gif#only-light">
        <img src="img/index_tutorial_qm_2D_wave_packet-colorinverted.gif#only-dark">
        </p>
        <p style="color: var(--md-default-fg-color)">
        Understand how to plot a quantum mechanical system in 2 dimensions.
        </p>
</a>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/quantum_mechanics_3D_wave_packet.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> 3D wave packets </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_qm_3D_wave_packet.gif#only-light">
    <img src="img/index_tutorial_qm_3D_wave_packet-colorinverted.gif#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Understand how to plot a quantum mechanical system in 3 dimensions.
    </p>
</a>
<!-- </a>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/quantum_mechanics_harmonic_oscillator.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> The harmonic oscillator </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_qm_harmonic_oscillator.gif#only-light">
    <img src="img/index_tutorial_qm_harmonic_oscillator-colorinverted.gif#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Investigate the quantum mechanical harmonic oscillator.
    </p>
</a> -->
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/quantum_mechanics_the_hydrogen_atom.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> The hydrogen atom </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_quantum_mechanics_hydrogen.gif#only-light">
    <img src="img/index_tutorial_quantum_mechanics_hydrogen-colorinverted.gif#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Get to know the hydrogen atom.
    </p>
</a>
</div>

### Bose-Einstein Condensates

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/bose_einstein_condensate_basic_framework.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> Basic Framework </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_bec_basic_framework-colorinverted.gif#only-dark">
    <img src="img/index_tutorial_bec_basic_framework.gif#only-light">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Understand the basics of the Bose Einstein Condensate model.
    </p>
</a>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/bose_einstein_condensate_time_dependenent_potentials.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong>Time-dependent potentials</strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_bec_time_dependent_potentials-colorinverted.gif#only-dark">
    <img src="img/index_tutorial_bec_time_dependent_potentials.gif#only-light">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Learn how to create time-dependent potentials to stir the Bose Einstein Condensate model.
    </p>
</a>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/bose_einstein_condensate_comoving_frame_and_defect_tracking.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong>Comoving frame and defect tracking</strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_bec_comoving_frame_defect_tracking-colorinverted.gif#only-dark">
    <img src="img/index_tutorial_bec_comoving_frame_defect_tracking.gif#only-light">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Learn how to track defects and study defects made by an obstacle.
    </p>
</a>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/bose_einstein_condensate_3D_comoving_frame.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong>3D and comoving frame </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_bec_3D_comoving_frame-colorinverted.gif#only-dark">
    <img src="img/index_tutorial_bec_3D_comoving_frame.gif#only-light">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Learn how to use the Bose Einstein Condensate model in 3 dimensions and in a comoving frame.
    </p>
</a>
</div>

### Nematic Liquid Crystal

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/nematic_liquid_crystal_2D_active_nematic.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> 2D active nematic </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_nematic_liquid_crystal_2D_active_nematic.gif#only-light">
    <img src="img/index_tutorial_nematic_liquid_crystal_2D_active_nematic-colorinverted.gif#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Simulate an active nematic liquid crystal in 2 dimensions.
    </p>
</a>
</div>

### Phase-field crystal

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/phase_field_crystal_basic_framework.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> Basic framework </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_pfc_basic_framework.gif#only-light">
    <img src="img/index_tutorial_pfc_basic_framework-colorinverted.gif#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Get to know the basic of the PFC framework, including how to insert dislocations, plot them, and evolve the PFC.
    </p>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/phase_field_crystal_stresses_and_strains.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> Stresses and strains </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_pfc_stresses_and_strains.gif#only-light">
    <img src="img/index_tutorial_pfc_stresses_and_strains-colorinverted.gif#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Learn how to calculate stresses and strains in the PFC model.
    </p>
</a>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/phase_field_crystal_polycrystalline_systems.ipynb" class="card" style="min-width: 160px; flex: 0 1 calc(20.00% - 10px); margin: 5px;">
    <div> <strong> Polycrystalline systems </strong></div>
    <hr>
    <p>
    <img src="img/index_tutorial_pfc_polycrystals.gif#only-light">
    <img src="img/index_tutorial_pfc_polycrystals-colorinverted.gif#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Create polycrystalline systems with the PFC model and evolve it according to different dynamics.
    </p>
</a>
</div>


For the time being, ComFiT is limited to periodic boundary conditions, but this may change in the future.

## Installation

Comfit can be installed from the Python Package Index (PyPI), a repository of software for the Python programming language, by executing the command

```bash
pip install comfit
```

pip install comfit in your terminal or command prompt.

## Virtual environnement

Using a virtual environnement when using ComFiT is highly encouraged for because even though we try to write robust code, it is still a library under development, so previously written simulations may break. By keeping your simulations together with the specific version of ComFiT, you make sure that your simulations will not break due to coming updates.

To create a virtual environnement, run the following command in your terminal after having navigated to the root folder of your exploration project

```bash
Python -m venv myvenv
```

This will create the folder `myvenv` which will contain the local installation of Python and associated packages.
To activate the virtual environnement, simply run

```bash
.\venv\Scripts\activate
```

from the terminal.
Afterwards, you may install ComFiT using PyPi.
If your folder is part of a github repository, it is recommended to remove the virtual environment from the git project by adding `venv/` to your `.gitignore` file.

## Contributing

We welcome contributions.
Whether you're fixing a bug, adding a new feature, or improving our documentation, your support helps us make the package more robust and versatile.
Contributions can take many forms, from fixing minor bugs to implementing complex new features. 
Below are the ways you can contribute:

### Bug Fixes

Did you identify a bug? Here's how to proceed:

1. **Fork the repository**: Start by forking the ComFiT GitHub repository.
2. **Create a branch**: Make a new branch on your fork dedicated to the bug fix.
3. **Fix the bug**: Make the necessary changes to resolve the bug.
4. **Run tests**: Ensure all existing tests pass with your changes. Add new tests if necessary to cover the bug fix.
5. **Submit a Pull Request (PR)**: Create a PR against the main ComFiT repository. Clearly describe the bug and how your changes fix it.

### Reporting Issues

Encountered an issue or have a suggestion? Please follow these steps:

1. **Check existing issues**: Before creating a new issue, please check existing issues to avoid duplicates.
2. **Create a new issue**: If your issue is unique, open a new issue on GitHub. Provide a detailed description, including steps to reproduce the issue if applicable.

### Feature Requests

Got an idea for a new feature or enhancement? We'd love to hear it! Please raise a discussion, or an issue as outlined above, detailing your idea and its potential benefits to ComFiT.

### Adding Your Own Model

If you're interested in adding your own model to ComFiT, we welcome your contribution! Your model should adhere to the following guidelines:

1. **Well-documented**: Include detailed documentation explaining your model's theory, implementation, and usage.
2. **Thoroughly tested**: Write comprehensive tests covering the functionality of your model.
3. **Follow ComFiT structure**: Ensure your model integrates seamlessly with the existing ComFiT framework.
4. **Tutorial**: Consider adding a tutorial in the form of a Jupyter notebook, demonstrating how to use your model. Link to the tutorial in your contribution.

For detailed instructions on implementing your own PDE model with ComFiT, refer to our [tutorial for creating your own model](https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/base_system_make_your_own_model.ipynb).

### Documentation Improvements

Good documentation is key to a project's usability and its community's growth. 
If you see areas for improvement or want to add documentation for undocumented features, your contributions are greatly appreciated.

--- End of file: docs\index.md ---

--- Start of file: docs\Plotting.md ---
# Plotting

See the ComFiT Library Reference below for a complete list of class methods and their usage.

<div class="grid cards" style="display: flex; flex-wrap: wrap;">
    <a href="https://comfitlib.com/library_reference/plot/" class="card" style="min-width: 160px; flex: 0 1 calc(100.00% - 10px); margin: 5px;">
        <div style="text-align: center;">
            <strong> ComFiT Library Reference </strong>
        </div>
    </a>
</div>

The `ComFiT` package supports both the `plotly` (default) and `matplotlib` 
plotting libraries. 
You can easily switch between the two by setting the `plot_lib` attribute of the 
`BaseSystem` class to either `plotly` or `matplotlib`, `plot_lib` can also be 
passed as an argument to the plotting functions.

Every plotting function returns a tuple containing a `fig` and an `ax` object.

=== "`matplotlib`"
    The `fig` object is the figure object of the plot, while the `ax` object represents the individual axes of the plot.

=== "`plotly`"
    The `fig` object is the figure for the plot, and the `ax` object is a dictionary containing properties necessary for correct placement of subplots. 
    Default is `ax = {'row': 1, 'col': 1, 'nrows': 1, 'ncols': 1}`.

To show the plot, use the `show` function, which takes the `fig` object as an argument

```python
cfi.show(fig)
```

## Plotting keywords

The following list gives the keyword arguments that determine the layout of the resulting plot.
These keywords can be passed to any plot function.
`bs` refers to an instance of the `BaseSystem` class.
In some cases, default values of other parameter depend on the value of `dim`, and are represented by curly brackets:

$$
\left \lbrace \begin{array}{l} \textrm{default value if } \texttt{dim }= 1 \\ \textrm{default value if } \texttt{dim }= 2  \\ \textrm{default value if } \texttt{dim }= 3  \\ \end{array} \right \rbrace
$$

| Keyword         | Definition         | Default value |
| ------------------ | --------------- | ----------- |
| `xlabel` | The label on the x-axis | $x/a_0$|
| `ylabel` | The label on the y-axis |  $\left \lbrace \begin{array}{c} \texttt{none} \\ y/a_0 \\  y/a_0 \\ \end{array} \right \rbrace$  |
| `zlabel` | The label on the z-axis |  $\left \lbrace \begin{array}{c} \texttt{none} \\ \texttt{none} \\  z/a_0 \\ \end{array} \right \rbrace$  |
| `suptitle` | The figure title | None |
| `title` | The axes title | None|
| `xmin` | The lower limit on the x-axis | `bs.xmin` |
| `xmax`| The upper limit on the x-axis | `bs.xmax - bs.dx` |
| `xlim`| A list or tuple consisting of the lower and upper limit on the x-axis. If `xlim` is provided, it trumps any provided `xmin` or `xmax`. | None|
| `ymin` | The lower limit on the y-axis | $\left \lbrace \begin{array}{c} \texttt{none} \\ \texttt{bs.ymin} \\  \texttt{bs.ymin} \\ \end{array} \right \rbrace$ |
| `ymax`| The upper limit on the y-axis | $\left \lbrace \begin{array}{c} \texttt{none} \\ \texttt{bs.ymax-bs.dy} \\  \texttt{bs.ymax-bs.dy} \\ \end{array} \right \rbrace$ |
| `ylim`| A list or tuple consisting of the lower and upper limit on the y-axis. If `ylim` is provided, it trumps any provided `ymin` or `ymax`. | None |
| `zmin` | The lower limit on the z-axis | $\left \lbrace \begin{array}{c} \texttt{none} \\ \texttt{none} \\  \texttt{bs.zmin} \\ \end{array} \right \rbrace$ |
| `zmax`| The upper limit on the z-axis | $\left \lbrace \begin{array}{c} \texttt{none} \\ \texttt{none} \\  \texttt{bs.zmax-bs.dz} \\ \end{array} \right \rbrace$ |
| `zlim`| List or tuple consisting of the lower and upper limit on the z-axis. If `zlim` is provided, it trumps any provided `zmin` or `zmax`. | None |
| `vmin` | Lower limit on the field to be plotted. In the case of a complex function, this is the lower limit of the absolute value of the field to be plotted. |None|
| `vmax` | Upper limit on the value of field to be plotted. In the case of a complex function, this is the upper limit of the absolute value of the field to be plotted. |None|
| `vlim` | List or tuple consisting of the lower and upper limit of the value to be plotted. Only relevant for `plot_field`. | None |
| `vlim_symmetric` | A Boolean parameter specifying whether the value limits should be symmetric. Only relevant for `plot_field`. | `False` |
| `colorbar` | Boolean parameter indicating whether or not to plot the colorbar | `True` (if applicable)|
| `colormap` | String specifying the colormap to be used | Varies |
| `grid` | Boolean parameter indicating whether or not to plot the axes grid | `False` |
| `hold` | Boolean parameter indicating whether or not to hold the current plot | `False` |
| `opacity` | The opacity of the plot (only sometimes relevant) | 1 |
| `plot_shadows` | Boolean parameter indicating whether or not to plot the shadows of the objects. Only applicable for `plot_complex_field`. | `True` |
| `fig` | `plotly` or `matplotlib` figure handle | None|
| `ax` | `matplotlib` axis handle or dictionary with subplot properties | None|
| `xticks` | List of ticks on the x-axis | None |
| `xticklabels` | List of labels for the ticks on the x-axis | None |
| `yticks` | List of ticks on the y-axis | None |
| `yticklabels` | List of labels for the ticks on the y-axis | None |
| `zticks` | List of ticks on the z-axis | None |
| `zticklabels` | List of labels for the ticks on the z-axis | None |
| `cticks` | List of ticks on the colorbar | None |
| `cticklabels` | List of labels for the ticks on the colorbar | None |
| `alpha` | The alpha value of the plot | 0.5 |
| `spacing` | The spacing between the arrows in a vector field plot | Varies |
| `x` | A custom 1D x-coordinate array with the same shape as `bs.x`.  | `bs.x` |
| `y` | A custom 1D y-coordinate array with the same shape as `bs.y`.  | `bs.y` |
| `z` | A custom 1D z-coordinate array with the same shape as `bs.z`.  | `bs.z` |
| `X` | A custom nD x-coordinate array.  | None |
| `Y` | A custom nD y-coordinate array.  | None |
| `Z` | A custom nD z-coordinate array.  | None |
| `fourier` | Boolean parameter indicating whether or not the field to plot is in Fourier space | `False` |


## Subplots

To plot multiple graphs in the same figure, use the `plot_subplots` function before any plotting functions. This function accepts the following arguments:

* `nrows` (int): The number of rows in the subplot grid.
* `ncols` (int): The number of columns in the subplot grid.
* `figsize` (tuple): The size of the figure.

The function returns a tuple `(fig, axs)`, where `fig` is the figure object and `axs` is a list of axis objects.
Following `matplotlib` conventions, if the subplot grid is one-dimensional, `axs` is a one-dimensional list of axis objects; otherwise, `axs` is a two-dimensional list of lists (so `axs[i][j]` is the axis object at the ith row and jth column).

=== "`matplotlib`"
    The `axs` object is a list (or array) of axis objects.

=== "`plotly`"
    The `axs` object is a list of `(row, col)` tuples; thus, `axs[i][j]` corresponds to the `(row, col)` position of the axis object in the ith row and jth column.

When plotting, pass the `fig` and `ax` objects to the plotting functions, e.g.

```python
import comfit as cf
import numpy as np

cfi = cf.BoseEinsteinCondensate(2)
cfi.psi = cfi.x + 1j * cfi.y
cfi.plot_lib = 'matplotlib'

fig, axs = cfi.plot_subplots(2, 2, figsize=(10, 10))

cfi.plot_complex_field(cfi.psi, fig=fig, ax=axs[0][0])
cfi.plot_field(abs(cfi.psi), fig=fig, ax=axs[0][1])
cfi.plot_angle_field(np.angle(cfi.psi), fig=fig, ax=axs[1][0])
cfi.show(fig)
```

## Matplotlib convention

The convention followed in `ComFiT` are as follows:

* When a plotting function is called *without* a keyword argument specifying the current figure or axes, then the current figure will be cleared and potential axes (in the case of matplotlib) will be created onto it.
This is because with no reference to which axes the plot is meant to go ontop, there is no way of knowing.
* If a figure is provided by the keyword `fig=myfig` with, then it will be cleared and the new plot will be plotted on `myfig`.
This is because with no reference to which axes the plot is meant to go ontop, there is no way of knowing.
* If an axes object is provided by the keyword `ax`, then the `ax` instance will be cleared and the new plot will be plotted on `ax`, unless the keyword `hold=True` is provided, in which case the new plot will be plotted ontop of the old plot.

To show the current plot, one writes

```python
plt.show()
```

which will pause the simulation until the plot window has been closed.
In order to draw the image and continue the simulation, as for instance when viewing a simulation live, one needs to write

```python
plt.pause(0.01)
```

## Plotly 3D properties

## Plotly 3D properties

Plotly handles manipulating figures differently in 2D and 3D dimensions.
In the `tool_set_plot_axis_properties_plotly` function, several helper dictionaries are constructed to set the proper plotting properties.

### Properties of the `ax` object

The `ax` object contains the following properties:

```python
row, nrows   # Row position and total number of rows
col, ncols   # Column position and total number of columns
xaxis = 'xaxis1'  # Axis identifier
yaxis = 'yaxis1'  # Axis identifier  
plot_dimension   # Dimension of the plot
```

### 2D updates

For 2D plots, updates are saved in the `layout_updates` dictionary:

```python
layout_updates = {
    'xaxis_range': [0, 10],  # Same format for y-axis
    'xaxis_title': 'x/a0'    # Title for x-axis
}
```

### 3D updates

For 3D plots, updates are organized in separate dictionaries for each axis:

```python
xaxis_updates = {
    'range': [0, 10],
    'title': 'x/a0',
    'tickvals': [0, 1, 2, ...],
    'ticktext': ['0', 'pi', ...]
}
```

Similar dictionaries exist for `yaxis_updates` and `zaxis_updates`.

These are combined in the `scene_updates` dictionary:

```python
scene_updates = {
    'xaxis': xaxis_updates,
    'yaxis': yaxis_updates,
    'zaxis': zaxis_updates
}
```

### Understanding `kwargs` vs `ax` dictionary

In all plot functions, there's an important distinction between the `kwargs` and `ax` dictionaries:

- `kwargs`: Contains settings specific to the current plot
- `ax`: Contains settings that apply to all plots in a given subplot





## Colormaps

There is a large overlap of colormaps between `matplotlib` and `plotly`, but there are some differences.
Here is an overview over *some* of the available colormaps in `ComFiT`.

![Colormaps](img/plotting_colormaps.png)

All the colormaps can be reversed by adding the `_r` suffix, e.g., `viridis_r`.
The colormaps `sunburst`, `bluewhitered` and `angle` have been custom made for ComFiT.
The colormap `winter` is not native in `plotly` but has been ported.

`colormap`: Strings describing the colormap.

`colorbar`: Boolean parameter indicating whether or not to plot the colorbar.

`colormap_object`: The colormap object, which is called in plot commands.

## Plotting functions

The `BaseSystem` class comes pre-packaged with a number of plotting functions to plot four different types of fields.

### Real fields

Real fields are fields that take real values, for example the temperature in a room.

#### `plot_field`

The `plot_field` function is used to plot a real field.

??? example "Example"

    ```python
    import comfit as cf
    import matplotlib.pyplot as plt
    import numpy as np

    fig = plt.figure()

    ax1 = fig.add_subplot(131)
    bs = cf.BaseSystem(1,xRes=31)
    field = bs.x**2
    bs.plot_field(field,ax=ax1)

    ax2 = fig.add_subplot(132)
    bs = cf.BaseSystem(2,xRes=31,yRes=31)
    field = bs.x**2 + bs.y**2
    bs.plot_field(field,ax=ax2)

    ax3 = fig.add_subplot(133, projection='3d')
    bs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)
    field = bs.x**2 + bs.y**2 + bs.z**2
    bs.plot_field(field,ax=ax3)

    plt.show()
    ```

    ![](img/plotting_plot_field_demo.png#only-light)
    ![](img/plotting_plot_field_demo-colorinverted.png#only-dark)

#### `plot_field_in_plane` 

The `plot_field_in_plane` function is used to plot a real field in a plane.

??? example "Example"
    ```python 
    import comfit as cf
    import matplotlib.pyplot as plt
    import numpy as np


    fig = plt.figure()

    ax1 = fig.add_subplot(121, projection='3d')
    bs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)
    field = (bs.x**2 + bs.y**2 + bs.z**2)
    bs.plot_field_in_plane(field, ax=ax1)

    ax2 = fig.add_subplot(122, projection='3d')
    bs.plot_field_in_plane(field, ax=ax2, normal_vector=[1,1,0],position=[10,10,10])

    plt.show()
    ```

    ![](img/plotting_plot_field_in_plane_demo.png#only-light)
    ![](img/plotting_plot_field_in_plane_demo-colorinverted.png#only-dark)

### Complex fields

Complex fields are fields that take complex values, for example the electric field in a light wave.

#### `plot_complex_field` 

The `plot_complex_field` function is used to plot a complex field.

??? example "Example"

    ```python
    import comfit as cf
    import matplotlib.pyplot as plt
    import numpy as np

    fig = plt.figure()

    ax1 = fig.add_subplot(231)
    bs = cf.BaseSystem(1,xRes=31)
    field = bs.x**2*np.exp(1j*bs.x/3)
    bs.plot_complex_field(field,ax=ax1)

    ax2 = fig.add_subplot(232)
    bs = cf.BaseSystem(2,xRes=31,yRes=31)
    field = (bs.x**2 + bs.y**2)*np.exp(1j*bs.x/3)
    bs.plot_complex_field(field,ax=ax2,plot_method='phase_angle')

    ax3 = fig.add_subplot(233, projection='3d')
    bs = cf.BaseSystem(2,xRes=31,yRes=31)
    field = (bs.x**2 + bs.y**2)*np.exp(1j*bs.x/3)
    bs.plot_complex_field(field,ax=ax3,plot_method='3Dsurface')

    ax5 = fig.add_subplot(235, projection='3d')
    bs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)
    field = (bs.x**2 + bs.y**2 + bs.z**2)*np.exp(1j*bs.x/3)
    bs.plot_complex_field(field,ax=ax5,plot_method='phase_angle')

    ax6 = fig.add_subplot(236, projection='3d')
    bs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)
    field = (bs.x**2 + bs.y**2 + bs.z**2)*np.exp(1j*bs.x/3)
    bs.plot_complex_field(field,ax=ax6,plot_method='phase_blob')

    plt.show()
    ```

    ![](img/plotting_plot_complex_field_demo.png#only-light)
    ![](img/plotting_plot_complex_field_demo-colorinverted.png#only-dark)

#### `plot_complex_field_in_plane` 

The `plot_complex_field_in_plane` function is used to plot a complex field in a plane.
The modulus of the complex field is shown as the alpha channel, where the minimum modulus value is transparent and the maximum modulus value is opaque.
The phase of the complex field is shown as the color of the field, where the color is determined by the angle color scheme.

??? example "Example"
    ```python 
    import comfit as cf
    import matplotlib.pyplot as plt
    import numpy as np

    fig = plt.figure()

    ax1 = fig.add_subplot(121, projection='3d')
    bs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)
    complex_field = (bs.x**2 + bs.y**2 + bs.z**2)*np.exp(1j*bs.y/3)
    bs.plot_complex_field_in_plane(complex_field, ax=ax1)

    ax2 = fig.add_subplot(122, projection='3d')
    bs.plot_complex_field_in_plane(complex_field, ax=ax2, normal_vector=[0,0,1],position=[10,10,10])

    plt.show()
    ```

    ![](img/plotting_plot_complex_field_in_plane_demo.png#only-light)
    ![](img/plotting_plot_complex_field_in_plane_demo-colorinverted.png#only-dark)

### Angle fields

Angle fields are fields that take values in the interval $[-\pi,\pi]$, for example the phase of a complex field.

#### `plot_angle_field`

The `plot_angle_field` function is used to plot an angle field.

??? example "Example"
    ```python
    import comfit as cf
    import matplotlib.pyplot as plt
    import numpy as np

    fig = plt.figure()

    ax1 = fig.add_subplot(131)
    bs = cf.BaseSystem(1,xRes=31)
    angle_field = np.mod((bs.x)/5,2*np.pi)-np.pi
    bs.plot_angle_field(angle_field,ax=ax1)

    ax2 = fig.add_subplot(132)
    bs = cf.BaseSystem(2,xRes=31,yRes=31)
    angle_field = np.mod((bs.x + 2*bs.y)/5,2*np.pi)-np.pi
    bs.plot_angle_field(angle_field,ax=ax2)

    ax3 = fig.add_subplot(133, projection='3d')
    bs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)
    angle_field = np.mod((bs.x + 2*bs.y + 3*bs.z)/5,2*np.pi)-np.pi
    bs.plot_angle_field(angle_field,ax=ax3)

    plt.show()
    ```

    ![](img/plotting_plot_angle_field_demo.png#only-light)
    ![](img/plotting_plot_angle_field_demo-colorinverted.png#only-dark)

#### `plot_angle_field_in_plane` 

The `plot_angle_field_in_plane` function is used to plot an angle field in a plane.

??? example "Example"
    ```python 
    import comfit as cf
    import matplotlib.pyplot as plt
    import numpy as np

    fig = plt.figure()

    ax1 = fig.add_subplot(121, projection='3d')
    bs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)
    angle_field = np.mod((bs.x + 2*bs.y + 3*bs.z)/5,2*np.pi)-np.pi
    bs.plot_angle_field_in_plane(angle_field, ax=ax1)

    ax2 = fig.add_subplot(122, projection='3d')
    bs.plot_angle_field_in_plane(angle_field, ax=ax2, normal_vector=[0,0,1],position=[10,10,10])

    plt.show()
    ```

    ![](img/plotting_plot_angle_field_in_plane_demo.png#only-light)
    ![](img/plotting_plot_angle_field_in_plane_demo-colorinverted.png#only-dark)

### Vector fields

#### `plot_vector_field`

The `plot_vector_field` function is used to plot a vector field $\mathbf v = (v_x,v_y,v_z)$.
Vector fields are usually plotted blue.
Together with the typical keyword arguments, the `plot_vector_field` function has the kewyword `spacing` which determines the spacing between the arrows in the plot.

The behavior of this plot function is dependent on the interplay between the dimension of the system and the dimension $n$ of the vector field.
In cases where `dim` $+ n > 3$, it is not possible to plot the vector field in a quantitatively accurate (QA) way.
In such cases, different scalings which results in not quantitatively accurate representations (not QA) are taken to visualize the vector field, as described in the table below, and the user is encouraged to plot the vector field components individually for quantitative analysis.
The scaling used is can be seen in the code of the `plot_vector_field` function, and a custom scaling can be provided by the user by setting the `vx_scale`, `vy_scale` and `vz_scale` keyword arguments. 
These factors scale the normalized vector field ($\frac{\mathbf v = \mathbf v }{|\mathbf v|}$) components in the x-, y- and z-axes, respectively, as shown for $n=3$ below.

```python
# Normalizing
U = U / max_vector
V = V / max_vector
W = W / max_vector

# Scale factors
vx_scale = kwargs.get('vx_scale', 2*spacing*self.size_x/max_vector)
vy_scale = kwargs.get('vy_scale', 2*spacing*self.size_y/max_vector)
vz_scale = kwargs.get('vz_scale', spacing)

# Scaling
U = vx_scale*U
V = vy_scale*V
W = vz_scale*W
```

The following table summarizes the behavior of the `plot_vector_field` function.

| System dimension | $n=1$ | $n=2$ | $n=3$ |
| ----------------- | ----- | ----- | ----- |
|`dim=1` | $v_x$ on y-axis <br>(QA). | $v_x$ on y-axis, $v_y$ on z-axis <br>(QA). | $v_x, v_y$ and $v_z$ along x-, y- and z-axes, respectively <br>(not QA).  |
| `dim=2` | $v_x$ on the x-axis. <br>(not QA) | $v_x$ and $v_y$ on x- and y-axes, respectively <br>(not QA).| $v_x$, $v_y$ and $v_z$ on the x-, y- and z-axes, respectively <br>(not QA). |
| `dim=3` | $v_x$ on the x-axis <br>(not QA) | $v_x$, $v_y$ on the x-, and y-xes, respectively <br>(not QA). | $v_x$, $v_y$ and $v_z$ on the x-, y- and z-axes, respectively <br>(not QA). |

??? example "Example"
    ```python
    import comfit as cf
    import matplotlib.pyplot as plt
    import numpy as np

    fig = plt.figure()

    #1D system
    bs = cf.BaseSystem(1,xRes=31)

    # 1D vector field
    ax1 = fig.add_subplot(331)
    vector_field = np.array([bs.x*np.cos(bs.x/5)])
    bs.plot_vector_field(vector_field,ax=ax1, spacing=1)

    # 2D vector field
    ax2 = fig.add_subplot(332, projection='3d')
    vector_field = np.array([bs.x*np.cos(bs.x/5), bs.x*np.sin(bs.x/5)])
    bs.plot_vector_field(vector_field,ax=ax2, spacing=2)

    # 3D vector field
    ax3 = fig.add_subplot(333, projection='3d')
    vector_field = np.array([bs.x*np.cos(bs.x/5), bs.x*np.sin(bs.x/5), bs.x*np.cos(bs.x/5)])
    bs.plot_vector_field(vector_field,ax=ax3, spacing=3)

    #2D system
    bs = cf.BaseSystem(2,xRes=31,yRes=31)

    # 1D vector field
    ax4 = fig.add_subplot(334)
    vector_field = np.array([bs.x*np.cos(bs.y/5)])
    bs.plot_vector_field(vector_field,ax=ax4,spacing=3)

    # 2D vector field
    ax5 = fig.add_subplot(335)
    vector_field = np.array([bs.x*np.cos(bs.y/5), bs.y*np.sin(bs.x/5)])
    bs.plot_vector_field(vector_field,ax=ax5,spacing=5)

    # 3D vector field
    ax6 = fig.add_subplot(336, projection='3d')
    vector_field = np.array([bs.x*np.cos(bs.y/5), bs.y*np.sin(bs.x/5), bs.x*np.cos(bs.y/5)])
    bs.plot_vector_field(vector_field,ax=ax6, spacing=3)

    # 3D system
    bs = cf.BaseSystem(3,xRes=11,yRes=11,zRes=11)

    # 1D vector field
    ax7 = fig.add_subplot(337, projection='3d')
    vector_field = np.array([bs.z+bs.x*np.cos(bs.y/5)])
    bs.plot_vector_field(vector_field,ax=ax7,spacing=3)

    # 2D vector field
    ax8 = fig.add_subplot(338, projection='3d')
    vector_field = np.array([bs.z+ bs.x*np.cos(bs.y/5), bs.z + bs.y*np.sin(bs.x/5)])
    bs.plot_vector_field(vector_field,ax=ax8,spacing=5)

    # 3D vector field
    ax9 = fig.add_subplot(339, projection='3d')
    vector_field = np.array([bs.z+ bs.x*np.cos(bs.y/5), bs.z + bs.y*np.sin(bs.x/5), -bs.z + bs.x*np.cos(bs.y/5)])
    bs.plot_vector_field(vector_field,ax=ax9,spacing=3)

    plt.show()
    ```

    ![](img/plotting_plot_vector_field_demo.png#only-light)
    ![](img/plotting_plot_vector_field_demo-colorinverted.png#only-dark)

#### `plot_vector_field_in_plane`

The `plot_vector_field_in_plane` function is used to plot a vector field in a plane.

??? example "Example"
    ```python
    import comfit as cf
    import matplotlib.pyplot as plt
    import numpy as np

    fig = plt.figure()

    ax1 = fig.add_subplot(121, projection='3d')
    bs = cf.BaseSystem(3,xRes=11,yRes=11,zRes=11)
    vector_field = np.array([bs.z+bs.x*np.cos(bs.y/5), bs.z+bs.y*np.sin(bs.x/5), -bs.z+bs.x*np.cos(bs.y/5)])
    bs.plot_vector_field_in_plane(vector_field, ax=ax1)

    ax2 = fig.add_subplot(122, projection='3d')
    bs = cf.BaseSystem(3,xRes=11,yRes=11,zRes=11)
    vector_field = np.array([bs.z+bs.x*np.cos(bs.y/5), bs.z+bs.y*np.sin(bs.x/5)])
    bs.plot_vector_field_in_plane(vector_field, ax=ax2, normal_vector=[0,1,1],position=[2,3,3])

    plt.show()
    ```

    ![](img/plotting_plot_vector_field_in_plane_demo.png#only-light)
    ![](img/plotting_plot_vector_field_in_plane_demo-colorinverted.png#only-dark)

## Animation

Creating animations are typically done by exporting each frame to a `png`-file and then combining the frames together.
For a ComFiT instance `cfi`, the command to export a frame is given by

```python
cfi.save_plot(n, fig)
```

where `n` is the frame number (assumed to start at `0`) and `fig` is the output of a plotting function.
If `plot_lib` is set to `matplotlib`, then `fig` is a tuple of the `matplotlib` figure and axes objects and if `plot_lib` is set to `plotly`, then `fig` is a `plotly` figure object.
An optional keyword argument `ID` can be given, which assigns a unique identifier to the plot, which is useful in case of running multiple simulations in parallel.

After producing the individual figures, they can be combined into an animation using the command

```python
cf.tool_make_animation_gif(n)
```

where `n` is the last frame number.

??? example "Example"
    
    Here is how one would create an animation of a field.

    ```python
    # Initialize the field and the ComFiT instance cfi

    for n in range(100):
        # Update the field
        # Plot the field and save in fig
        cfi.save_plot(n, fig)
    cf.tool_make_animation_gif(n)
    ```

## Angle color scheme

In many of the plotting functions, we are plotting angles, for example in plotting the phase
of a complex number or the value of an order parameter on S1
. In these cases, all values
modulus 2π are eqvuivalent, but if one uses a regular color scheme, this equivalence is not
readily visible. Therefore, when expressing angles, we use the color scheme shown in Fig. 1.1.
This has the benefit of wrapping around itself at θ = ±π, stressing that these correspond

![Angle color scheme](img/conventions_angle_colormap.png#only-light)
![Angle color scheme](img/conventions_angle_colormap-colorinverted.png#only-dark)

*Angle color scheme.* The color scheme follows the hsv color circle going through  $\theta=0$ (Red), $\theta=\pi/3$ (Yellow), $\theta=2\pi/3$ (Lime), $\theta = \pm \pi$ (Aqua), $\theta = -2\pi/3$ (Blue), $\theta = -\pi/3$ (Fuchsia).



### Technicality: The `marching_cubes` function and interpolation

The marching cubes algorithm is used to create a 3D surface from a 3D field and is used in creating many of the plots in three dimensions.
If you are going to make changes to the codebase, then it is useful to have an idea of how it works and what the resulting quantities are.

Typically, we have our 3D system with a total resolution of, say 300, and a field `field`, of which we want to extract the values on some specific isosurface `iso_value`.
The `marching_cubes` function is called as follows

```python
verts, faces, _, _ = marching_cubes(field,iso_value)
```

`verts` is a list of the (integer) positions of the vertices of the surfaces, e.g.,

```python
verts = 
[[x0i,y0i,z0i],
 [x1i,y1i,z1i],
 [x2i,y2i,z2i],
 [x3i,y3i,z3i],
 [x4i,y4i,z4i]]

verts = 
[[ 0.  5.  1.]
 [ 0.  5.  0.]
 [ 1.  5.  1.]
 [ 1.  5.  0.]
 [ 0.  5.  2.]]
```

if the surface has five vertices.
`faces` is a list of the indices of the vertices that make up the triangles of the surface.

```python
faces = 
[[v0i,v1i,v2i],
 [v3i,v4i,v5i],
 ... #3 hidden rows
 [v2i,v1i,v0i]]

faces =
[[  2   1   0]
 [  2   3   1]
 [  1   3   2]
 [  0   4   2]
 [  2   3   1]
 [  0   1   2]]
```

if the surface has six faces.
In other words, if `faces[0] = [2, 1, 0]`, then it represents the triangle given by the three vertices

```python
verts[2] = [ 1.  5.  1.]
verts[1] = [ 0.  5.  1.]
verts[0] = [ 0.  5.  0.]
```

Now, it is useful to calculate the position of a point located on the surface, which is calculated by the line

```python
centroids = np.mean(verts[faces], axis=1)
```

which gives the position of the centroids of the triangles that make up the surface.

```python
centroids = 
[[x0c,y0c,z0c],
 [x1c,y1c,z1c],
 [x2c,y2c,z2c],
 [x3c,y3c,z3c],
 [x4c,y4c,z4c]
 [x5c,y5c,z5c]]

centroids =
[[0.33333334 5.         0.6666667 ]
 [0.6666667  5.         0.33333334]
 [0.33333334 5.         1.6666666 ]
 [0.6666667  5.         1.3333334 ]
 [0.33333334 5.         2.6666667 ]
 [0.6666667  5.         2.3333333 ]]
```

As we see, the centroids array consists of as many rows as there are faces (naturally), and each row consists of the x-, y- and z-coordinates of the centroid of the corresponding face.

In the next line, we typically create the `points` array, as follows:

```python
x, y, z = np.mgrid[0:field.shape[0], 0:field.shape[1], 0:field.shape[2]]
points = np.c_[x.ravel(), y.ravel(), z.ravel()]
```

The `points` array is a list of the (integer) positions of all the points in the full 3D grid.

```python
points = 
[[x0i,y0i,z0i],
 [x1i,y1i,z1i],
 [x2i,y2i,z2i],
 [x3i,y3i,z3i],
 [x4i,y4i,z4i],
 ... # 300 rows total
 [x299i,y299i,z299i]]

 points = 
 [[ 0  0  0]
 [ 0  0  1]
 [ 0  0  2]
 ... # 300 rows total
 [10 10  8]
 [10 10  9]
 [10 10 10]]
```

Then, we create the `field_values` array by 

```python
field_values = field.ravel()
```

which is a `(300,)`-shaped array of the values of the field at the points in the `points` array, i.e., in the full grid.

Now we get to the interpolation, which happens by the command

```python
field_verts = sp.interpolate.griddata(points, field_values,centroids, method='nearest')
```

which uses the information in `points` and `field_values` to interpolate the field values at the centroids of the faces of the surface.
It returns thus a `(6,)`-array containing the field values to be used in the plotting of the surface.
The `nearest` method is used to interpolate the field values, which means that the field value at the centroid of a face is the field value of the point in the full grid that is closest to the centroid of the face.

--- End of file: docs\Plotting.md ---

--- Start of file: docs\Templates.md ---
Card template:

<div class="grid cards">
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/file_name.ipynb" class="card">
    <div> <strong> Heading 1</strong></div>
    <hr>
    <p>
    <img src="_link_to_light_theme_image_#only-light">
    <img src="_link_to_dark_theme_image_#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Description 1
    </p>
</a>
<a href="https://colab.research.google.com/github/vidarsko/ComFiT/blob/main/tutorial/file_name.ipynb" class="card">
    <div> <strong>Heading 2</strong></div>
    <hr>
    <p>
    <img src="_link_to_light_theme_image_#only-light">
    <img src="_link_to_dark_theme_image_#only-dark">
    </p>
    <p style="color: var(--md-default-fg-color)">
    Description 2
    </p>
</a>
</div>
--- End of file: docs\Templates.md ---

--- Start of file: docs\TopologicalDefects.md ---
# Topological defects

Topological defects are defects that appear due to imposed constraints by boundary conditions[^merminTopologicalTheoryDefects1979].
In this work, we will track topological defects as entities derivable from a coarse defect density field[^skogvollUnifiedFieldTheory2023].
In short, for a system containing topological defects, it is possible to derive a defect density field $\rho$, which upon suitable spatial integration gives the charge of the defects contained in that region.

## The algorithm for tracking topological defects

The algorithm for identifying topological defects is implemented in the method `BaseSystem.calc_defect_nodes`.
It requires an input of a positive real scalar field `defect_density`, which upon integration over a region gives a number proportional to the number of defects in that region.

!!! note "Note"
    The `defect_density` field is not necessarily the same as the defect density field $\rho$ alluded to above.
    Whereas $\rho$ might be a vector- or tensor-valued field, `defect_density` is a real and positive scalar field.
    They are, however, related, and the exact connection depends on the model in question. 
    For example, in the case of a 2D Bose-Einstein condensate, the `defect_density` is given by $|\rho|$, and in three dimension, where $\vec \rho$ is a vector field, `defect_density` is given by $\vec \rho$. 

The algorithm takes`charge_tolerance` and `integration_radius` as inputs, and then follows these steps:

| Step | Illustration|
|----|----|
| 1. Identify the `position_index` corresponding to `max(defect_density)`. | ![Illustration of step 1](img/topological_defects_algorithm_1.png#only-light) ![Illustration of step 1](img/topological_defects_algorithm_1-colorinverted.png#only-dark)  |
| 2. Calculate the integral `charge` of `defect_density` in a ball `region_to_integrate` of radius `integration_radius` around the point corresponding to `position_index`. If `charge>charge_tolerance`, then the point will be added to the identified defect nodes. | ![Illustration of step 2](img/topological_defects_algorithm_2.png#only-light) ![Illustration of step 2](img/topological_defects_algorithm_2-colorinverted.png#only-dark)|
| `while` `charge>charge_tolerance` | |
| &nbsp;&nbsp; 3.1 Store `position_index` in the dictionary `defect_node`.  | |
| &nbsp;&nbsp; 3.2 Calculate position $\mathbf r_0$ of `defect_note` as the expectation value of $(x,y,z)$ by using `defect_density` as a probability distribution function in `region_to_integrate`. | ![Illustration of step 3.2](img/topological_defects_algorithm_3_2.png#only-light) ![Illustration of step 3.2](img/topological_defects_algorithm_3_2-colorinverted.png#only-dark)  |
| &nbsp;&nbsp; 3.3 Add `defect_node` to the list `defect_nodes`. | |
| &nbsp;&nbsp; 3.4 Remove a ball of radius `2*integration_radius` around `position_index` from the region `region_to_search` in which to search for new defect nodes. | ![Illustration of step 3.4](img/topological_defects_algorithm_3_4.png#only-light) ![Illustration of step 3.4](img/topological_defects_algorithm_3_4-colorinverted.png#only-dark) |
| &nbsp;&nbsp; 3.5 Identify the `position_index` corresponding to `max(defect_density)` in the region `region_to_search`. | ![Illustration of step 3.5](img/topological_defects_algorithm_3_5.png#only-light) ![Illustration of step 3.5](img/topological_defects_algorithm_3_5-colorinverted.png#only-dark) |
| &nbsp;&nbsp; 3.6 Calculate the integral `charge` of `defect_density` in a ball `region_to_integrate` of radius `integration_radius` around the point corresponding to `position_index`. | ![Illustration of step 3.6](img/topological_defects_algorithm_3_6.png#only-light) ![Illustration of step 3.6](img/topological_defects_algorithm_3_6-colorinverted.png#only-dark)|

The value of `charge_tolerance` and `integration_radius` must be set depending on the particular system and the nature of defect density.
For example, in the case of a 2D phase-field crystal, the defect density will be $\sqrt{\alpha_{ij} \alpha_{ij}}$, which is the density of Burgers vectors.
Upon integration over a defect node, it is expected to give the absolute value of the Burgers vector of the defect, which is expressed in units of $a_0$, the lattice constant.
Therefore, the input charge tolerance is given in units of $a_0$, e.g., `charge_tolerance=0.2*self.a0`.
In the case of the 2D Bose-Einstein condensate, however, the integral over the defect density will be a unitless number equal to $1$ if integrated over a defect node.
Thus, the input charge tolerance is a unitless number, e.g., `charge_tolerance=0.2`.

Even though it was exemplified in two dimensions, the same algorithm is readily usable in three dimensions, but care needs to be taken to set the proper `charge_tolerance`.
For example, in a 3D Bose-Einstein condensate, the charge density provided is a 2D charge density in 3D space (for details, see Ref.[^skogvollUnifiedFieldTheory2023]).
The integral over the defect density will then no longer be a unitless number, but scale with `integration_radius`, so one might set both `charge_tolerance=0.2*self.a0` and `integration_radius=self.a0` to scale with `a0`.

### Properties of the defect nodes

Typically, `BaseSystem.calc_defect_nodes` is used to make the list of defect nodes, which is then used to calculate the node properties in the model-specific classes.
For instance, `BoseEinsteinCondensate.calc_vortex_nodes` first calls `BaseSystem.calc_defect_nodes` to get the list of defect nodes, and then calculates the properties of the defect nodes, such as their charge.
To calculate the velocity of defects using the method outlined in Ref.[^skogvollUnifiedFieldTheory2023], one must formulate the order parameter as an $n$-component vector field $\vec \psi$ and provide both `psi` (the vector field) and `dt_psi` as an input to `BaseSystem.calc_defect_velocity_field`.
This will return a vector field describing the velocity of the full defect density field, which can be evaluated at the defect nodes to get the velocity of the nodes.
See an example of how this is done in `BoseEinsteinCondensate.calc_vortex_nodes`.




[^merminTopologicalTheoryDefects1979]: Mermin, N. D. (1979). The topological theory of defects in ordered media. Reviews of Modern Physics, 51(3), 591–648. [https://doi.org/10.1103/RevModPhys.51.591](https://doi.org/10.1103/RevModPhys.51.591)

[^skogvollUnifiedFieldTheory2023]: Skogvoll, V., Rønning, J., Salvalaglio, M., & Angheluta, L. (2023). A unified field theory of topological defects and non-linear local excitations. Npj Computational Materials, 9(1), Article 1. [https://doi.org/10.1038/s41524-023-01077-6](https://doi.org/10.1038/s41524-023-01077-6)

--- End of file: docs\TopologicalDefects.md ---

