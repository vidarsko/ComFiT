{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ComFiT documentation","text":"<p>ComFiT (Github) is a versatile Python library for simulating field theories, including plotting and animation in an object-oriented manner. If you use ComFiT in your research, please cite the following paper:</p> <p>Skogvoll, V., &amp; R\u00f8nning, J. (2024). ComFiT: A Python library for computational field theory with topological defects. Journal of Open Source Software, 9(98), 6599. https://doi.org/10.21105/joss.06599</p> <p>Below is a prepromt you can use with a language model to help you get started.</p> Preprompt for large language model (LLM) <pre><code>You are a helpful coding assistant who answers questions to the point.\n\nGauge the understanding of the user before providing answers.\n\nRemind the user that you may not give completely correct answers and encourage the user to paste error messages if they encounter any.\n\nInfo about ComFiT - Python library for field theories, periodic boundary conditions:\n\nimport comfit as cf (general instance: cfi)\n\nClass BaseSystem: (instance: bs) (no dynamics)\nModels inheriting from BaseSystem: \nQuantumMechanics (qm), BoseEinsteinCondensate (bec), NematicLiquidCrystal (nlc), PhaseFieldCrystal (pfc)\nEach model (e.g., qm) directly inherits BaseSystem's attributes, such as dim, dif, and others, accessible directly like, e.g., qm.dif\n\nConfigurable vars:\ndim (1,2, or 3)\ndx\nxmin\nxmax\nxlim ([xmin, xmax])\nxRes\nsimilar vars for y, z in case bs.dim&gt;1\ndt\nplot_lib ('matplotlib' or 'plotly')\n\nOther vars: \n\npsi (field): primary order parameter (name varies between models)\npsi_f (Fourier transform of psi)\nx (coordinate array)\nxmid\nxmidi (index)\nsize_x (xmax-xmin)\nsimilar vars for y, z in case bs.dim&gt;1\nRes (total)\ndims (xRes if bs.dim=1, [xRes,yRes] if bs.dim=2 etc.)\nrmin = [xmin,ymin,zmin]\nrmid, rmax similar\nvolume\ndV\ntime (scalar)\nk (list, k[0] wave numbers for x etc.)\ndif (list, dif[i] = 1j*k[i], for differentiation)\n\nBroadcasting:\n\nx.shape = (xRes,) if bs.dim=1\nx.shape = (xRes,1) if bs.dim=2, y.shape = (1,yRes)\nsimilar for x,y,z if bs.dim=3\n\nThus, `x+y` is a 2D array of shape `(xRes,yRes)` (no need for meshgrid)\n\nFunctions types:\n\ncalc_-calculates and returns output\nconf_-changes cfi, configures psi and psi_f, returns None\nevolve_-evolves cfi, returns None\nplot_-returns (fig,ax)\nget_-extracts variable \n\nFourier fields denoted `(field)_f`\nFourier transformation (FT) given by `cfi.fft` and `cfi.ifft`.\n\nDerivatives using FT, examples:\n\ndxfield = cfi.ifft(bs.dif[0]*field_f)(.real() if field is real)\nLaplacian: cfi.ifft(-bs.calc_k2()*field_f)(.real() if field is real)\n\nImportant functions:\n\ncalc_k2() returns k^2 (for Laplacian)\n\nTime evolution:\nBaseSystem has no dynamics, but models inheriting BaseSystem have (see below)\ntime incremented automatically by `dt` in time evolution loop\n\nPlotting:\n\nplot_field\nplot_complex_field\nplot_angle_field\nplot_vector_field\nplot_field_in_plane\nplot_complex_field_in_plane\nplot_angle_field_in_plane\nplot_vector_field_in_plane\n\nPlots (replace `plot_field` under with desired function)\n\nfig, ax = cfi.plot_field(field, title='title')\ncfi.show(fig) \n\n\nSubplots (if either `number_of_(rows or columns)` is 1, `axs` is list, not 2D array)\n\nfig, axs = cfi.plot_subplots(2,2)\ncfi.plot_field(field1, fig=fig, ax=axs[0,0])\ncfi.plot_field(field2, fig=fig, ax=axs[0,1]) \n#etc.\n\nfig, axs = cfi.plot_subplots(1,2)\ncfi.plot_field(field1, fig=fig, ax=axs[0])\ncfi.plot_field(field2, fig=fig, ax=axs[1]) \n#etc.\n\nAnimation:\n\nnumber_of_frames = 100\nfor n in range(number_of_frames):\n    #Evolve cfi\n    fig, ax = cfi.plot_field(field) #replace with appropriate plot function\n    cfi.plot_save(fig, n)\ncf.tool_make_animation_gif(number_of_frames-1)\n\nCreating custom model example:\n\nimport comfit as cf\nimport numpy as np\nimport scipy as sp\n\nclass LandauSystem(cf.BaseSystem):\n    def __init__(self,dim, r, **kwargs):\n        self.r = r\n        super().__init__(dim, **kwargs)\n    def calc_omega_f(self):\n        return -self.calc_k2() - self.r\n    def calc_nonlinear_evolution_function_f(self, field, t):\n        return -sp.fft.fftn(field**3) \n    def evolve(self, number_steps):\n        omega_f = self.calc_omega_f()\n        integrating_factors_f, solver = self.calc_integrating_factors_f_and_solver(omega_f, method='ETD2RK')\n        for n in range(number/_steps):\n            self.psi, self.psi_f = solver(integrating_factors_f, \n                                        self.calc_nonlinear_evolution_function_f, \n                                        self.psi, self.psi_f)\n            self.psi = np.real(self.psi)\n\nls = LandauSystem(2, 0.5)\nls.psi = np.random.rand(ls.xRes,ls.yRes)-0.5\nls.psi_f = sp.fft.fftn(ls.psi)\n\nls.evolve(200)\nfig, ax = ls.plot_field(ls.psi)\nls.show(fig)\n\nModels inheriting BaseSystem \n\nQuantumMechanics (instance: qm):\nevolve_schrodinger(number_of_steps) evolves qm.psi\nconf_initial_condition_Gaussian(position, width, initial_velocity)\nconf_wavefunction(psi) #sets wavefunction\n\nBoseEinsteinCondensate (bec)\nevolve_dGPE(number_of_steps) evolves bec.psi\nconf_initial_condition_Thomas_Fermi()\nconf_insert_vortex(charge,position)\nconf_dissipative_frame(interface_width)\nevolve_relax(number_of_steps)\ncalc_vortex_nodes()\nplot_nodes(vortex_nodes)\n\nNematicLiquidCrystal (nlc) Contains \nevolve_nematic evolves nlc.Q (tensor)\nconf_initial_condition_ordered\nconf_insert_disclination_dipole\ncalc_nonlinear_evolution_function_f\ncalc_active_force_f\ncalc_passive_force_f\ncalc_pressure_f\ncalc_disclination_density_nematic\ncalc_order_and_director\nplot_nodes\n\nPhaseFieldCrystal (pfc): \nevolve_PFC\npfc.psi (real scalar field representing crystalline structures)\nEvolves pfc.psi\nincluding evolve_PFC. Contains: conf_PFC_from_amplitudes\ncalc_PFC_from_amplitudes\ncalc_nonlinear_evolution_function_conserved_f\ncalc_nonlinear_evolution_function_unconserved_f\nplot_field\ncalc_dislocation_nodes\ncalc_orientation_field, calc_free_energy\n</code></pre> <p>See the ComFiT Library Reference below for a complete list of class methods and their usage.</p>  ComFiT Library Reference"},{"location":"#tutorials","title":"Tutorials","text":"<p>The best way to get to know ComFiT is by using it in one of the following tutorials.</p>"},{"location":"#base-system","title":"Base System","text":"Basic Framework <p> Understand the basics of ComFiT, how to calculate derivatives and produce plots and animations in 1, 2 and 3 dimensions. </p> How to make your own model <p> </p> <p>Learn how to implement, solve and animate your own partial differential equation.</p>"},{"location":"#quantum-mechanics","title":"Quantum Mechanics","text":"<p>Modules for learning quantum mechanics with ComFiT. Author: Carl Fredrik Nordb\u00f8 Knutsen.</p>  Module 1  <p> </p> <p> The Schr\u00f6dinger equation for a single particle, in one and two dimensions.     </p>  Module 2  <p> </p> <p>     Operators and expectation values.     </p>  Module 3  <p> </p> <p>     The Quantum Harmonic Oscillator and her eigenstates.     </p>  Module 4  <p> </p> <p>     Quantum tunneling.      </p> <p>General tutorials.</p>  1D wave packets  <p> </p> <p>         Understand the basics of the Quantum Mechanics model.         </p>  2D wave packets  <p> </p> <p>         Understand how to plot a quantum mechanical system in 2 dimensions.         </p>  3D wave packets  <p> </p> <p>     Understand how to plot a quantum mechanical system in 3 dimensions.     </p>  The hydrogen atom  <p> </p> <p>     Get to know the hydrogen atom.     </p>"},{"location":"#bose-einstein-condensates","title":"Bose-Einstein Condensates","text":"Basic Framework  <p>     Understand the basics of the Bose Einstein Condensate model.     </p> Time-dependent potentials <p> </p> <p>     Learn how to create time-dependent potentials to stir the Bose Einstein Condensate model.     </p> Comoving frame and defect tracking <p> </p> <p>     Learn how to track defects and study defects made by an obstacle.     </p> 3D and comoving frame  <p> </p> <p>     Learn how to use the Bose Einstein Condensate model in 3 dimensions and in a comoving frame.     </p>"},{"location":"#nematic-liquid-crystal","title":"Nematic Liquid Crystal","text":"2D active nematic  <p>     Simulate an active nematic liquid crystal in 2 dimensions.     </p>"},{"location":"#phase-field-crystal","title":"Phase-field crystal","text":"Basic framework  <p>     Get to know the basic of the PFC framework, including how to insert dislocations, plot them, and evolve the PFC.     </p>  Stresses and strains  <p> </p> <p>     Learn how to calculate stresses and strains in the PFC model.     </p>  Polycrystalline systems  <p> </p> <p>     Create polycrystalline systems with the PFC model and evolve it according to different dynamics.     </p> <p>For the time being, ComFiT is limited to periodic boundary conditions, but this may change in the future.</p>"},{"location":"#installation","title":"Installation","text":"<p>Comfit can be installed from the Python Package Index (PyPI), a repository of software for the Python programming language, by executing the command</p> <pre><code>pip install comfit\n</code></pre> <p>pip install comfit in your terminal or command prompt.</p>"},{"location":"#virtual-environnement","title":"Virtual environnement","text":"<p>Using a virtual environnement when using ComFiT is highly encouraged for because even though we try to write robust code, it is still a library under development, so previously written simulations may break. By keeping your simulations together with the specific version of ComFiT, you make sure that your simulations will not break due to coming updates.</p> <p>To create a virtual environnement, run the following command in your terminal after having navigated to the root folder of your exploration project</p> <pre><code>Python -m venv myvenv\n</code></pre> <p>This will create the folder <code>myvenv</code> which will contain the local installation of Python and associated packages. To activate the virtual environnement, simply run</p> <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <p>from the terminal. Afterwards, you may install ComFiT using PyPi. If your folder is part of a github repository, it is recommended to remove the virtual environment from the git project by adding <code>venv/</code> to your <code>.gitignore</code> file.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions. Whether you're fixing a bug, adding a new feature, or improving our documentation, your support helps us make the package more robust and versatile. Contributions can take many forms, from fixing minor bugs to implementing complex new features.  Below are the ways you can contribute:</p>"},{"location":"#bug-fixes","title":"Bug Fixes","text":"<p>Did you identify a bug? Here's how to proceed:</p> <ol> <li>Fork the repository: Start by forking the ComFiT GitHub repository.</li> <li>Create a branch: Make a new branch on your fork dedicated to the bug fix.</li> <li>Fix the bug: Make the necessary changes to resolve the bug.</li> <li>Run tests: Ensure all existing tests pass with your changes. Add new tests if necessary to cover the bug fix.</li> <li>Submit a Pull Request (PR): Create a PR against the main ComFiT repository. Clearly describe the bug and how your changes fix it.</li> </ol>"},{"location":"#reporting-issues","title":"Reporting Issues","text":"<p>Encountered an issue or have a suggestion? Please follow these steps:</p> <ol> <li>Check existing issues: Before creating a new issue, please check existing issues to avoid duplicates.</li> <li>Create a new issue: If your issue is unique, open a new issue on GitHub. Provide a detailed description, including steps to reproduce the issue if applicable.</li> </ol>"},{"location":"#feature-requests","title":"Feature Requests","text":"<p>Got an idea for a new feature or enhancement? We'd love to hear it! Please raise a discussion, or an issue as outlined above, detailing your idea and its potential benefits to ComFiT.</p>"},{"location":"#adding-your-own-model","title":"Adding Your Own Model","text":"<p>If you're interested in adding your own model to ComFiT, we welcome your contribution! Your model should adhere to the following guidelines:</p> <ol> <li>Well-documented: Include detailed documentation explaining your model's theory, implementation, and usage.</li> <li>Thoroughly tested: Write comprehensive tests covering the functionality of your model.</li> <li>Follow ComFiT structure: Ensure your model integrates seamlessly with the existing ComFiT framework.</li> <li>Tutorial: Consider adding a tutorial in the form of a Jupyter notebook, demonstrating how to use your model. Link to the tutorial in your contribution.</li> </ol> <p>For detailed instructions on implementing your own PDE model with ComFiT, refer to our tutorial for creating your own model.</p>"},{"location":"#documentation-improvements","title":"Documentation Improvements","text":"<p>Good documentation is key to a project's usability and its community's growth.  If you see areas for improvement or want to add documentation for undocumented features, your contributions are greatly appreciated.</p>"},{"location":"ClassBaseSystem/","title":"Class: Base system","text":"<p>This class simply initiates a system, defines the grid and contains the basic functionality for evolving in time.</p> <p>See the ComFiT Library Reference below for a complete list of class methods and their usage.</p>  ComFiT Library Reference"},{"location":"ClassBaseSystem/#types-of-functions","title":"Types of functions","text":"<p>There are five different types of functions:</p> <ol> <li><code>conf_</code>-functions: Configures the state of the system, for instance by setting an initial condition. Output nothing.</li> <li><code>evolve_</code>-functions: Evolves the state in time according to some equation of motion.</li> <li><code>calc_</code>-functions: Calculates something from the state, returns that which has been calculated.</li> <li><code>plot_</code>-functions: Functions tailored to plot specific things. Output the axes and figure.</li> <li><code>get_</code>-functions: Functions that return a component of a tensor field. Relevant for symmetric and antisymmetric tensors where it is not convenient to save all elements.</li> </ol>"},{"location":"ClassBaseSystem/#general-keywords-and-parameters","title":"General keywords and parameters","text":"<p>The only required input argument to the BaseSystem class is the <code>dim</code> argument, which specifies the dimension of the system. In some cases, default values of other parameter depend on the value of <code>dim</code>, and are represented by curly brackets:</p> \\[ \\left \\lbrace \\begin{array}{l} \\textrm{default value if } \\texttt{dim }= 1 \\\\ \\textrm{default value if } \\texttt{dim }= 2  \\\\ \\textrm{default value if } \\texttt{dim }= 3  \\\\ \\end{array} \\right \\rbrace \\] <p>These are the optional keywords for the <code>BaseSystem</code> class.</p> Keyword Definition Default value <code>xmin</code> Minimum value of \\(x\\) of the simulation domain \\(0\\) <code>ymin</code> Minimum value of \\(y\\) of the simulation domain \\(0\\) <code>zmin</code> Minimum value of \\(z\\) of the simulation domain \\(0\\) <code>xmax</code> Maximum value of \\(x\\) of the simulation domain. \\(100\\) <code>ymax</code> Maximum value of \\(y\\) of the simulation domain \\(\\left \\lbrace \\begin{array}{c} 1 \\\\ 100 \\\\ 100 \\\\ \\end{array} \\right \\rbrace\\) <code>zmax</code> Maximum value of \\(z\\) of the simulation domain \\(\\left \\lbrace \\begin{array}{c} 1 \\\\ 1 \\\\  100 \\\\ \\end{array} \\right \\rbrace\\) <code>xRes</code> Resolution of the \\(x\\) axis \\(101\\) <code>yRes</code> Resolution of the \\(y\\) axis \\(\\left \\lbrace \\begin{array}{c} 1 \\\\ 101 \\\\  101 \\\\ \\end{array} \\right \\rbrace\\) <code>zRes</code> Resolution of the \\(z\\) axis \\(\\left \\lbrace \\begin{array}{c} 1 \\\\ 1 \\\\  101 \\\\ \\end{array} \\right \\rbrace\\) <code>dx</code> Spacing between points on the \\(x\\)-axis. Trumps <code>xRes</code> if provided. <code>xmax</code> will be modified to match. \\(\\frac{\\texttt{xmax}-\\texttt{xmin}}{\\texttt{xRes}} = 1\\) <code>dy</code> Spacing between points on the \\(y\\)-axis. Trumps <code>yRes</code> if provided. \\(\\frac{\\texttt{ymax}-\\texttt{ymin}}{\\texttt{yRes}} = 1\\) <code>dz</code> Spacing between points on the \\(x\\)-axis. Trumps <code>zRes</code> if provided. \\(\\frac{\\texttt{zmax}-\\texttt{zmin}}{\\texttt{zRes}} = 1\\) <code>xlim</code> List or tuple consisting of the lower and upper limit for the simulation domain in the \\(x\\)-direction. Trumps <code>xmin</code> and <code>xmax</code> if provided. \\((\\texttt{xmin},\\texttt{xmax}) = (0,101)\\) <code>ylim</code> List or tuple consisting of the lower and upper limit for the simulation domain in the \\(y\\)-direction. Trumps <code>ymin</code> and <code>ymax</code> if provided. \\((\\texttt{ymin},\\texttt{ymax}) = \\left \\lbrace \\begin{array}{c} (0,1) \\\\ (0,101) \\\\  (0,101) \\\\ \\end{array} \\right \\rbrace\\) <code>zlim</code> List or tuple consisting of the lower and upper limit for the simulation domain in the \\(z\\)-direction. Trumps <code>zmin</code> and <code>zmax</code> if provided. \\((\\texttt{xmin},\\texttt{xmax}) = \\left \\lbrace \\begin{array}{c} (0,1) \\\\ (0,1) \\\\  (0,101) \\\\ \\end{array} \\right \\rbrace\\) <code>time</code> Float specifying the time of initialization \\(0\\) <code>a0</code> Characteristic length scale associated with the system, in units of which all plots will be scaled. This is also the default width used with the coarse-graining operation. \\(1\\) <code>X</code> 2D numpy array with position coordinates. Typically used when the coordinates are not a regular grid. <code>None</code> <code>Y</code> 2D numpy array with position coordinates. Typically used when the coordinates are not a regular grid. <code>None</code> <code>Z</code> 2D numpy array with position coordinates. Typically used when the coordinates are not a regular grid. <code>None</code> <p>From these keywords, a number of useful parameters are constructed, given in the table below.</p> Parameter Definition Value <code>x</code> Numpy array with dimensions \\(\\left \\lbrace \\begin{array}{l} \\texttt{xRes} \\\\ \\texttt{xRes}\\times 1  \\\\ \\texttt{xRes}\\times 1 \\times 1  \\\\ \\end{array} \\right \\rbrace\\) consisting of the grid points from <code>xmin</code> to (including) <code>xmax-dx</code>. <code>y</code> Numpy array with dimensions \\(\\left \\lbrace \\begin{array}{l} 1 \\\\ 1 \\times \\texttt{yRes}  \\\\ 1 \\times \\texttt{yRes} \\times 1  \\\\ \\end{array} \\right \\rbrace\\) consisting of the grid points from <code>ymin</code> to (including) <code>ymax-dy</code>. <code>z</code> Numpy array with dimensions \\(\\left \\lbrace \\begin{array}{l} 1 \\\\ 1  \\\\ 1 \\times 1 \\times \\texttt{zRes} \\\\ \\end{array} \\right \\rbrace\\) consisting of the grid points from <code>zmin</code> to (including) <code>zmax-dz</code>. <code>xmidi</code> Index of the mid \\(x\\)-value. In the case of an odd <code>xRes</code>, this midpoint index will not hit the middle exactly but undershoot by <code>dx/2</code>. <code>xmid</code> The \\(x\\) value given by <code>xmidi</code>. <code>ymidi</code> Index of the mid \\(y\\)-value. In the case of an odd <code>yRes</code>, this midpoint index will not hit the middle exactly but undershoot by <code>dy/2</code>. <code>ymid</code> The \\(y\\) value given by <code>ymidi</code>. <code>zmidi</code> Index of the mid \\(z\\)-value. In the case of an odd <code>zRes</code>, this midpoint index will not hit the middle exactly but undershoot by <code>dz/2</code>. <code>zmid</code> The \\(z\\) value given by <code>zmidi</code>. <code>size_x</code> Size of the \\(x\\)-axis \\(\\texttt{xmax} - \\texttt{xmin}\\) <code>size_y</code> Size of the \\(y\\)-axis \\(\\texttt{ymax} - \\texttt{ymin}\\) (1 if <code>dim</code> \\(&lt;2\\)) <code>size_z</code> Size of the \\(z\\)-axis \\(\\texttt{zmax} - \\texttt{zmin}\\) (1 if <code>dim</code> \\(&lt;3\\)) <code>size_min</code> Minimum value of the simulation domain \\(\\left \\lbrace \\begin{array}{c} \\texttt{size_x} \\\\ \\texttt{min}(\\texttt{size_x}, \\texttt{size_y})\\\\ \\texttt{min}(\\texttt{size_x}, \\texttt{size_y}, \\texttt{size_z}) \\\\ \\end{array} \\right \\rbrace\\) <code>size_max</code> Maximum value of the simulation domain \\(\\left \\lbrace \\begin{array}{c} \\texttt{size_x} \\\\ \\texttt{max}(\\texttt{size_x}, \\texttt{size_y})\\\\ \\texttt{max}(\\texttt{size_x}, \\texttt{size_y}, \\texttt{size_z}) \\\\ \\end{array} \\right \\rbrace\\) <code>dV</code> Volume element of the grid. \\(\\left \\lbrace \\begin{array}{l} \\texttt{dx} \\\\ \\texttt{dx} \\times \\texttt{dy}  \\\\ \\texttt{dx} \\times \\texttt{dy} \\times \\texttt{dz}  \\\\ \\end{array} \\right \\rbrace\\). <code>volume</code> Volume of the simulation domain \\(\\texttt{size_x} \\times \\texttt{size_y} \\times \\texttt{size_z}\\) <p>Note that even though variables like <code>yRes</code>, <code>zRes</code> etc. are defined in cases where they are not relevant, such as for a \\(1\\)-dimensional system, they play no significant role in any calculations in such situations.</p> <p> </p> <p>Periodic boundary conditions means that <code>xmax</code> and <code>xmin</code> are identified as the same point. </p>"},{"location":"ClassBaseSystem/#fourier-transformations","title":"Fourier transformations","text":"<p>ComFiT is based on so-called spectral methods, which means using Fourier transformations to solve differential equations.  There are some subtleties to how the Fourier transformations work, which we will explain here. If you prefer a video explanation, you can watch the following video.</p>"},{"location":"ClassBaseSystem/#infinite-system","title":"Infinite system","text":"<p>For an infinite system, the Fourier transformation of a function \\(g(\\mathbf{r})\\) is given by</p> <p>The Fourier transform</p> \\[ g_{\\mathfrak f}(\\mathbf{k}) = \\mathcal F[g] = \\frac{1}{(2 \\pi)^d} \\int d^d r e^{-\\mathfrak i \\mathbf{k}\\cdot \\mathbf{r}} g(\\mathbf{r}), \\] <p>and the inverse Fourier transformation is given by</p> <p>The inverse Fourier transform</p> \\[ g(\\mathbf{r}) = \\mathcal  F^{-1}[g_\\mathfrak f] = \\int d^d k e^{\\mathfrak i \\mathbf{k}\\cdot \\mathbf{r}} g_{\\mathfrak f}(\\mathbf{k}). \\] <p>The factor \\(\\frac{1}{(2\\pi)^d}\\) in the definition of \\(g_{\\mathfrak f}\\) is a convention. It is useful when thinking of \\(g_{\\mathfrak f}(\\mathbf k)\\)  as the weight of the corresponding different Fourier components. If \\(g(\\mathbf r)\\) is a real function, then \\(g_{\\mathfrak f}(-\\mathbf k) = g_{\\mathfrak f}^*(\\mathbf k)\\). Thus, in principle, to calculate a derivative of a function, one can take the Fourier transformation, multiply by \\(\\mathfrak i \\mathbf k\\), and then take the inverse Fourier transformation.</p> \\[ \\frac{\\partial }{\\partial x} g(\\mathbf r) = \\mathcal F^{-1}[\\mathfrak i k_x \\mathcal F[g]], \\] <p>which is why we can calculate derivatives of a field <code>g</code> in ComFiT using</p> <p>Numerical derivative</p> <pre><code>dxg = bs.ifft(1j*bs.k[0]*bs.fft(g))\n</code></pre> <p>where <code>1j</code> is how to write the imaginary unit in Python. In fact, the combination <code>1j*bs.k[0]</code> is used so often that it is saved in its own property <code>bs.dif[0]</code>, so it is more common to see the derivative calculated as</p> <pre><code>dxg = bs.ifft(bs.dif[0]*bs.fft(g))\n</code></pre> <p>In reality, however, we are working with a periodic grid, which means that the Fourier transformation is not exactly the same as the one defined above. We will cover this next.</p>"},{"location":"ClassBaseSystem/#periodic-grid","title":"Periodic grid","text":"<p>In this section, we will show why we can calculate a numerical derivative as given above. In one dimension, on a periodic grid, a function is defined on a grid with \\(N\\) points, where it is assumed that the \\(N+1\\)th point (<code>x_n</code>) would be the same as the first point (<code>x_0</code>).</p> \\[ g_n = g(x_n) \\quad \\texttt{on} \\quad x_0, x_1,..., x_{N-1} \\] <p>Numerically, the Discrete Fourier transformation as</p> \\[ g_{\\mathfrak f m} = \\sum_{n=0}^{N-1} g(x_n) \\exp\\left (-\\mathfrak i \\frac{2\\pi m n}{N}\\right ) \\] <p>and the inverse discrete Fourier transformation is given by</p> \\[ g(x_n) = \\frac{1}{N} \\sum_{m=0}^{N-1} g_{\\mathfrak f m} \\exp \\left (\\mathfrak i \\frac{2\\pi m n}{N} \\right ). \\] <p>Difference between \\(g_{\\mathcal f}\\) and \\(g_{\\mathcal f m}\\)</p> <p>The Fourier transform \\(g_{\\mathfrak f}\\) is a function of the wavenumber \\(\\mathbf k\\), while \\(g_{\\mathfrak f m}\\) is a function of the index \\(m\\).</p> <p>\\(n\\) is related to the values \\(x_n\\) by</p> \\[ x_n = x_0 + n\\Delta x \\] <p>so</p> \\[ n = \\frac{x_n-x_0}{\\Delta x}. \\] <p>Inserting this into the Fourier transform, we get</p> \\[ g_{\\mathfrak f m} = \\sum_{n=0}^{N-1} g(x_n) \\exp\\left (-\\mathfrak i \\frac{2\\pi m }{N} \\frac{x_n-x_0}{\\Delta x}\\right ) \\] <p>Now, we define</p> \\[ k_m = \\frac{2\\pi m}{N \\Delta x} \\quad \\texttt{where} \\quad m=0,1,...,N-1, \\] <p>i.e,</p> \\[ k_m = 0, \\frac{2 \\pi}{N\\Delta x}, \\frac{4 \\pi}{N\\Delta x}, ... , \\frac{(N-1) 2 \\pi}{N\\Delta x}. \\] <p>So we see that \\(g_{\\mathfrak f k}\\) can be thought of as a function \\(g_{\\mathfrak f}\\), the Fourier transform of \\(g\\) evaluated at the points \\(k_n\\)</p> <p>The discrete Fourier transformation</p> \\[ g_{\\mathfrak f m} = g(k_m) = \\sum_{n=0}^{N-1} g(x_n) \\exp\\left (-\\mathfrak i k_m (x_n-x_0)\\right ) \\] <p>So we can write the inverse Fourier transform as</p> <p>The inverse discrete Fourier transformation</p> \\[ g(x_n) = \\frac{1}{N} \\sum_{m=0}^{N-1} g_{\\mathfrak f m} \\exp \\left (\\mathfrak i k_m (x_n-x_0) \\right ) \\] <p>From this expression, we see that if we multiply \\(g_{\\mathfrak f m}\\) with \\(\\mathfrak i k_m\\), we get</p> \\[ \\frac{1}{N} \\sum_{m=0}^{N-1} \\mathfrak i k_m g_{\\mathfrak f m} \\exp \\left (\\mathfrak i k_m (x_n-x_0) \\right ) = (\\partial_x g)(x_n) \\] <p>which justifies the numerical derivative given in the previous section.</p>"},{"location":"ClassBaseSystem/#the-nyquist-frequency","title":"The Nyquist frequency","text":"<p>The function <code>calc_wavenums</code> calculates the wavenumbers corresponding to the input position vectors given by <code>x</code>.</p> <pre><code># In ComFiT 1.8.7\ndef calc_wavenums(\n            self, \n            x: np.ndarray\n            ) -&gt; np.ndarray:\n        \"\"\"Calculates the wavenumbers corresponding to the input position vectors given by x.\n\n        Parameters\n        ----------\n        x : numpy.ndarray\n            1D array of x-positions.\n\n        Returns\n        -------\n        numpy.ndarray\n            1D array of wavenumbers with all the modes for the given x-array,\n            assuming periodicity from x[0] to x[0] over n intervals.\n\n        Examples\n        --------\n        &gt;&gt;&gt; x = np.array([-10, -5, 0, 5, 10])\n        &gt;&gt;&gt; k = instance_of_BaseSystem.calc_wavenums(self, x)\n        &gt;&gt;&gt; print(k)\n        [ 0.          0.25132741  0.50265482 -0.50265482 -0.25132741]\n        \"\"\"\n        n = len(x)\n\n        high = (n - 1) // 2\n        low = - (n // 2)\n\n        l = n * (x[1] - x[0])\n\n        k = np.concatenate((np.arange(0, high + 1), np.arange(low, 0))) * 2 * np.pi / l\n\n        return k\n</code></pre> <p>However, there is a slight difference between the wavenumbers calculated here and \\(k_m\\) in the previous section. The wavenumbers are the same up to \\(k_{N/2}\\) (which correspond to the so-called Nyquist frequency), but then the wavenumbers are negative, the reason for this is that for a function defined on a grid with \\(N\\) points, the highest wavenumber that can be resolved is \\(k_{N/2}\\), and wavenumbers \\(k_m\\) above are effective the same as negative wavenumbers. We will explain this next.</p> <p>The Nyquist frequency is given by</p> \\[ f_{NQ} = \\frac{1}{2\\Delta x}, \\] <p>which corresponds to the wavenumber</p> \\[ k_{NQ} = 2\\pi f_{NQ} = \\frac{\\pi}{\\Delta x} \\] <p>The value of \\(m\\) corresponding to this frequency is</p> \\[ \\frac{2\\pi m}{N\\Delta x} = \\frac{\\pi}{\\Delta x} \\] \\[ m = \\frac{N}{ 2 } \\] <p>Insert \\(- k_m\\), where \\(k_m&lt; k_{NQ}\\) into the Fourier transform, we get</p> \\[ g_{\\mathfrak f (-m)} = g(-k_m) = \\sum_{n=0}^{N-1} g(x_n) \\exp\\left (-\\mathfrak i (-k_m) (x_n-x_0)\\right ) \\] \\[  =  \\sum_{n=0}^{N-1} g(x_n) \\exp\\left (-\\mathfrak i (2k_{NQ} -k_m) (x_n-x_0)\\right ), \\] <p>where we have used that</p> \\[ \\exp(-\\mathfrak i 2 k_{NQ} (x_n-x_0)) = \\exp(-\\mathfrak i 2 \\frac{\\pi}{\\Delta x} (x_n-x_0)) = 1. \\] <p>This shows that finding the Fourier spectrum above the Nyquist frequency corresponds to finding the amplitude to negative wavenumbers. So, in the <code>calc_wavenum</code>  function, we set the first \\(N/2\\) k-values to  \\([ k_m ]_{m=1}^{N/2} = [0,..., N/2] \\cdot \\frac{2\\pi}{N \\Delta x}\\) and  then the following wavenumbers to \\([k_m]_{N/2}^{N} = [-N/2,...,-1]\\cdot \\frac{2\\pi}{N \\Delta x}\\)</p>"},{"location":"ClassBaseSystem/#plotting-a-fourier-field","title":"Plotting a Fourier field","text":"<p>From a numerical point of view, in calculating derivatives, we can use the discrete Fourier transformations directly, as outline above. For physical applications, however, the Fourier transformation defined on an infinite domain is more useful. In plotting the Fourier fields (passing the <code>fourier=True</code> parameter to the relevant plot function), therefore, we slightly modify <code>g_f</code>. We will detail this next.</p> <p>We can write the inverse discrete Fourier transformation as follows</p> \\[ g(x_n) =  \\sum_{m=0}^{N-1} \\left ( g_{\\mathfrak f m} \\frac{1}{N \\Delta k} e^{-\\mathfrak i k_m x_0} \\right ) \\exp \\left (\\mathfrak i k_m x_n \\right ) \\Delta k, \\] <p>The sum is a numerical approximation of the infinite inverse Fourier transform of \\(g_{\\mathfrak f}(\\mathbf k)\\), if we make the connection</p> <p>Connection between the discrete and infinite Fourier transformation</p> \\[ g_{\\mathfrak f}(\\mathbf k) \\approx g_{\\mathfrak f m} \\frac{1}{N \\Delta k} e^{-\\mathfrak i k_m x_0}. \\] <p>This is why, when passing the <code>fourier=True</code> parameter to the plot functions, the field is modified in the <code>_check_if_fourier_and_adjust</code> function in <code>base_system_plot</code> according by</p> <pre><code># In ComFiT 1.9.0\ndkx = self.k[0][1]-self.k[0][0]\nphase_shift = 1/(self.xRes*dkx)*np.exp(1j*self.k[0]*self.xmin)\nif self.dim &gt; 1:\n    dky = self.k[1][0,1]-self.k[1][0,0]\n    phase_shift = phase_shift*1/(self.yRes*dky)*np.exp(1j*self.k[1]*self.ymin)\nif self.dim &gt; 2:\n    dkz = self.k[2][0,0,1]-self.k[2][0,0,0]\n    phase_shift = phase_shift*1/(self.zRes*dkz)*np.exp(1j*self.k[2]*self.zmin)\n\nfield = np.fft.fftshift(phase_shift*field, axes=range(-self.dim, 0))\n</code></pre> <p>before passing the field to be plotted. This adjusts the discrete transform to approximate the continuous Fourier transform. The <code>fftshift</code> function is used to shift the zero frequency component to the center of the array.</p> Example <pre><code># In ComFiT 1.9.0\n\nimport comfit as cf\nimport numpy as np\n\nbs = cf.BaseSystem(1, xlim=[-10,10], xRes=101)\n\nfield = 0.5*bs.calc_Gaussian(position=1)\nfield_f = bs.fft(field)\n\nfig, ax = bs.plot_subplots(1,2)\nbs.plot_field(field, ax=ax[0], fig=fig, title='Real field')\nbs.plot_complex_field(field_f, fourier=True, ax=ax[1], fig=fig, title='Fourier transform')\n\nbs.plot_save(fig)\n</code></pre> <p> </p> <p>Notice that since the field is real, the Fourier transform is symmetric in amplitude and opposite in phase around the zero frequency.</p>"},{"location":"ClassBaseSystem/#coarse-graining","title":"Coarse-graining","text":"<p>A common and useful method is that of coarse-graining, which is defined as</p> \\[ \\rho = \\langle \\tilde \\rho \\rangle \\equiv \\int d^d r' \\mathcal K(\\mathbf r-\\mathbf r') \\tilde \\rho(\\mathbf r') , \\] <p>where \\(\\mathcal K(\\mathbf r'-\\mathbf r)\\) is a Gaussian kernel given by</p> \\[ \\mathcal K(\\mathbf r- \\mathbf r') = \\frac{1}{(2\\pi w^2)^{d/2}} \\exp\\left (-\\frac{(\\mathbf r-\\mathbf r')^2}{2w^2} \\right ), \\] <p>From a numerical point of view, this is done in Fourier space since, by the convolution theorem,</p> \\[ \\rho_{\\mathfrak f} = \\mathcal K_{\\mathfrak f} \\tilde \\rho_{\\mathfrak f}. \\] <p>Thus, we need the Fourier transform of \\(\\mathcal K\\), which is</p> \\[ \\mathcal K_{\\mathfrak f} = \\int d^d r e^{-i \\mathbf k \\cdot \\mathbf r} \\frac{1}{(2\\pi w^2)^{d/2}} \\exp\\left (-\\frac{\\mathbf r^2}{2w^2} \\right ) \\] \\[ = \\frac{1}{(2\\pi w^2)^{d/2}} \\prod_{n=1}^d \\int dr_n e^{-\\frac{1}{2 w^2} r_n^2 - \\mathfrak i k_n r_n} \\] \\[ = \\frac{1}{(2\\pi w^2)^{d/2}} \\prod_{n=1}^d \\int dr_n e^{-\\frac{1}{2 w^2} (r_n^2 + 2 \\mathfrak i w^2 k_n r_n)}   \\] \\[ = \\frac{1}{(2\\pi w^2)^{d/2}} \\prod_{n=1}^d e^{-\\frac{1}{2} w^2 k_n^2} \\int dr_n e^{-\\frac{1}{2 w^2} (r_n + \\mathfrak i w^2 k_n)^2} \\] \\[ = e^{-\\frac{1}{2} w^2 \\mathbf k^2}. \\] <p>This is why we have the following function</p> <pre><code>calc_Gaussian_filter_f\n</code></pre> <p>which calculates \\(\\mathcal K_{\\mathfrak f}\\).</p> <p>Typically, a field is coarse-grained with a width using the following piece of code</p> <pre><code>field = bs.ifft(bs.fft(field) * self.calc_Gaussian_filter_f(width))\n</code></pre> <p>The Gaussian function is actually so useful that is given by can be calculated using</p> <pre><code>Gaussian = bs.calc_Gaussian()\n</code></pre>"},{"location":"ClassBaseSystem/#vortex-fields","title":"Vortex fields","text":"<p>A general feature that will be reused is that of vortex fields. An angle field is a field where each point in space corresponds to an angle \\(\\theta \\in \\mathcal S^n\\). A vortex is a topological defect in an angle field, around which the circulation is some integer multiple of the covering of \\(\\mathcal S^n\\).</p>"},{"location":"ClassBaseSystem/#angle-field-of-a-single-vortex-in-two-dimensions","title":"Angle field of a single vortex in two dimensions","text":"<p>In two dimensions, the angle field takes values \\(\\theta \\in [-\\pi,\\pi \\rangle\\) and a vortex is a point \\(\\mathbf r_0\\). The angle field produced by the vortex has a circulation which is a multiple integer of \\(2\\pi\\), i.e.,</p> \\[ \\oint d\\theta = 2\\pi s_n, \\] <p>where \\(s_n\\) is the integer charge of the vortex. A possible angle field for a vortex positioned at \\((x_0,y_0)\\) is given by</p> \\[ \\theta_n = s_n \\textrm{atan2}(y-y_0,x-x_0) \\]"},{"location":"ClassBaseSystem/#angle-field-of-a-vortex-ring-in-three-dimensions","title":"Angle field of a vortex ring in three dimensions","text":"<p>For a ring vortex in three dimensions centered at \\(\\mathbf{r_0}\\) with radius \\(R\\), an angle field with the correct topological charge is given by first calculating the auxiliary quantities</p> \\[ m_2 = (\\mathbf{r}-\\mathbf{r_0})\\cdot \\mathbf{n}, \\] \\[ m_1 = |(\\mathbf{r}-\\mathbf{r_0}) - m_2\\mathbf{n}|. \\] <p>and then calculating</p> \\[ \\theta_1 = \\textrm{atan2}\\left (m_2,m_1+R\\right ) \\] \\[ \\theta_2 = \\textrm{atan2}\\left (m_2,m_1-R\\right ) . \\] <p>These expressions are based on the geometry depicted in the following figure.</p> <p> </p> <p>Vortex ring angle field explanation: Geometry of a vortex ring in the plane given by \\(\\vec n\\). \\(\\mathcal N'\\) is the plane normal to the tangent vector \\(\\vec t'\\) at \\(\\vec r'\\) upon which we impose a Cartesian coordinate system to determine the angles \\(\\theta_1\\), \\(\\theta_2\\) that are used to construct the (inset) initial angle field. Figure reprinted from Ref.<sup>3</sup> with permission.</p> <p>The angle field is then given by</p> \\[ \\theta(\\mathbf{r}) = \\textrm{mod}(\\theta_1+\\theta_2,[-\\pi,\\pi \\rangle) \\] <p>and is implemented in the function <code>calc_angle_field_vortex_ring</code>.</p>"},{"location":"ClassBaseSystem/#periodic-boundary-conditions-numerical-implementation-of-angle-fields","title":"Periodic boundary conditions: Numerical implementation of angle fields","text":"<p>Apart from the angle field of a single vortex, the other fields are compatible with periodic boundary conditions. The expressions for these fields, however, are really only valid for an infinite region. When this is imposed on periodic boundary conditions, it results in spurious boundary effects, especially if either of the vortices is placed near the edge of the simulation domain. By simply inserting the vortices directly, we get what is shown in the following figure (a).</p> <p> </p> <p>Numerical implementation of periodic angle fields: The angle field of panel (a) has been filtered by the field \\(F\\) with \\(w=0.2x_{\\textrm{max}}\\) to produce the periodic field given in panel (c). This field is simply rolled to produce a different position for the dipole in panel (d).</p> <p>This field is not periodic on the domain. This typically causes the unintentional nucleation of vortices and strain on the boundary. We therefore seek to modify the fields so that they don't \"see\" the periodic boundary conditions.</p> <p>In order to produce a field that is periodic on the domain, we transform the field \\(\\theta\\) to a complex field \\(\\eta = e^{i \\theta}\\). The argument of this complex field has the correct winding configuration of the vortex dipole. However, we want to smooth this field so that it goes to \\(1\\) (\\(\\theta=0)\\) at the borders. To do so, we introduce the filter function</p> \\[ F = \\frac{1}{2} \\left ( \\tanh((r^2-R^2)/w^2) - 1 \\right ), \\] <p>where \\(r^2 = (x-x_{\\textrm{mid}})^2 + (y-y_{\\textrm{mid}})^2\\), which is a function that is zero in the center region and goes to \\(1\\) at infinity over a width of \\(w\\). The filtered field \\(\\eta\\) is then obtained by making a smooth function that goes from the previous angle field according to</p> \\[ \\tilde \\eta = F \\cdot \\eta + (F-1) \\cdot 1. \\] <p>\\(\\tilde \\eta\\) is shown in Figure (c). The value of \\(w\\) and \\(R\\) can be adjusted and are found in the source code as <code>width</code> and <code>radius</code>, respectively.</p> <p>From this section, it is clear that the initial vortex dipole should not be too large. Thus, we have included a warning in case it is attempted to initiate a dipole with a larger distance than a certain threshold.</p>"},{"location":"ClassBaseSystem/#numerical-integration-scheme","title":"Numerical integration scheme","text":"<p>The systems of interest for this code are those that can be written on the form</p> \\[ \\partial_t \\psi = \\omega \\psi + N \\] <p>where \\(\\omega\\) is a linear differential operator and \\(N\\) is a non-linear operator (function of \\(\\psi\\)). The following table shows some examples from the models that we will discuss in the following chapters.</p> Model \\(\\omega\\) \\(\\omega_{\\mathfrak f}(\\mathbf{k})\\) \\(N\\) Quantum Mechanics $\\frac{1}{2}i \\nabla^2 $ \\(-\\frac{1}{2} i \\mathbf{k}^2\\) \\(- i V\\) BEC \\((i+\\gamma) (1+\\frac{1}{2}\\nabla^2)\\) \\((i+\\gamma) (1-\\frac{1}{2}\\mathbf k^2)\\) \\(- (i + \\gamma) (V_{ext} + \\psi \\psi^*)\\psi\\) Active Nematic \\(\\frac{K}{\\gamma} \\nabla^2 +\\frac{AB}{\\gamma}\\) \\(-\\frac{K}{\\gamma} k^2 +\\frac{AB}{\\gamma}\\) \\(- \\mathbf{u}\\cdot \\nabla Q + Q \\Omega -\\Omega Q - \\frac{2A}{\\gamma}Q^2_{kk}Q\\) <p>Table: Examples of time evolution operators, non-conserved.</p> <p>In the following, we will explain the method of evolution of exponential time differencing for stiff systems<sup>1</sup>. This will result in two integration schemes, the exponential time differencing second order Runge-Kutta 2 (ETD2RK) scheme and the forth order ETD4RK scheme. As in Ref. [coxExponentialTimeDifferencing2002], we will show an intuitive way to obtain the former and only recite the expressions for the latter.</p>"},{"location":"ClassBaseSystem/#the-etd2rk-scheme","title":"The ETD2RK scheme","text":"<p>To see how we obtain the ETD2RK scheme, we take the Fourier transformation of the time evolution equation, and get:</p> \\[ \\partial_t \\psi_{\\mathfrak f} = \\omega_{\\mathfrak f} \\psi_{\\mathfrak f} + N_{\\mathfrak f} . \\] \\[ (\\partial_t \\psi_{\\mathfrak f})e^{- \\omega_{\\mathfrak f} t}  -  \\omega_{\\mathfrak f} \\psi_{\\mathfrak f}  e^{- \\omega_{\\mathfrak f} t} = N_{\\mathfrak f} e^{- \\omega_{\\mathfrak f} t} . \\] \\[ \\partial_t (\\psi_{\\mathfrak f} e^{-\\omega_{\\mathfrak f} t} ) =  e^{-\\omega_{\\mathfrak f} t} N_{\\mathfrak f} \\] <p>Where \\(\\psi_{\\mathfrak f}(\\mathbf{k})\\) is the Fourier transform of \\(\\psi(\\mathbf{r})\\). Integrating from \\(t\\) to \\(t+ \\Delta t\\), one finds:</p> \\[ \\psi_{\\mathfrak f} (t+\\Delta t) e^{- \\omega_{\\mathfrak f}(t+ \\Delta t)} - \\psi_{\\mathfrak f} (t) e^{- \\omega_{\\mathfrak f} t} = \\int_t^{t+\\Delta t} e^{- \\omega_{\\mathfrak f} \\tau} N_{\\mathfrak f} d\\tau \\] <p>we multiply by \\(e^{ \\omega_{\\mathfrak f}(t+ \\Delta t)}\\) and get:</p> \\[ \\psi_{\\mathfrak f} (t+\\Delta t) = \\psi_{\\mathfrak f} (t) e^{\\omega_{\\mathfrak f} \\Delta t} + e^{ \\omega_{\\mathfrak f} (t+\\Delta t)} \\int_t^{t+\\Delta t} e^{- \\omega_{\\mathfrak f} \\tau} N_{\\mathfrak f} d\\tau \\] <p>This is an exact result, however, the last integral is unknown. In order to calculate the last integral here, we approximate it by \\(N (t+\\tau) \\approx N_{\\mathfrak f 0} +  \\frac{\\Delta N_{\\mathfrak f}}{\\Delta t} \\tau\\) where \\(N_{\\mathfrak f 0} = (N(\\psi(t))_{\\mathfrak f}\\) and \\(\\Delta N_{\\mathfrak f} = N_{\\mathfrak f}(t+\\Delta t)-N_{\\mathfrak f}(t)\\). We also change the integration limits from \\(\\tau \\in [t,t+\\Delta t]\\) to \\(\\tau \\in [0,\\Delta t]\\), which gives:</p> \\[ \\psi_{\\mathfrak f} (t+\\Delta t) = \\psi_{\\mathfrak f} (t) e^{ \\omega_{\\mathfrak f} \\Delta t} \\] \\[ + e^{\\omega_{\\mathfrak f} \\Delta t} \\frac{1}{- \\omega_{\\mathfrak f}} [e^{- \\omega_{\\mathfrak f} \\tau}]_0^{\\Delta t} N_{\\mathfrak f 0} + e^{ \\omega_{\\mathfrak f} \\Delta t} \\frac{1}{\\Delta t} [\\frac{\\tau e^{-\\omega_{\\mathfrak f} \\tau}}{-\\omega_{\\mathfrak f}} - \\frac{e^{-\\omega_{\\mathfrak f} \\tau}}{\\omega_{\\mathfrak f}^2}]_0^{\\Delta t} \\Delta N_{\\mathfrak f} \\] <p>To find \\(\\psi_{\\mathfrak f} (t+\\Delta t)\\), we would need to know the value \\(N_{\\mathfrak f} (t+\\Delta t)\\) before finding the state at \\(\\psi(t+\\Delta t)\\). To do this, we first find a predicted state \\(\\psi_a\\) by assuming \\(\\Delta N_{\\mathfrak f}=0\\) and calculating \\(\\psi(t)\\) according to the equation above. This lets us calculate an approximate \\(\\Delta N_{\\mathfrak f} = N_{\\mathfrak f a} - N_{\\mathfrak f 0}\\) and we use this in order to evolve \\(\\psi\\). This is the ETD2RK scheme.</p> \\[ \\psi_{\\mathfrak f a} = I_{\\mathfrak f 0} \\psi_{\\mathfrak f 0} + I_{\\mathfrak f 1} N_{\\mathfrak f 0} \\] \\[ \\psi_{\\mathfrak f} (t+\\Delta t) = \\psi_{\\mathfrak f a} + I_{\\mathfrak f 2} (N_{\\mathfrak f a} - N_{\\mathfrak f 0}) \\] \\[ \\textrm{where} \\] \\[ I_{\\mathfrak f 0} = e^{\\omega_{\\mathfrak f} \\Delta t} \\] \\[ I_{\\mathfrak f 1} = \\frac{1}{\\omega_{\\mathfrak f}} (e^{ \\omega_{\\mathfrak f} \\Delta t} - 1) \\] \\[ I_{\\mathfrak f 2} = \\frac{1}{\\omega_{\\mathfrak f}^2 \\Delta t} (e^{ \\omega_{\\mathfrak f} \\Delta t} -1  -\\omega_{\\mathfrak f} \\Delta t) \\] \\[ N_{\\mathfrak f 0} = (N(\\psi(t),t))_{\\mathfrak f} \\] \\[ N_{\\mathfrak f a} = (N(\\psi_a,t+\\Delta t))_{\\mathfrak f} \\] <p>Note that \\(N_{\\mathfrak f}\\) is a non-linear function of the field variable \\(\\psi\\), but can also be an explicit variable of time \\(t\\), i.e. \\(N_{\\mathfrak f}(\\psi,t)\\). Therefore, in the code, it has to be encoded as a function of these two variables <code>calc_nonlinear_evolution_function_f(self, psi, t)</code>.</p> <p>For numerical purposes, it is useful to calculate the small \\(\\omega_{\\mathfrak f}\\) limit. We expand the exponential in its Taylor series and keep the leading order term to get:</p> \\[ I_{\\mathfrak f 0} \\approx 1 \\] \\[ I_{\\mathfrak f 1} \\approx   \\frac{1}{\\omega_{\\mathfrak f}} (1 + \\omega_{\\mathfrak f} \\Delta t - 1) = \\Delta t \\] \\[ I_{\\mathfrak f 2} \\approx \\frac{1}{\\omega_{\\mathfrak f}^2 \\Delta t}  \\left ( 1 + \\omega_{\\mathfrak f} \\Delta t + \\frac{1}{2} ( \\omega_{\\mathfrak f} \\Delta t )^2  -1 - \\omega_{\\mathfrak f} \\Delta t \\right ) = \\frac{1}{2} \\Delta t \\] <p>In \\(I_{\\mathfrak f 1}\\), and \\(I_{\\mathfrak f 2}\\) there is a division by \\(0\\) when \\(\\omega_{\\mathfrak f} = 0\\). To avoid numerical issues related to this we use the above limits when \\(|\\omega_{\\mathfrak f}|\\) is smaller than a tolerance. We don't use the limit for \\(I_{\\mathfrak f 0}\\) since it doesn't contain a division by \\(0\\). The function <code>evolve_ETD2RK_loop</code> defined in the base system class performs an ETD2RK step. This function is called by the evolvers discussed in the model chapter if the method is defined as <code>method = \"ETD2RK\"</code>. This is the default solver if <code>method</code> is not set. The integrating factors for a given \\(\\omega_{\\mathfrak f}(\\mathbf{k})\\) can be found with the function <code>calc_evolution_integrating_factors_ETD2RK</code> where the variable <code>tol</code> gives when the factors should be replaced by their leading order Taylor expansion. Note that all solvers defined in the  class <code>BaseSystem</code> updates the time variable <code>self.t</code> to allow for time-dependents in the non-linear term.</p>"},{"location":"ClassBaseSystem/#the-etd4rk-scheme","title":"The ETD4RK scheme","text":"<p>Following Ref.<sup>1</sup>, we may generalize the method to a fourth order Runge-Kutta as follows</p> \\[ \\begin{aligned} \\psi_{\\mathfrak f a} &amp;= I_{\\mathfrak f 0} \\psi_{\\mathfrak f 0} +  I_{\\mathfrak f 1} N_{\\mathfrak f 0} \\\\ \\psi_{\\mathfrak f b} &amp;= I_{\\mathfrak f 0} \\psi_{\\mathfrak f 0} + I_{\\mathfrak f 1} N_{\\mathfrak f a} \\\\ \\psi_{\\mathfrak f c} &amp;= I_{\\mathfrak f 0} \\psi_{\\mathfrak f a} + I_{\\mathfrak f 1} (2 N_{\\mathfrak f b} - N_{\\mathfrak f 0}) \\\\ \\psi_{\\mathfrak f} (t+\\Delta t) &amp;= I_{\\mathfrak f 2} \\psi_{\\mathfrak f 0} + I_{\\mathfrak f 3} N_{\\mathfrak f 0} + I_{\\mathfrak f 4} (N_{\\mathfrak f a} + N_{\\mathfrak f b}) + I_{\\mathfrak f 5} N_{\\mathfrak f c} \\end{aligned} \\] <p>where</p> \\[ \\begin{aligned} I_{\\mathfrak f 0} &amp;= e^{\\omega_{\\mathfrak f} \\Delta t/2} \\\\ I_{\\mathfrak f 1} &amp;= \\frac{1}{\\omega_{\\mathfrak f}} ( e^{ \\omega_{\\mathfrak f} \\Delta t/2} - 1) \\\\ I_{\\mathfrak f 2} &amp;= e^{\\omega_{\\mathfrak f} \\Delta t} \\\\ I_{\\mathfrak f 3} &amp;= \\frac{1}{ \\omega_{\\mathfrak f}^3\\Delta t^2} \\left ( -4 -  \\omega_{\\mathfrak f} \\Delta t  + e^{\\omega_{\\mathfrak f} \\Delta t}(4-3\\omega_{\\mathfrak f} \\Delta t + \\omega_{\\mathfrak f}^2 \\Delta t^2 )  \\right ) \\\\ I_{\\mathfrak f 4} &amp;= \\frac{2}{ \\omega_{\\mathfrak f}^3\\Delta t^2} \\left ( 2 + \\omega_{\\mathfrak f} \\Delta t + e^{\\omega_{\\mathfrak f} \\Delta t}(-2 + \\omega_{\\mathfrak f} \\Delta t) \\right ) \\\\ I_{\\mathfrak f 5} &amp;= \\frac{1}{ \\omega_{\\mathfrak f}^3\\Delta t^2} \\left ( -4 - 3 \\omega_{\\mathfrak f} \\Delta t -  \\omega_{\\mathfrak f}^2 \\Delta t^2 + e^{\\omega_{\\mathfrak f} \\Delta t}(4-\\omega_{\\mathfrak f} \\Delta t) \\right ) \\end{aligned} \\] <p>Algorithm: The ETD4RK scheme</p> <p>In the small \\(\\omega_{\\mathfrak f}\\) limit, we have</p> \\[ I_{\\mathfrak f 0} \\approx 1 \\] \\[ I_{\\mathfrak f 1} \\approx \\frac{1}{2} \\Delta t \\] \\[ I_{\\mathfrak f 2} \\approx 1 \\] \\[ I_{\\mathfrak f 3} \\approx \\frac{1}{ \\omega_{\\mathfrak f}^3\\Delta t^2} \\times \\left ( -4 - \\omega_{\\mathfrak f} \\Delta t + (1 + \\omega_{\\mathfrak f} \\Delta t + \\frac{1}{2} (\\omega_{\\mathfrak f} \\Delta t)^2 + \\frac{1}{6} (\\omega_{\\mathfrak f} \\Delta t)^3 )(4-3\\omega_{\\mathfrak f} \\Delta t + \\omega_{\\mathfrak f}^2 \\Delta t^2 ) \\right ) \\] \\[ = \\frac{1}{ \\omega_{\\mathfrak f}^3\\Delta t^2} \\left ( \\frac{4}{6} (\\omega_{\\mathfrak f} \\Delta t)^3 - \\frac{3}{2} (\\omega_{\\mathfrak f} \\Delta t)^3 + (\\omega_{\\mathfrak f} \\Delta t)^3 \\right ) = \\frac{1}{6} \\Delta t \\] \\[ I_{\\mathfrak f 4} \\approx \\frac{2}{ \\omega_{\\mathfrak f}^3\\Delta t^2} \\left (2 + \\omega_{\\mathfrak f} \\Delta t +(1 + \\omega_{\\mathfrak f} \\Delta t + \\frac{1}{2} (\\omega_{\\mathfrak f} \\Delta t)^2 + \\frac{1}{6} (\\omega_{\\mathfrak f} \\Delta t)^3 )(-2 + \\omega_{\\mathfrak f} \\Delta t) \\right ) \\] \\[ = \\frac{2}{ \\omega_{\\mathfrak f}^3\\Delta t^2} \\left ( \\frac{1}{2} (\\omega_{\\mathfrak f} \\Delta t)^3-\\frac{2}{6}(\\omega_{\\mathfrak f} \\Delta t)^3 \\right ) = \\frac{1}{3} \\Delta t \\] \\[ I_{\\mathfrak f 5} = \\frac{1}{ \\omega_{\\mathfrak f}^3\\Delta t^2} \\times \\left ( -4 - 3 \\omega_{\\mathfrak f} \\Delta t -  \\omega_{\\mathfrak f}^2 \\Delta t^2 + (1 + \\omega_{\\mathfrak f} \\Delta t + \\frac{1}{2} (\\omega_{\\mathfrak f} \\Delta t)^2 + \\frac{1}{6} (\\omega_{\\mathfrak f} \\Delta t)^3 )(4-\\omega_{\\mathfrak f} \\Delta t) \\right )   \\] \\[ =\\frac{1}{ \\omega_{\\mathfrak f}^3\\Delta t^2} \\left ( \\frac{4}{6} (\\omega_{\\mathfrak f} \\Delta t)^3 - \\frac{1}{2} (\\omega_{\\mathfrak f} \\Delta t)^3 \\right ) = \\frac{1}{6} \\Delta t \\] <p>Similar as for the EDT2RK case \\(I_{\\mathfrak f 1}\\), \\(I_{\\mathfrak f 3}\\), \\(I_{\\mathfrak f 4}\\), and \\(I_{\\mathfrak f 5}\\) contains a division by \\(0\\) when \\(\\omega_{\\mathfrak f} = 0\\). We therefore replace these coefficients with their limits when \\(|\\omega_{\\mathfrak f}|\\) is smaller than a tolerance. This has been important in order to make the the code stable for some of the systems. In the same way as the EDT2RK scheme this is implemented as the function <code>self.evolve_ETD4RK_loop(self, integrating_factors_f, non_linear_evolution_function, field, field_f)</code> This function is called by the evolvers discussed in the model chapter if the method is defined as <code>method = \"ETD4RK\"</code>, the integrating factors are found with <code>self.calc_evolution_integrating_factors_ETD4RK(self, omega_f, tol=10**(-4))</code>.</p>"},{"location":"ClassBaseSystem/#the-fully-non-linear-limit","title":"The fully non-linear limit","text":"<p>It is both interesting and enlightening to see the fully non-linear limit of these equations, i.e., the limit in which \\(\\omega_{\\mathfrak f} =0\\), \\(N_{\\mathfrak f} = \\partial_t \\psi \\equiv \\dot{\\psi}_{\\mathfrak f}\\) and the small \\(\\omega_{\\mathfrak f}\\) approximations are exact. For the ETD2RK scheme, we get</p> \\[ \\psi_{\\mathfrak f a} = \\psi_{\\mathfrak f 0} +  \\dot{\\psi}_{0_f} \\Delta t \\] \\[ \\psi(t+\\Delta t)_f = \\psi_{\\mathfrak f 0} + \\dot{\\psi}_{\\mathfrak f 0} \\frac{\\Delta t}{2} + \\dot{\\psi}_{\\mathfrak f a} \\frac{\\Delta t}{2}, \\] <p>which is a two-stage Runge-Kutta method called Heun's method.</p> <p>The ETD4RK scheme becomes</p> \\[ \\psi_{\\mathfrak f a} = \\psi_{\\mathfrak f 0} +  \\dot{\\psi}_{\\mathfrak f 0} \\frac{\\Delta t}{2} \\] \\[ \\psi_{\\mathfrak f b} =  \\psi_{\\mathfrak f 0} +  \\dot{\\psi}_{\\mathfrak f a} \\frac{\\Delta t}{2} \\] \\[ \\psi_{\\mathfrak f c} = \\psi_{\\mathfrak f a} + ( 2 \\dot{\\psi}_{\\mathfrak f b} - \\dot{\\psi}_{\\mathfrak f 0}) \\frac{\\Delta t}{2} \\] \\[ \\psi_{\\mathfrak f} (t+\\Delta t) = \\psi_{\\mathfrak f 0} + \\frac{1}{6} ( \\dot{\\psi}_{\\mathfrak f 0} + 2 \\dot{\\psi}_{\\mathfrak f a} + 2 \\dot{\\psi}_{\\mathfrak f b} + \\dot{\\psi}_{\\mathfrak f c} ) \\Delta t. \\] <p>Note that this is not the typical Runge-Kutta 4 method, due to the differences in calculating \\(\\psi_{\\mathfrak f c}\\). The reason is that a straight-forward generalization of the Runge-Kutta 4 method will not produce a fourth-order method in the general case <sup>1</sup>.</p>"},{"location":"ClassBaseSystem/#the-fully-linear-limit","title":"The fully linear limit","text":"<p>If \\(N=0\\), the evolution equation changes to</p> \\[ \\psi_{\\mathfrak f}(t+\\Delta t) = e^{\\omega_{\\mathfrak f} \\Delta t} \\psi_{\\mathfrak f}. \\] <p>An example of this is the schr\u00f6dinger equation, for which \\(\\omega_{\\mathfrak f} = -\\frac{1}{2}  i \\mathbf k^2\\), so we get</p> \\[ \\psi_{\\mathfrak f}(t+\\Delta t) = e^{- i \\frac{1}{2} \\mathbf k^2 \\Delta t} \\psi_{\\mathfrak f}. \\] <p>This is an exact equation, of course, so you may evolve this free particle solution to any time.</p>"},{"location":"ClassBaseSystem/#testing","title":"Testing","text":"<p>In order to test the numerical methods, study the simplest model of a field equation with a (non-linear) forcing term, namely the heat equation</p> \\[ \\partial_t T = \\nabla^2 T + f(\\mathbf r), \\] <p>where \\(T\\) is the temperature in celsius, and \\(f(\\mathbf r)\\) is a forcing term, which we model as</p> \\[ f(\\mathbf r) = A (T_0-T) \\exp\\left (-\\frac{(\\mathbf r-\\mathbf r_0)^2}{2\\sigma^2}\\right ), \\] <p>which represents a heating element with temperature \\(T_0\\) placed at \\(\\mathbf r_0\\).</p> <p>As a benchmark, we use the <code>solve_ivp</code> of the <code>scipy</code> library <code>sp.integrate</code> to solve the equation using a finite difference method. The solutions match to a satisfactory degree, but a more thorough investigation into how the accuracy of the framework and integration methods scale with spatial and temporal resolution will be performed in the future. Tests are included in <code>test_base_system.py</code>, but for visual examination, here are animations of the initial condition \\(T=0\\) in all three dimensions</p> <p> </p> <p> </p> <p> </p>"},{"location":"ClassBaseSystem/#stochastic-noize","title":"Stochastic noize","text":"<p>Supose that the equation </p> \\[ \\partial_t T = \\omega(\\nabla) T + N(T)  \\] <p>has a noize term<sup>4</sup> in the non-linear part \\(N = N_{ns} + f\\).  We can in that case still do the integration with the integrating factor and get the following equation in fourier space</p> \\[ \\tilde T(t+\\Delta t) = e^{\\tilde \\omega \\Delta t} \\tilde T(t) +  e^{\\tilde \\omega \\Delta t}\\int_0^{\\Delta t} d\\tau e^{-\\tilde\\omega \\tau}  \\tilde N_{ns}(T, t+\\tau)   +  e^{\\tilde \\omega \\Delta t}\\int_0^{\\Delta t} d\\tau e^{-\\tilde\\omega \\tau}  \\tilde f(t+\\tau), \\] <p>The first of these integrals can be handled using one of the schemes described above,  but the later needs some extra care.  We have in fourier space</p> \\[ \\tilde T_s =  e^{\\tilde \\omega \\Delta t}\\int_0^{\\Delta t} d\\tau e^{-\\tilde\\omega \\tau}  \\tilde f(\\vec k,n\\Delta t+\\tau). \\] <p>Let now </p> \\[ \\hat f(\\vec k, \\tau) = \\tilde A(\\vec k) \\eta(k,\\tau), \\] <p>where \\(\\eta\\) is a white noise and \\(\\tilde A(\\vec k)\\) is a kernel that contains the spatial variation.  The mean value of \\(\\tilde T_s\\) vanishes, while the coorelation is</p> \\[ \\langle\\tilde T_s(t_1) \\tilde T_s(t_2) \\rangle = \\tilde A^2(\\vec k) e^{2\\tilde \\omega \\Delta t} \\int_0^{\\Delta t}\\int_0^{\\Delta t} d\\tau_1 d\\tau_2 e^{-\\tilde\\omega (\\tau_1 + \\tau_2)}  \\langle \\eta(n_1\\Delta t+\\tau_1)\\eta(n_2\\Delta t+\\tau_2)\\rangle \\] <p>where \\(t_1 =n_1 \\Delta t\\). Using that \\(\\eta\\) is delta corelated we can write</p> \\[ \\langle\\tilde T_s(t_1) \\tilde T_s(t_2) \\rangle = \\sigma^2 \\tilde A^2(\\vec k) e^{2\\tilde \\omega \\Delta t} \\int_0^{\\Delta t}\\int_0^{\\Delta t} d\\tau_1 d\\tau_2 e^{-\\tilde\\omega (\\tau_1 + \\tau_2)} \\delta((n_1 -n_2)\\Delta t + \\tau_1 -\\tau_2 ). \\] <p>Here \\(\\sigma\\) is the standard deviation of \\(\\eta\\). The delta function pics out \\(\\tau_1 = \\tau_2 +(n_2-n_1)\\Delta t\\), this is only posible if \\(n_1 = n_2\\) because \\(\\tau_i \\in (0,\\Delta t)\\), which gives </p> \\[  \\langle\\tilde T_s(t_1) \\tilde T_s(t_2) \\rangle = \\sigma^2 \\tilde A^2(\\vec k) e^{\\tilde \\omega \\Delta t [2 +(n_2-n_1)]} \\delta_{n_1,n_2}\\int_0^{\\Delta t}  d\\tau_2 e^{-2\\tilde\\omega \\tau_2 }.  \\] <p>the last integral is trivial and we can write this as</p> <p>$$ \\langle\\tilde T_s(t_1) \\tilde T_s(t_2) \\rangle = \\sigma^2 A^2(\\vec k) \\delta_{n_1,n_2} \\frac{1}{2\\hat \\omega} \\left(e^{2\\tilde \\omega \\Delta t } -1 \\right).  $$</p> <p>The stochastic part of the integral can therefore be evaluated as</p> \\[ \\tilde T_s = \\sigma \\tilde A(\\vec k)\\eta_k\\sqrt{ \\frac{1}{2\\hat \\omega} \\left(e^{2\\tilde \\omega \\Delta t } -1 \\right)}. \\] <p>For some wave vectors \\(\\omega \\Delta t\\) is close to zero. To avoid problems with divisions of zero we taylor expand the integrating factor when \\(|\\omega \\Delta t| &lt; 10^{-2}\\), and have</p> \\[ T_s(|\\omega|&lt; \\text{tol}) \\approx \\sigma \\tilde A(\\vec k\\eta_n)\\sqrt{ \\frac{1}{2\\hat \\omega} \\left(1 + 2\\tilde\\omega \\Delta t  -1 \\right)} = \\sigma \\tilde A(\\vec k)\\eta_n \\sqrt{  \\Delta t  }  \\] <p>Which is the same as would have been in a standard Euler-Maruyama scheme. </p>"},{"location":"ClassBaseSystem/#notes-on-the-kernel","title":"Notes on the kernel","text":"<p>The kernel \\(A(\\vec k)\\) is representing the spatial coherence of the noise.  It comes from the fourier transform of the noize, which in our notation reads</p> \\[ \\tilde f = \\int d\\vec r e^{i\\vec k \\cdot \\vec r} f(\\vec r,t) \\] <p>Assuming white noize in time we write this as</p> \\[ \\tilde f(k,t) = \\eta(t) \\int d\\vec r e^{i\\vec k \\cdot \\vec r} \\xi(\\vec r) \\] <p>With \\(\\xi\\) being some noize with a spatial distribution.  The kernel is then given by the integral</p> \\[ A(\\vec k) = \\int d\\vec r e^{i\\vec k \\cdot \\vec r} \\xi(\\vec r) \\]"},{"location":"ClassBaseSystem/#algorithms-for-tracking-defects","title":"Algorithms for tracking defects","text":"<p>To be written</p>"},{"location":"ClassBaseSystem/#calculating-the-velocity","title":"Calculating the velocity","text":"<p>The equations for the velocity are taken from Ref.<sup>2</sup>, simplified using Mathematica and then substituted for python code using chatGPT.</p> <ol> <li> <p>Cox, S. M., &amp; Matthews, P. C. (2002). Exponential Time Differencing for Stiff Systems. Journal of Computational Physics, 176(2), 430\u2013455. https://doi.org/10.1006/jcph.2002.6995 \u21a9\u21a9\u21a9</p> </li> <li> <p>Skogvoll, V., R\u00f8nning, J., Salvalaglio, M., &amp; Angheluta, L. (2023). A unified field theory of topological defects and non-linear local excitations. Npj Computational Materials, 9(1), Article 1. https://doi.org/10.1038/s41524-023-01077-6 \u21a9</p> </li> <li> <p>Skogvoll, V., Angheluta, L., Skaugen, A., Salvalaglio, M., &amp; Vi\u00f1als, J. (2022). A phase field crystal theory of the kinematics of dislocation lines. Journal of the Mechanics and Physics of Solids, 166, 104932. https://doi.org/10.1016/j.jmps.2022.104932\u00a0\u21a9</p> </li> <li> <p>Gallego, R. (2011) Predictor-corrector pseudospectral methods for stochastic partial differential equations with additive white noise. Applied Mathematics and Computation, 218(7), 3905-3917\u00a0\u21a9</p> </li> </ol>"},{"location":"ClassBoseEinsteinCondensate/","title":"Class: Bose-Einstein Condensate","text":"<p>There are two types of particles in the world: fermions and bosons. Whereas fermions can never occupy the same quantum state due to the Pauli Exclusion Principle, the same is not true for bosons. A Bose-Einstein condensate (BEC) is a state of matter consisting of ultra-cold bosons that undergo a phase transition at a low critical temperature, causing most bosons to occupy the lowest quantum energy state (the ground state) of the system. It was theorized by Satyendra Nath Bose and Albert Einstein in the 1920s as a new state of matter and was first produced experimentally in 1995 by Eric Cornell and Carl Wieman<sup>1</sup>.</p> <p>This class simulates a Bose-Einstein condensate in 1, 2, and 3 dimensions using the Gross-Pitaevskii equation (GPE).</p> <pre><code>file: comfit/models/bose_einstein_condensate.py \nclass: BoseEinsteinCondensate\n</code></pre> <p>See the ComFiT Library Reference below for a complete list of class methods and their usage.</p>  ComFiT Library Reference"},{"location":"ClassBoseEinsteinCondensate/#variables-and-parameters","title":"Variables and Parameters","text":"<p>The primary field in the Bose-Einstein condensate model is the complex wave function \\(\\psi\\):</p> <pre><code>bec.psi\n</code></pre> <p>The <code>BoseEinsteinCondensate</code> class accepts the same keyword arguments as the <code>BaseSystem</code> class, with the addition of the following specific parameter:</p> Keyword Definition Default Value <code>gamma</code> Dissipative factor \\(0.01\\) <p>This parameter allows for the customization and fine-tuning of the Bose-Einstein condensate simulation.</p>"},{"location":"ClassBoseEinsteinCondensate/#model","title":"Model","text":"<p>The BEC in the mean-field regime is described by the Gross-Pitaevskii equation (GPE)<sup>2</sup> <sup>3</sup>. This is a non-linear Schr\u00f6dinger equation which reads:</p> \\[ i\\hbar \\partial_t\\psi = \\left[-\\frac{\\hbar^2}{2m} \\nabla^2+ V_{ext}(\\mathbf{r}, t) -\\mu +g|\\psi|^2 \\right]\\psi. \\] <p>Here, \\(\\mu\\) is the chemical potential, \\(m\\) is the mass of the bosons, \\(g\\) is an interaction parameter, and \\(\\hbar\\) is the reduced Planck constant. \\(\\psi\\) is the wave function describing the condensate phase, and \\(V_{ext}(\\mathbf{r}, t)\\) is an external potential, which can depend on position \\(\\mathbf{r}\\) and time \\(t\\). The GPE can be obtained from the variational principle \\(\\mathfrak i \\hbar \\partial_t \\psi = \\frac{\\delta K}{\\delta \\psi^*}\\) <sup>3</sup><sup>4</sup> with the Hamiltonian:</p> \\[ K = \\int d\\mathbf{r} \\left[\\frac{\\hbar^2}{2m}|\\nabla\\psi|^2 +(V_{ext}(\\mathbf{r}, t) -\\mu)|\\psi|^2 +\\frac{g}{2}|\\psi|^4 \\right]. \\] <p>We introduce dimensionless units for length \\(\\xi = \\hbar/\\sqrt{m\\mu}\\) and time \\(\\tau = \\xi/c\\), and rescale the wave function as \\(\\psi \\rightarrow \\sqrt{\\frac{g}{\\mu}}\\psi\\). Additionally, we include a dissipative factor \\(\\gamma\\). This results in the damped Gross-Pitaevskii equation (dGPE) in dimensionless form as <sup>5</sup><sup>6</sup><sup>7</sup><sup>8</sup>:</p> <p>The damped Gross-Pitaevski equation (<code>evolve_dGPE</code>)</p> \\[ \\partial_t \\psi = -(\\mathfrak{i}+\\gamma) \\left[-\\frac{1}{2}\\nabla^2 + V_{ext}(\\mathbf{r}, t) -1 +|\\psi|^2 \\right]\\psi. \\] <p>We can split this equation into its linear and non-linear parts:</p> \\[ \\omega = (\\mathfrak{i}+\\gamma) (1 + \\frac{1}{2}\\nabla^2), \\quad N = - (\\mathfrak{i} + \\gamma) (V_{ext}(\\mathbf{r}, t) + |\\psi|^2)\\psi \\] <p>The Hamiltonian and its density in dimensionless units are calculated by the functions:</p> <pre><code>bec.calc_hamiltonian()\nbec.calc_hamiltonian_density()\n</code></pre>"},{"location":"ClassBoseEinsteinCondensate/#approximation-of-ground-states","title":"Approximation of Ground States","text":"<p>In simulations, it is often convenient to start in a configuration that is close to the ground state. We can estimate this ground state by noting that the GPE dissipates energy when evolved in imaginary time (\\(t \\rightarrow -it\\)) <sup>9</sup><sup>3</sup>. We refer to this as evolving the dGPE in imaginary time. Given an external potential \\(V_{ext}\\), we can therefore find an approximation to the ground state by starting with an initial guess and then removing energy from the guessed state by evolving the equations in imaginary time.</p> <p>To obtain an initial guess for the ground state for a given potential \\(V_{ext}\\), we use the Thomas-Fermi approximation <sup>2</sup><sup>3</sup>. In this approximation, we assume that \\(\\psi\\) is slowly varying, allowing us to neglect the Laplacian term (\\(\\nabla^2 \\psi \\approx 0\\)). Looking for stationary solutions (\\(\\partial_t \\psi = 0\\)) to the dGPE, we obtain the equation:</p> \\[ 0 = (V_{ext}(\\mathbf{r}) - 1 +|\\psi|^2 )\\psi. \\] <p>This equation has two solutions: \\(\\psi = 0\\) and \\(|\\psi|^2 = 1-V_{ext}(\\mathbf{r})\\). In the case where \\(V_{ext}(\\mathbf{r}) &gt; 1\\), only \\(\\psi = 0\\) is physically possible (since density \\(|\\psi|^2\\) must be non-negative). In the case where \\(V_{ext}(\\mathbf{r}) &lt; 1\\), both solutions exist. To determine which represents the ground state, we consider the Hamiltonian in the Thomas-Fermi limit:</p> \\[ K_{TF} = \\int d\\mathbf{r} \\left[(V_{ext}(\\mathbf{r}) -1)|\\psi|^2 + \\frac{1}{2} |\\psi|^4 \\right]. \\] <p>Inserting the ansatz \\(\\psi = 0\\) yields \\(K_{TF} = 0\\). Inserting the ansatz \\(|\\psi|^2 = 1-V_{ext}(\\mathbf{r})\\) gives \\(K_{TF} = \\int d\\mathbf{r} [-(1-V_{ext})^2 + \\frac{1}{2}(1-V_{ext})^2] = -\\frac{1}{2} \\int d\\mathbf{r} (1-V_{ext})^2\\), which is negative for \\(V_{ext}(\\mathbf{r}) &lt; 1\\). We therefore conclude that the Thomas-Fermi ground state approximation is:</p> \\[ \\psi_{TF}(\\mathbf{r}) = \\begin{cases}     0 &amp; \\text{if } V_{ext}(\\mathbf{r}) \\ge 1 \\\\     \\sqrt{1 -V_{ext}(\\mathbf{r})}  &amp; \\text{if } V_{ext}(\\mathbf{r}) &lt; 1     \\end{cases} \\] <p>This ground state guess can be initialized using:</p> <pre><code>bec.conf_initial_condition_Thomas_Fermi()\n</code></pre> <p>Once this guess is initialized, the wave function can be propagated in imaginary time to relax towards the true ground state using the function:</p> <pre><code>bec.evolve_relax(number_of_steps, method='ETD2RK')\n</code></pre> <p>Note that the external potential \\(V_{ext}\\) must be constant during this relaxation evolution.</p>"},{"location":"ClassBoseEinsteinCondensate/#potentials","title":"Potentials","text":"<p>Many interesting dynamics in a BEC arise from its interaction with an external potential. This potential is represented by the function:</p> <pre><code>bec.V_ext(t) \n</code></pre> <p>By default, this is initialized as a time-independent potential returning 0 everywhere. The potential can be changed using the function:</p> <pre><code>bec.conf_external_potential(V_ext, additive=False)\n</code></pre> <p>This function can set the potential based on whether <code>V_ext</code> is a callable function (expecting time <code>t</code> as an argument), a constant float, or a NumPy array representing a static potential field. If <code>additive=True</code>, the provided <code>V_ext</code> (if constant or an array) is added to the existing potential. If <code>V_ext</code> is a function, it should have the signature:</p> <pre><code>def V(t):\n     # calculate potential based on time t\n     # requires access to spatial coordinates like bec.x, bec.y, bec.z\n     potential_field = ... \n     return potential_field\n</code></pre> <p>The evolver will evaluate this function using the current simulation time <code>bec.time</code>. An example using a Gaussian stirring potential is provided in the example folder.</p> <p>To simplify setup, some common potentials are provided:</p> <ul> <li>Harmonic Potential: Configured using <code>bec.conf_harmonic_potential(trapping_strength)</code>. The potential takes the form \\(V_H(\\mathbf{r}) = \\texttt{trapping_strength} \\times |\\mathbf{r} - \\mathbf{r}_{mid}|^2\\).</li> <li>Gaussian Potential: Can be created using <code>bec.calc_Gaussian(position, width, top=strength)</code>. This returns \\(V_g(\\mathbf{r}) = \\texttt{strength} \\times e^{-|\\mathbf{r} - \\mathbf{r}_{position}|^2/(2 \\times \\texttt{width}^2)}\\). You would then use <code>conf_external_potential</code> to set this as the external potential.</li> </ul> <p>Much of the interesting physics occurs when the potential is time-dependent. For this, one can define a function <code>V(t)</code> as shown above and update the external potential by calling <code>bec.conf_external_potential(V)</code>.</p>"},{"location":"ClassBoseEinsteinCondensate/#hydrodynamics","title":"Hydrodynamics","text":"<p>The dGPE can be transformed into a hydrodynamic description of the BEC. The first step is to introduce the Madelung transformation \\(\\psi = \\sqrt{\\rho} e^{i\\theta}\\), where \\(\\rho = |\\psi|^2\\) is the superfluid density <sup>3</sup>. For \\(\\gamma = 0\\), this density is conserved and satisfies the continuity equation:</p> \\[ \\partial_t \\rho + \\nabla\\cdot \\mathbf{J}_s = 0, \\] <p>with the superfluid current given by:</p> \\[ \\mathbf{J}_s = \\Im(\\psi^* \\nabla \\psi) = \\rho \\nabla \\theta = \\rho \\mathbf{v}_s. \\] <p>Here, the superfluid velocity is introduced as \\(\\mathbf{v}_s = \\nabla \\theta\\). The superfluid current can be calculated using the function:</p> <pre><code>bec.calc_superfluid_current()   \n</code></pre> <p>We can also substitute the Madelung transformation into the Hamiltonian to get <sup>7</sup><sup>10</sup>:</p> <p>$$ K = \\int d\\mathbf{r} \\left[\\frac{1}{2}\\rho v_s^2 +\\frac{1}{8} \\frac{|\\nabla \\rho|^2}{\\rho} + (V_{ext}-1)\\rho +\\frac{1}{2}\\rho^2 \\right]. $$ Note: The original text had \\(\\rho^4\\), but based on the GPE Hamiltonian, it should be \\(\\rho^2\\) (corresponding to \\(|\\psi|^4\\)).</p> <p>The first term, \\(\\frac{1}{2}\\rho v_s^2\\), represents the kinetic energy density of the condensate. To calculate the total kinetic energy, it is convenient to introduce the density-weighted velocity \\(\\mathbf{u} = \\sqrt{\\rho}\\mathbf{v}_s\\) <sup>7</sup>. This quantity has the advantage of not being singular at the core of topological defects (where \\(\\rho \\to 0\\)). Using this, the kinetic energy can be written as \\(E_k = \\int d\\mathbf{r} \\frac{1}{2}|\\mathbf{u}|^2\\). The density-weighted velocity and the total kinetic energy can be calculated using the functions:</p> <pre><code>bec.calc_velocity()\nbec.calc_kinetic_energy()\n</code></pre> <p>Furthermore, by inserting the Madelung transformation into the dGPE, one can derive equations resembling the Navier-Stokes equations <sup>3</sup><sup>7</sup>:</p> \\[\\begin{aligned}     \\partial_t \\rho + \\nabla\\cdot(\\rho \\mathbf{v}_s) &amp;= 2\\gamma \\rho (1-V_{eff}), \\\\     \\partial_t \\mathbf{v}_s + (\\mathbf{v}_s \\cdot \\nabla) \\mathbf{v}_s &amp;=  - \\nabla(V_{ext} + \\rho - \\frac{1}{2\\sqrt{\\rho}}\\nabla^2\\sqrt{\\rho}) + \\frac{\\gamma}{2}\\nabla^2 \\mathbf{v}_s. \\end{aligned}\\] <p>Note: The exact form of the momentum equation can vary depending on the derivation details and approximations (e.g., quantum pressure term \\(\\frac{1}{2\\sqrt{\\rho}}\\nabla^2\\sqrt{\\rho}\\)). The density equation shows that the condensate density is only conserved when \\(\\gamma = 0\\). \\(V_{eff}\\) includes the external potential and interaction terms.</p>"},{"location":"ClassBoseEinsteinCondensate/#forces-on-external-potential","title":"Forces on External Potential","text":"<p>To study how the BEC interacts with impurities, one can model the impurity as an external potential (e.g., Gaussian) and measure the force exerted on it <sup>11</sup><sup>12</sup><sup>13</sup>. According to the Ehrenfest theorem, the force exerted by the external potential on the condensate is given by \\(\\mathbf{F}_{cond} = -\\langle \\nabla V_{ext}\\rangle\\). By Newton's third law, the force exerted by the condensate on the potential (or the object creating it) is \\(\\mathbf{F}_{pot} = - \\mathbf{F}_{cond} = \\langle \\nabla V_{ext}\\rangle\\). Written explicitly, this is:</p> \\[ \\mathbf{F}_{pot} = \\int d\\mathbf{r} |\\psi|^2 \\nabla V_{ext}(\\mathbf{r}) = -\\int d\\mathbf{r} V_{ext}(\\mathbf{r}) \\nabla(|\\psi|^2), \\] <p>where the second equality follows from integration by parts (assuming boundary terms vanish). This force is calculated by the function:</p> <pre><code>bec.calc_force_on_external_potential()\n</code></pre> <p>Note that this calculates the total force exerted by the condensate on the source of the entire external potential \\(V_{ext}\\).</p>"},{"location":"ClassBoseEinsteinCondensate/#quantized-vortices","title":"Quantized Vortices","text":"<p>Topological defects in a BEC manifest as quantized vortices. This arises because the superfluid velocity is the gradient of the phase, \\(\\mathbf{v}_s = \\nabla \\theta\\). Consequently, the circulation around any closed loop \\(C\\) is quantized:</p> \\[ \\Gamma = \\oint_C d\\mathbf{l} \\cdot \\mathbf{v}_s = \\oint_C d\\mathbf{l} \\cdot \\nabla \\theta = \\Delta\\theta = 2\\pi n, \\] <p>where \\(n\\) must be an integer for the wave function \\(\\psi = \\sqrt{\\rho}e^{i\\theta}\\) to be single-valued. In two dimensions, these vortices are point defects, while in three dimensions, they are line defects. The locations (nodes) of these vortices can be identified using the function:</p> <pre><code>bec.calc_vortex_nodes(dt_psi=None)\n</code></pre> <p>This function finds the vortex nodes in two or three dimensions. If the time derivative of the wave function, \\(\\partial_t \\psi\\), is provided as the argument <code>dt_psi</code>, the function also calculates the velocity of the defects.</p> <p>Vortices can be created in several ways: by manually inserting them into the initial state (using functions like <code>conf_insert_vortex</code>, <code>conf_insert_vortex_dipole</code>, <code>conf_insert_vortex_ring</code>), by stirring the condensate with a moving potential, or by relaxing a disordered initial state (quenching).</p>"},{"location":"ClassBoseEinsteinCondensate/#comoving-frame","title":"Comoving Frame","text":"<p>When studying a BEC stirred by a potential moving at velocity \\(-\\mathbf{V}_p\\), it is sometimes convenient to switch to a reference frame moving with the potential (the comoving frame). In this frame, the potential is stationary, and the BEC flows past it with velocity \\(\\mathbf{V}_p\\). The transformed dGPE reads:</p> \\[ \\partial_t \\psi = -\\mathbf{V}_p \\cdot \\nabla \\psi - (\\mathfrak{i}+\\gamma) \\left[-\\frac{1}{2}\\nabla^2 + V_{ext}(\\mathbf{r}) -1 +|\\psi|^2 \\right]\\psi. \\] <p>Note that a standard Galilean transformation of the GPE (\\(\\gamma=0\\)) often includes a phase factor \\(e^{i(\\mathbf{V}_p \\cdot \\mathbf{r} - \\frac{1}{2} V_p^2 t)}\\) to ensure the transformed velocity represents the velocity in the new frame<sup>14</sup>. However, the dGPE (\\(\\gamma \\neq 0\\)) is not Galilean invariant, so we omit this phase factor here. Consequently, the superfluid velocity calculated from \\(\\psi\\) in this frame still represents the velocity in the original lab frame <sup>11</sup>.</p> <p>To prevent artificial recycling of excitations from the outflow boundary back into the incoming flow due to periodic boundary conditions, a dissipative buffer region can be introduced around the computational domain where \\(\\gamma\\) is significantly larger than in the bulk <sup>15</sup>. The dissipative factor becomes a function of space, typically defined as:</p> \\[ \\gamma(\\mathbf{r}) = \\max[\\gamma_x(x), \\gamma_y(y), \\gamma_z(z)] \\quad \\text{(3D)} \\] <p>or</p> \\[ \\gamma(\\mathbf{r}) = \\max[\\gamma_x(x), \\gamma_y(y)] \\quad \\text{(2D)} \\] <p>where, for example:</p> \\[ \\gamma_x(x) = \\gamma_0 + \\frac{\\gamma_{max}-\\gamma_0}{2} \\left( \\tanh\\left(\\frac{x - (x_{mid} + w_x/2)}{d}\\right) - \\tanh\\left(\\frac{x - (x_{mid} - w_x/2)}{d}\\right) + 2 \\right). \\] <p>Here, \\(\\gamma_0\\) is the bulk dissipation value, \\(\\gamma_{max}\\) is the high value in the buffer (often implicitly set, e.g., \\(\\gamma_{max} \\approx \\gamma_0 + 1\\)), \\(d\\) is the width of the interface between the bulk and the buffer, and \\(w_x\\) defines the size of the central low-dissipation region along the x-axis. Similar functions define \\(\\gamma_y(y)\\) and \\(\\gamma_z(z)\\). When \\(\\gamma\\) depends on space, the term involving \\(\\gamma \\nabla^2 \\psi\\) can no longer be treated as part of the linear operator \\(\\omega\\) and must be handled within the non-linear term calculation. This is managed by the specific evolver:</p> <pre><code>bec.evolve_comoving_dGPE(number_of_steps, velx, method='ETD2RK')\n</code></pre> <p>This evolver assumes the boost (and thus the flow) is in the positive x-direction with speed <code>velx</code> and correctly handles the spatially dependent dissipation \\(\\gamma(\\mathbf{r})\\).</p> <ol> <li> <p>Anderson, M. H., Ensher, J. R., Matthews, M. R., Wieman, C. E., &amp; Cornell, E. A. (1995). Observation of Bose-Einstein Condensation in a Dilute Atomic Vapor. Science, 269(5221), 198\u2013201. https://doi.org/10.1126/science.269.5221.198 \u21a9</p> </li> <li> <p>Dalfovo, F., Giorgini, S., Pitaevskii, L. P. and Stringari, S. (1999). Theory of Bose-Einstein condensation in trapped gases. Reviews of Modern Physics. 71, 3, 463. https://doi.org/10.1103/RevModPhys.71.463 \u21a9\u21a9</p> </li> <li> <p>Kevrekidis, P. G., Frantzeskakis, D. J. and Carretero-Gonz\u00e1lez, R. (2008). Emergent nonlinear phenomena in Bose-Einstein condensates: theory and experiment. Springer Science &amp; Business Media. Berlin.\u00a0\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Pitaevskii, L. and Stringari, S. (2016). Bose-Einstein Condensation and Superfluidity. Oxford University Press. https://doi.org/10.1093/acprof:oso/9780198758884.001.0001 \u21a9</p> </li> <li> <p>Gardiner, C. W. and Davis, M. J. (2003). The stochastic Gross-Pitaevskii equation: II. Journal of Physics B: Atomic, Molecular and Optical Physics. 36, 23, 4731. https://doi.org/10.1088/0953-4075/36/23/010 \u21a9</p> </li> <li> <p>Rooney, S. J., Blakie, P. B. and Bradley, A. S. (2012). Stochastic projected Gross-Pitaevskii equation. Physical Review A. 86, 5, 053634. https://doi.org/10.1103/PhysRevA.86.053634 \u21a9</p> </li> <li> <p>Bradley, A. S. and Anderson, B. P. (2012). Energy spectra of vortex distributions in two-dimensional quantum turbulence. Physical Review X. 2, 4, 041001 https://doi.org/10.1103/PhysRevX.2.041001 \u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Skaugen, A. (2018). A Unified Perspective on Two-Dimensional Quantum Turbulence and Plasticity. PhD Thesis, University of Oslo. http://urn.nb.no/URN:NBN:no-69394 \u21a9</p> </li> <li> <p>Minguzzi, A., Succi, S., Toschi, F., Tosi, M. P. and Vignolo, P. (2004). Numerical methods for atomic quantum gases with applications to Bose-Einstein condensates and to ultracold fermions. Physics reports. 395, 4-5, 223-355. https://doi.org/10.1016/j.physrep.2004.02.001 \u21a9</p> </li> <li> <p>Nore, C., Abid, M. and Brachet, M. E. (1997). Kolmogorov turbulence in low-temperature superflows. Physical review letters. 78, 20, 3896. https://doi.org/10.1103/PhysRevLett.78.3896 \u21a9</p> </li> <li> <p>R\u00f8nning, J., Skaugen, A., Hern\u00e1ndez-Garc\u00eda, E., L\u00f3pez, C. and Angheluta, L. (2020). Classical analogies for the force acting on an impurity in a Bose-Einstein condensate. New Journal of Physics. 22, 7, 073018. https://doi.org/10.1088/1367-2630/ab95de \u21a9\u21a9</p> </li> <li> <p>Astrakharchik, G. E. and Pitaevskii, L. P. (2004). Motion of a heavy impurity through a {Bose-Einstein} condensate. Physical Review A. 70, 1, 013608. https://doi.org/10.1103/PhysRevA.70.013608 \u21a9</p> </li> <li> <p>Pinsker, F. (2017). Gaussian impurity moving through a {Bose-Einstein} superfluid. Physica B: Condensed Matter. 521, 36-42. https://doi.org/10.1016/j.physb.2017.06.038 \u21a9</p> </li> <li> <p>Pismen, L.M. (1999). Vortices in Nonlinear Fields: From Liquid Crystals to Superfluids, From Non-Equilibrium Patterns to Cosmic Strings. Oxford university press. Oxford\u00a0\u21a9</p> </li> <li> <p>Reeves, M. T., Billam, T. P., Anderson, B. P. and Bradley, A. S. (2015). Identifying a superfluid Reynolds number via dynamical similarity. Physical Review Letters. 114, 15, 155302. https://doi.org/10.1103/PhysRevLett.114.155302 \u21a9</p> </li> </ol>"},{"location":"ClassNematicLiquidCrystal/","title":"Class: Nematic Liquid Crystal","text":"<p>A nematic liquid crystal is a state of matter between a solid and a liquid.  It is characterized by the orientation of the molecules, which is ordered, but not the position.  The molecules are rod-like and the orientation is described by a unit vector, the nematic director.  The nematic liquid crystal is the simplest form of liquid crystal, and is characterized by the nematic director being the only order parameter.  The nematic liquid crystal is used to describe the behavior of many biological systems, such as the cytoskeleton, and is also used in many technological applications, such as in liquid crystal displays.</p> <p>In this class, we simulate an active nematic liquid crystal using [framework].</p> <pre><code>file: comfit/models/nematic_liquid_crystal.py \nclass: NematicLiquidCrystal\n</code></pre> <p>See the ComFiT Library Reference below for a complete list of class methods and their usage.</p>  ComFiT Library Reference"},{"location":"ClassNematicLiquidCrystal/#variables-and-parameters","title":"Variables and parameters","text":"<p>The primary variables are the symmetric traceless tensor \\(Q\\) and the velocity field \\(\\mathbf{u}\\)</p> <pre><code>nem.Q \nnem.u\n</code></pre> <p>The NematicLiquidCrystal class takes the same keyword as the BaseSystem class in addition to</p> Keyword Definition Default value <code>alpha</code> The activity parameter. Negative is extensile \\(-1\\) <code>K</code> Frank elastic constant \\(1\\) <code>A</code> Parameter in front of \\(\\text{Tr}(Q^2)\\) in the free-energy \\(1\\) <code>B</code> Parameter in front of \\(\\text{Tr}(Q^2)^2\\) in the free-energy \\(1\\) <code>C</code> Parameter in front of \\(\\text{Tr}(Q^3)\\) in the free-energy. 3D only \\(0\\) <code>gamma</code> Rotational diffusion \\(1\\) <code>Gamma</code> Friction \\(0\\) <code>eta</code> Viscosity \\(1\\) <p>These parameters are discussed in more detail in the model section. </p>"},{"location":"ClassNematicLiquidCrystal/#note-on-the-tensor-parameters","title":"Note on the tensor parameters","text":"<p>The \\(Q\\) tensor is given by the nematic director as</p> \\[ Q_{ij} = S (n_i n_j - \\frac{1}{d} \\delta_{ij}) \\] <p>in \\(d\\) dimensions. To take advantage of its symmetric nature we have saved \\(Q\\) as a vector field, which in two and three dimensions takes the forms</p> \\[ \\begin{aligned} \\mathbf{Q} &amp;= [ Q_{xx},Q_{xy} ] \\\\ \\mathbf{Q} &amp;= [ Q_{xx},Q_{xy},Q_{xz},Q_{yy},Q_{yz}] \\end{aligned} \\] <p>respectivly. We can translate from tensor indexes to the right value stored in the vector by using the function</p> <pre><code>get_sym_tl(self,Q,i,j)\n</code></pre> <p>This returns the element \\(Q_{ij}\\) of a symmetric and traceless tensor field. In addition to this we also have the function</p> <pre><code>get_anti_sym(self,omega,i,j)\n</code></pre> <p>so that we can optimally store the antisymetric tensors as well. In two dimensions these only have one independent component, which is stored as a scalar field, while in three dimensions it is stored as</p> \\[ \\mathbf \\Omega = [\\Omega_{xy}, \\Omega_{xz}, \\Omega_{yz}] \\] <p>In order to calculate the director field \\(\\mathbf n\\) and the amount of order \\(S\\) in two dimensions we use that we can map the orderparameter to the complex field \\(\\psi = Q_{xx} +  iQ_{xy} =Se^{2i\\theta}/2\\), where \\(\\theta\\)  is the angle of the director field. In three dimensions we use that \\(S\\) is given by the largest eigenvalue as \\(S = 3\\lambda/2\\) with the director being the coresponding eigenvector <sup>1</sup>. This is taken care of in the function</p> <pre><code>calc_order_and_director(self)\n</code></pre> <p>Wich returns <code>S, n</code>, where <code>n</code> is the director field. Note that a nematic liquid crystall can be biaxial and given as</p> \\[ Q_{ij} = S (n_i n_j - \\frac{1}{3} \\delta_{ij}) + P (m_i m_j -l_i l_j) \\] <p>where \\(P\\) is given by the difference between the smallest eigenvalues and \\(\\mathbf m\\) and \\(\\mathbf l\\) is the corresponding eigenvectors.</p>"},{"location":"ClassNematicLiquidCrystal/#model","title":"Model","text":"<p>We model the active nematic using a set of coupled differential equations, namely the Edvard-Beris equation coupled to the Stokes equation <sup>2</sup> <sup>3</sup> <sup>4</sup> <sup>5</sup></p> <p>The Edward-Beris equation (<code>evolve_nematic</code>)</p> \\[     \\begin{aligned}         \\partial_t Q + \\mathbf u\\cdot \\nabla Q +\\Omega Q -Q \\Omega &amp;=\\gamma^{-1}H,         \\\\         (\\Gamma- \\eta \\nabla^2 )\\mathbf u &amp;= -\\nabla P + \\nabla \\cdot \\sigma^a(Q) + \\nabla \\cdot \\sigma^p, \\\\         \\nabla \\cdot \\mathbf u &amp;= 0.     \\end{aligned} \\] <p>Here \\(2\\Omega_{ij} = \\partial_i u_j - \\partial_j u_i\\) is the vorticity tensor, \\(P\\) is the pressure, \\(\\gamma\\) is the rotational friction coefficient, \\(\\sigma^p\\) is the passive stress, \\(\\Gamma\\) is friction with a substrate, \\(\\eta\\) is viscosity and the active stress is given by \\(\\sigma^a = \\alpha Q\\). The vorticity tensor is calculated by the function</p> <pre><code>calc_vorticity_tensor(self)\n</code></pre> <p>Note that the velocity has to be updated before this function is called. The calculation of the pressure and velocity is described furhter down. Since the active stress is simply proportional to \\(Q\\) we have not included any function to calculate it, but calculate the force directly with the function</p> <pre><code>calc_active_force_f(self,Q)\n</code></pre> <p>The molecular field \\(H\\) is given as</p> \\[H_{ij} =  -\\frac{\\delta \\mathcal{F}}{\\delta Q_{ij}} + \\frac{\\delta_{ij}}{d} \\text{Tr}\\left(\\frac{\\delta F}{\\delta Q}\\right) \\] <p>The last term is here to make it trace less. For the free energy we use</p> \\[\\mathcal F = \\int \\left( K |\\nabla Q|^2 - \\frac{A}{2} \\left[ B \\text{Tr}(Q^2) -\\text{Tr}(Q^2)^2   \\right] -\\frac{C}{3}\\text{Tr}(Q^3) \\right), \\] <p>where it is assumed that there is a single Frank elastic constant \\(K\\). Here \\(Q^2 = QQ\\) denote a standard matrix multiplication, and similar for \\(Q^3\\). We therfore have that \\(\\text{Tr}(Q^2)^2 = Q_{kj}Q_{jk}\\). The \\(\\text{Tr}(Q^3)\\) term only exists in three dimensons since it is zero for all symetric traceless matrices in two dimensions. The molecular field is given as</p> \\[  H_{ij} =  K \\nabla^2 Q_{ij} + A(B - 2Q^2_{kk})Q_{ij} +  \\begin{cases}   0, &amp; \\text{dim} = 2 \\\\  C Q^2_{ij} - \\frac{C}{3}Q^2_{kk} \\delta_{ij}, &amp; \\text{dim} = 3 \\end{cases} \\] <p>For the passive stress we use \\(\\(\\sigma_{ij} = Q_{ik}H_{kj}-H_{ik}Q_{kj} - K (\\partial_i Q_{kl})(\\partial_jQ_{kl}).\\)\\) Note that we use the convention that the dot product between a vector and a tensor contracts the last component when calculating the divergence of this. The first two terms is the asymmetric stress, while the second term is the Ericksen stress. Terms due to flow allingment and anisotropic viscosity are not included. The molecular field and the passive stress  are calculated by the functions</p> <pre><code>calc_molecular_field(self,Q)\ncalc_passive_stress_f(self,Q)\n</code></pre> <p>The linear and non-linear part of the evolution equation for \\(Q\\), eq.\u00a0is given as</p> \\[ \\begin{aligned} \\omega(\\nabla) &amp;= \\frac{K}{\\gamma} \\nabla^2 +\\frac{AB}{\\gamma}, \\\\ N(Q,t) &amp;= - \\mathbf u\\cdot \\nabla Q + Q \\Omega -\\Omega Q - \\frac{2A}{\\gamma}Q^2_{kk}Q +\\begin{cases}   0, &amp; \\text{dim} = 2 \\\\  C Q^2 - \\frac{C}{3}Q^2_{kk} I, &amp; \\text{dim} = 3 \\end{cases} \\end{aligned} \\] <p>The evolution of this is handled by the function</p> <pre><code>nem.evolve_nematic(self,number_of_steps,method='ETD2RK')\n</code></pre>"},{"location":"ClassNematicLiquidCrystal/#disipative-dynamics","title":"Disipative dynamics","text":"<p>Note that if we set the velocity field to zero the dynamics become \\(\\(\\partial_t Q=  \\frac{K}{\\gamma} \\nabla^2 Q_{ij} +\\frac{A}{\\gamma}(B - 2Q^2_{kk})Q_{ij}.\\)\\) This is used to relax the initial system before starting the simulation. The linear and nonlinear part of this equation are</p> \\[ \\begin{aligned}     \\omega(\\nabla) = \\frac{K}{\\gamma} \\nabla^2 +\\frac{AB}{\\gamma},  \\\\     N(Q) = - \\frac{2A}{\\gamma}Q^2_{kk}Q +\\begin{cases}   0, &amp; \\text{dim} = 2 \\\\  C Q^2 - \\frac{C}{3}Q^2_{kk} I, &amp; \\text{dim} = 3 \\end{cases}. \\end{aligned} \\] <p>An evolver for this dissipative dynamics is included as</p> <pre><code>nem.evolve_nematic_no_flow(self,number_of_steps,method='ETD2RK')\n</code></pre>"},{"location":"ClassNematicLiquidCrystal/#sec:nem_vel","title":"The velocity field","text":"<p>For a given orderparameter \\(Q\\) the velocity field is calculated in Fourier space using eq (??). We start by finding an expression for the pressure by taking the divergence of this eq. (??) and then using the incompressibility condition giving \\(\\(\\nabla^2 P = \\nabla \\cdot \\mathbf F,\\)\\) where \\(\\mathbf F =  \\nabla \\cdot \\sigma^a(Q) +\\nabla \\cdot \\sigma^p(Q)\\) is the active and passive forces. This is solved in Fourier space as</p> \\[ -k^2  {{P}_{\\scriptscriptstyle  f}} =  i\\mathbf k \\cdot {{\\mathbf F}_{\\scriptscriptstyle  f}}. \\] <p>The above equation can be inverted in order to find all the modes of the pressure except the zero mode, i.e the pressure is determined up to a constant. We set this constant to zero. Once the pressure is found we obtain the velocity from</p> \\[ (\\Gamma + \\eta k^2){{\\mathbf u}_{\\mathfrak  f}} = - i\\mathbf k {{P}_{\\mathfrak  f}} + {{F}_{\\mathfrak  f}}. \\] <p>Note that when \\(\\Gamma = 0\\) we need to set the zero mode of the velocity by hand. This is set to zero. The pressure and velocity are calculated/updated by the two functions</p> <pre><code>calc_pressure_f(self,F_af,F_pf) \nconf_velocity(self,Q)\n</code></pre> <p>Note that <code>calc_pressure_f</code> only returns the Fourier transform of the pressure. The function <code>conf_velocity</code> updates both the velocity field <code>self.u</code> and its Fourier transform <code>self.u_f</code>.  The arguments <code>F_af</code> and <code>F_pf</code> are the active and passive forces respectivly.  </p>"},{"location":"ClassNematicLiquidCrystal/#minimum-of-the-free-energy","title":"Minimum of the free energy","text":"<p>When starting a simulation it is often interesting to start from a configuration that is the minimum of the free energy pluss some perturbations or with a vortex dipole/fillament. From the free energy we see that the minimum energy is given by a homogeneous nematic, and it is inedependent of the direction the nematogens are pointing. Assuming that the unitvector \\(\\mathbf n\\) is homogeneous we can rewrite the free energy in terms of the parameter \\(S\\).</p>"},{"location":"ClassNematicLiquidCrystal/#in-two-dimmensions","title":"In two dimmensions","text":"<p>the free energy is only given by powers of \\(\\text{Tr}(Q^2)\\) which in two dimmensions is \\(S^2/2\\) in terms of \\(S\\). The free-energy is therfore for a homogeneous two dimentional nematic given as</p> \\[ \\mathcal F =  \\int \\left( - \\frac{A}{2} \\left[ B \\frac{S^2}{2} -\\frac{S^4}{4}   \\right] \\right). \\] <p>The minimum of this is given as \\(S =\\sqrt{B}\\) when \\(B &gt;0\\) and \\(S = 0\\) if \\(B&lt;0\\).</p>"},{"location":"ClassNematicLiquidCrystal/#in-three-dimensions","title":"In three dimensions","text":"<p>In three dimensions we have that \\(\\text{Tr}(Q^2) = 2 S^2/3\\) and \\(\\text{Tr}(Q^3)= 2 S^3/9\\). Using this we find that there are a local minima at</p> \\[ S = \\frac{1}{8}\\frac{C}{A} + \\frac{1}{2} \\sqrt{\\frac{C^2}{16 A^2} + 3 B} \\] <p>when \\(B &gt; -3 C^2/(16A^2)\\).</p>"},{"location":"ClassNematicLiquidCrystal/#topological-defects-and-active-turbulence","title":"Topological defects and active turbulence","text":"<p>Because of the head-tail symmetry if the nematic director the topological defects in the nematic phase can have half integer winding number. We can see this by maping the \\(Q\\) tensor to a complex field. This is done by writing the nematic director as \\(\\\\mathbf{n} = \\cos{\\theta} \\hat x + \\sin{\\theta} \\hat y\\), with \\(\\hat x /\\hat y\\) being the unit vectors in \\(x /y\\) direction, and mapping the \\(Q\\) tensor, see eq.\u00a0(??), to the complex field</p> \\[ \\psi = Q_{xx} +  iQ_{xy} = \\frac{S}{2} e^{2 i\\theta}. \\] <p>Using the same arguments as for the BEC we find that the allowed winding numbers \\(\\(k = \\int_C \\nabla \\theta \\cdot d\\\\mathbf{l} = 2\\pi q\\)\\) with \\(q\\) being a half-integer. The defects of lowest absolute charge is the \\(\\pm 1/2\\) defects, which are depicted below.</p> <p> </p> <p>Liquid crystal disclination dipole: The nematic director (head-less vectors) around a defect dipole. The \\(+1/2\\) defect is marked with red, while the \\(-1/2\\) defect is in blue.</p> <p>For tracing the defect nodes one can use the function</p> <pre><code>calc_vortex_nodes_nem(self, dt_Q=None,polarization = None)\n</code></pre> <p>If <code>dt_Q</code> is given this finds the defects velocity and if <code>polarization</code> is given the polarization of the \\(+1/2\\) defects are found. This polarization is given by</p> \\[ \\mathbf{e}_+ = \\left( \\frac{\\nabla \\cdot Q}{|\\nabla \\cdot Q|}\\right)_{\\mathbf{r}= \\mathbf{r}_+} \\] <p>where \\(\\mathbf{r}_+\\) is the defects position. The field \\(\\mathbf{e}_+\\) can be found by the function</p> <pre><code>calc_defect_polarization_field(self)\n</code></pre> <p>Note that this function does not include the normalization to avoid division by zero.</p>"},{"location":"ClassNematicLiquidCrystal/#initial-states","title":"Initial States","text":"<p>A homogeneous nematic with random noise can be implemented with the function</p> <pre><code>conf_initial_condition_disordered(self, noise_strength=0.01)  \n</code></pre> <p>This gives a state where the nematogens are aligned with the \\(x\\)-axis. The noise is in the angle \\(\\theta\\). If the activity is high enough this state will after a while start to spontaneously generate topological defects. In addition there is possible to insert defect dipoles using the function</p> <pre><code>conf_insert_vortex_dipole(self, dipole_vector=None, dipole_position=None) \n</code></pre> <p>which works similarly as the one implemented for the BEC. This function can be used either to initialize a homogeneous state with a dipole, or it can be used to insert a dipole into an already existing nematic. In three dimensions one can initialise two disclination lines paralel to the z-axis using the function </p> <pre><code>conf_initial_disclination_lines(self, position1=None,position2 = None)\n</code></pre> <p>This function intialises a wedge defect looking like the two dimensional \\(+1/2\\) defect at <code>position1</code> and one  looking like a \\(-1/2\\) at <code>position2</code>.  The positions are in the xy-plane. If no positions are given the defects are placed at the positions </p> <pre><code>    position1 = [self.xmid+self.size_x/3, self.ymid]\n    position2 = [self.xmid - self.size_x / 3, self.ymid]\n</code></pre>"},{"location":"ClassNematicLiquidCrystal/#spatially-varying-activity","title":"Spatially varying activity","text":"<p>The activity \\(\\alpha\\) is can be spatially varying. This can be used to make active channels as shown in the following figure.</p> <p> </p> <p>Nematic liquid crystal active channel: Illustration of an active channel. <code>width= 20</code> and \\(d = 2\\).</p> <p>This simple channel with the activity \\(\\alpha_0\\) inside and \\(\\alpha = 0\\) outside is included as the function</p> <pre><code>conf_active_channel(self,width,d=7)\n</code></pre> <p>Which sets the activity to \\(\\(\\alpha = \\alpha_0 \\left[1 -1/2 \\left(\\tanh([x-w/2]/d) -\\tanh([x+w/2]/d) \\right)\\right].\\)\\) \\(w\\) is here the width of the channel, \\(\\alpha_0\\) is the activity in the channel and \\(d\\) is the width of the interface between the channel and the bulk. More complicated structures can be created if one wish.</p>"},{"location":"ClassNematicLiquidCrystal/#three-dimensions","title":"Three dimensions","text":"<p>In three dimensions, the \\(Q\\)-tensor can be characterized as</p> \\[ Q_{ij} = S (n_i n_j - \\frac{1}{3} \\delta_{ij} ) + P (m_i m_j - l_i l_j), \\] <p>where \\((\\mathbf n, \\mathbf m, \\mathbf l )\\) is an orthornmal triad. It is five parameters: \\(S\\), the two defining angles of \\(\\mathbf n\\), \\(P\\) and the angle of \\(\\mathbf m\\) in the plane orthogonal to \\(\\mathbf n\\). \\(S\\) can always be determined from the highest eigenvalue \\(\\lambda_{\\textrm{max}}\\) of \\(Q\\) by <sup>1</sup></p> \\[ S = \\frac{3}{2} \\lambda_{\\textrm{max}} \\]"},{"location":"ClassNematicLiquidCrystal/#topological-defects","title":"Topological defects","text":"<p>Topological defects in nematic liquid crystals are called disclinations and are characterized the orientation of the rod-like particles having rotated after following a path around the dislocation. From <sup>6</sup>,</p> \\[ D_{\\gamma i} = \\epsilon_{\\gamma \\mu \\nu} \\epsilon_{ikl} \\partial_k Q_{\\mu \\alpha} \\partial_l Q_{\\nu \\alpha}. \\] <p>We can write this as</p> \\[ D_{\\gamma i} = \\delta_{\\gamma i} ( \\partial_k Q_{k\\alpha} \\partial_l Q_{l\\alpha} - \\partial_k Q_{l\\alpha}\\partial_l Q_{k\\alpha}) + 2( \\partial_\\gamma Q_{k\\alpha} \\partial_k Q_{i\\alpha} - \\partial_\\gamma Q_{i\\alpha} \\partial_k Q_{k\\alpha}) \\] <p>to reduce the number of sums preformed.</p> <p>In two dimensions, where \\(\\mathbf n = (\\cos \\theta,\\sin \\theta)\\), we have</p> \\[ Q = S\\begin{pmatrix} \\cos \\theta \\cos \\theta - \\frac{1}{2} &amp; \\cos \\theta \\sin \\theta \\\\ \\cos \\theta \\sin \\theta &amp; \\sin \\theta \\sin \\theta - \\frac{1}{2}\\\\ \\end{pmatrix} = \\frac{S}{2} \\begin{pmatrix} \\cos (2\\theta) &amp;  \\sin(2\\theta) \\\\ \\sin(2\\theta) &amp; - \\cos (2\\theta)\\\\ \\end{pmatrix}, \\] \\[ = \\frac{1}{2} \\begin{pmatrix} \\psi_1 &amp;  \\psi_2 \\\\ \\psi_2 &amp; - \\psi_1\\\\ \\end{pmatrix}, \\] <p>where \\(\\psi_1,\\psi_2\\) are the components of an \\(\\mathcal D^2\\) order parameter. We get only one component of \\(D_{\\gamma i}\\), which is \\(D_{33}\\) which is</p> \\[ D_{33} = \\epsilon_{\\mu \\nu} \\epsilon_{kl} \\partial_k Q_{\\mu \\alpha} \\partial_l Q_{\\nu \\alpha} \\] \\[ = \\epsilon_{\\mu \\nu} \\epsilon_{kl} \\partial_k Q_{\\mu 1} \\partial_l Q_{\\nu 1} + \\epsilon_{\\mu \\nu} \\epsilon_{kl} \\partial_k Q_{\\mu 2} \\partial_l Q_{\\nu 2} \\] <p>We have \\(Q_{\\mu1} = \\frac{1}{2} \\psi_\\mu\\) and \\(Q_{\\mu 2} = \\frac{1}{2} \\epsilon_{\\mu q} \\psi_q\\), so</p> \\[ D_{33} = \\frac{1}{4} \\epsilon_{\\mu \\nu} \\epsilon_{kl} (\\partial_k \\psi_\\mu )(\\partial_l \\psi_\\nu) + \\frac{1}{4} \\epsilon_{\\mu \\nu} \\epsilon_{kl} (\\partial_k  \\epsilon_{\\mu q} \\psi_q) (\\partial_l \\epsilon_{\\nu r} \\psi_r) \\] <p>And using that</p> \\[ \\epsilon_{\\mu \\nu} \\epsilon_{\\mu q} \\epsilon_{\\nu r} = \\epsilon_{qr}, \\] <p>we get</p> \\[ D_{33} = \\frac{1}{2} \\epsilon_{\\mu \\nu} \\epsilon_{kl} (\\partial_k \\psi_\\mu )(\\partial_l \\psi_\\nu). \\] <p>This is the same determinant as we would get using the coarse grain density of <sup>7</sup>, only with \\(\\psi_0\\), so, the disclination density should be</p> \\[ \\rho_{\\gamma i} = \\frac{1}{\\pi S_0^2} D_{\\gamma i} \\] <p>This fiel is found by the function </p> <p><pre><code>calc_disclination_density_nematic(self)\n</code></pre> which returns a tensorfield in three dimensions and a scalar field (\\(\\rho_{33}\\)) in two.  Since we have tensor in three dimenstions, the story is more complicated than usual.  This tensor contains two pieces of information, namely which direction the disclination is pointing, and around which axis \\(\\boldsymbol \\Omega\\), near the disclination, the rods are rotating. In that way, it is similar to a dislocation density in a crystal structure, only that it allows for the orientation the \"Burgers vector\" to be any direction. It can be written like this <sup>6</sup></p> \\[ \\rho_{\\gamma i} = \\omega \\Omega_\\gamma t_{i} , \\] <p>where the unit vectors are \\(\\boldsymbol t\\) is tangent vector and \\(\\boldsymbol\\Omega\\) is the rotational vector. From this, we see that</p> \\[ \\omega^2 =|\\rho|^2 = \\rho_{\\gamma i} \\rho_{\\gamma i}  \\] <p>so \\(\\omega\\) is the quantity we should integrate to find the nodes of the defects.  The unitvectors \\(\\boldsymbol t\\) and \\(\\boldsymbol \\Omega\\) is found as the eigenvectors of the matrices \\(\\rho^T \\rho\\) and \\(\\rho \\rho^T\\) respectivly. Since the eigenvectors are determined up to a sign one have to make sure that \\(\\boldsymbol t\\) is continous along the defect and impose the condition \\(\\text{sign}(\\boldsymbol \\Omega \\cdot \\boldsymbol t) = \\text{sign}(\\text{Tr}(\\rho))\\). The \\(\\rho\\) tensor field is calculated decomposed into the above mentioned vectors by the function</p> <p><pre><code>calc_disclination_density_decoupled(self)\n</code></pre> which returns \\(\\omega, \\Omega, T,\\) and \\(\\text{Tr}(\\rho)\\). </p> <p>From Ref.<sup>6</sup>, we have</p> \\[ t_i \\delta^{(2)}(\\mathbf r_{\\perp}) = \\delta^{(2)}(\\mathbf Q_\\perp) \\Omega_\\gamma D_{\\gamma i} \\] <p>replacing the delta function, which we may generalize to</p> \\[ \\mathbf \\rho = \\Omega_{\\gamma} \\frac{1}{\\pi (S_0-P_0)^2} D_{\\gamma i}. \\]"},{"location":"ClassNematicLiquidCrystal/#inserting-topological-defects","title":"Inserting topological defects","text":"<p>How do we insert topological defects of a given character?</p> <p>We can generate an initial state of \\(Q_{ij}\\) by writing</p> \\[ Q_{ij} = S_0 \\left (\\frac{1}{2} n_i n_j - \\frac{1}{d} \\delta_{ij} \\right ), \\] <p>and then simply impose an orientation field corresponding to an angle field on the \\(\\mathbf n\\) fields.</p> <ol> <li> <p>Schimming, C. D. (2022). Theoretical and Computational Methods for Mesoscopic Textures in Nematic Liquid Crystals with Anisotropic Elasticity. PhD Thesis. The University of Minnesota. https://hdl.handle.net/11299/241713 \u21a9\u21a9</p> </li> <li> <p>Marchetti, M. C., Joanny, J-F., Ramaswamy, S., Liverpool, T. B., Prost, J., and Rao, M. and Simha, R. A. (2013). Hydrodynamics of soft active matter. Reviews of Modern Physics. 85, 3, 1143. https://doi.org/10.1103/RevModPhys.85.1143 \u21a9</p> </li> <li> <p>Genkin, M. M., Sokolov, A., Lavrentovich, O. D. and Aranson, I. S. (2017). Topological defects in a living nematic ensnare swimming bacteria. Physical Review X. 7, 1,011029. https://doi.org/10.1103/PhysRevX.7.011029 \u21a9</p> </li> <li> <p>Nejad, M. R., Doostmohammadi, A. and Yeomans, J. M. (2021). Memory effects, arches and polar defect ordering at the cross-over from wet to dry active nematics. Soft Matter. 17, 9, 2500-2511. https://doi.org/10.1039/D0SM01794A \u21a9</p> </li> <li> <p>Angheluta, L., Chen, Z., Marchetti, M. C. and Bowick, Mark J. (2021). The role of fluid flow in the dynamics of active nematic defects. New Journal of Physics. 23, 3, 033009. https://doi.org/10.1088/1367-2630/abe8a8 \u21a9</p> </li> <li> <p>Schimming, C. D. and Vi\u00f1als, J. (2023). Kinematics and dynamics of disclination lines in three-dimensional nematics. Proceedings of the Royal Society A. 479, 2273, 20230042. https://doi.org/10.1098/rspa.2023.0042 \u21a9\u21a9\u21a9</p> </li> <li> <p>Skogvoll, V., R\u00f8nning, J., Salvalaglio, M., Angheluta, L. (2023). A unified field theory of topological defects and non-linear local excitations. npj Comput Mater, 9, 122. https://doi.org/10.1038/s41524-023-01077-6 \u21a9</p> </li> </ol>"},{"location":"ClassPhaseFieldCrystal/","title":"Class: Phase Field Crystal","text":"<p>In this class, we simulate a crystal using the phase-field crystal methodology.  The phase-field crystal (PFC) model is a mesoscopic model that describes the dynamics of a crystal. The model is based on a free energy functional, which is minimized to find the equilibrium state of the system. The free energy functional is a function of the phase field \\(\\psi\\), which is a real-valued field that describes the local density of the crystal. The PFC model is a powerful tool for studying the dynamics of crystals, and it has been used to study a wide range of phenomena, including the formation of defects, the dynamics of grain boundaries, and the growth of crystals.</p> <pre><code>file: comfit/models/phase_field_crystal.py \nclass: PhaseFieldCrystal\n</code></pre> <p>See the ComFiT Library Reference below for a complete list of class methods and their usage.</p>  ComFiT Library Reference"},{"location":"ClassPhaseFieldCrystal/#variables-and-parameters","title":"Variables and parameters","text":"<p>The phase field \\(\\psi\\).</p> <pre><code>pfc.psi\n</code></pre>"},{"location":"ClassPhaseFieldCrystal/#basic-model","title":"Basic model","text":"<p>The PFC methodology is based on postulating a free energy</p> <p>The PFC free energy</p> \\[ \\mathcal F = \\int d\\boldsymbol{r} \\tilde f(\\psi, \\nabla \\psi, ...) \\] <p>with the goal of the state that minimizes \\(\\mathcal F\\) has a certain symmetry.  In this documentation, we will present six such models to represent different crystalline structures in 1, 2 and 3 dimensions, all of which are on the form</p> <p>The PFC free energy density</p> \\[ \\tilde f( \\psi, \\nabla \\psi, ...) = \\frac{1}{2} (\\mathcal L(\\nabla) \\psi)^2 + \\frac{1}{2} \\texttt{r} \\psi^2  + \\frac{1}{3} \\texttt t \\psi^3 + \\frac{1}{4} \\texttt v \\psi^4, \\] <p>where \\(\\mathcal L (\\nabla)\\) is a gradient operator dependent on the dimension and target symmetry, listed below</p> Model Derivative operator \\(\\mathcal L\\) 1D periodic \\(\\mathcal L_1 = (1+\\nabla^2)\\) 2D triangular \\(\\mathcal L_1 = (1+\\nabla^2)\\) 2D square \\(\\mathcal L_1 \\mathcal L_2 = (1+\\nabla^2) (2+\\nabla^2)\\) 3D bcc \\(\\mathcal L_1 = (1+\\nabla^2)\\) 3D fcc \\(\\mathcal L_1 \\mathcal L_{4/3} = (1+\\nabla^2) (4/3+\\nabla^2)\\) 3D simple cubic \\(\\mathcal L_1 \\mathcal L_2 \\mathcal L_3 = (1+\\nabla^2) (2+\\nabla^2) (3+\\nabla^2)\\) <p>Table: Phase-field crystal models. \\(\\mathcal L_X = (X+\\nabla^2)\\).</p> <p>Of particular interest is the PFC chemical potential, given by </p> <p>The PFC chemical potential</p> \\[ \\tilde \\mu_c = \\frac{\\delta \\mathcal F}{\\delta \\psi} = \\left ( \\mathcal L^2 \\psi + \\texttt r \\psi + \\texttt t \\psi^2 + \\texttt v \\psi^3 \\right ) \\] <p>The PFC model was introduced inin Ref.<sup>1</sup>. The primary field is \\(\\psi\\), a real valued field</p> <pre><code>pfc.psi \n</code></pre>"},{"location":"ClassPhaseFieldCrystal/#crystal-symmetry","title":"Crystal symmetry","text":"<p>The way in which this field can model a crystalline lattice is by the ground state having that particular symmetry. For instance, the figure below shows the (real) field \\(\\psi\\) for a (a) 2D triangular, and a (b) 2D square lattice.</p> <p> </p> <p>Figure: Ground state of the PFC model for (a) 2D triangular and (b) 2D square lattice.</p> <p>The crystalline symmetry is described by a Bravais lattice, which consists of vectors that point to peaks on the lattice. The Fourier transform of a field that a Bravais lattice symmetry will itself have a lattice symmetry, which is called the reciprocal lattice, and is useful to express the field in terms of a Fourier series.</p> <p> </p> <p>Figure: Bravais lattices \\(\\mathcal B\\) and their reciprocal lattices \\(\\mathcal R\\) for square and triangular symmetry. In each case, \\(\\{\\mathbf a^{(n)}\\}_{n=1}^2\\) are primitive lattice vectors and \\(\\{ \\mathbf q^{(n)}\\}_{n=1}^2\\) primitive reciprocal lattice vectors (RLVs) that satisfy \\(\\mathbf a^{(n)} \\cdot \\mathbf q^{(m)} = 2\\pi \\delta_{nm}\\). Amended and reprinted from Ref. <sup>2</sup> with permission.</p> <p>Using the reciprocal lattice, one can express a field which has a Bravais lattice symmetry as a Fourier series in terms of the reciprocal lattice vectors</p> \\[ \\psi (\\mathbf r) = \\sum_{\\mathbf q^{(n)} \\in \\mathcal R} \\eta_n e^{\\mathfrak i \\mathbf q^{(n)} \\cdot \\mathbf r}, \\] <p>the reciprocal lattice is \\(d\\) dimensions generated by \\(d\\) primitive RLVs \\(\\lbrace\\boldsymbol{q}^{(n)}\\rbrace_{n=1}^d\\), satisfying</p> <p>The primitive BLV-RLV orthogonality relation.</p> \\[ \\boldsymbol{q}^{(n)} \\cdot \\boldsymbol{a}^{(m)} = 2\\pi \\delta_{nm}, \\quad n,m \\leq d. \\] <p>There are infinitely many BLVs and RLVs, but of particular interest are those with the smallest magnitude; which are sometimes named primary RLVs/BLVs. These values are encoded in the instance properties <code>a,q</code>, e.g.,</p> <pre><code>import comfit as cf\n\npfc = cf.PhaseFieldCrystal2DTriangular(1,1)\nprint(pfc.a)\nprint(pfc.q)\n&gt;&gt; \n[[3.627, 6.283], [7.255, 0.0], [3.627, -6.283]]\n[[0, 1], [0.866, -0.5], [-0.866, -0.5]]\n</code></pre> Example: The 1D PFC - Crystal symmetry <p>The simplest example of a PFC model is the 1D periodic model, which simply looks like a sine wave.</p> <p> </p> <p>The crystal symmetry in this case refers to \\(\\psi\\) having a periodicity of \\(a_0=2\\pi\\), and so the Bravais lattice is simply \\(\\{ a^{(n)} \\} = \\{...,-2\\pi,-\\pi,0,\\pi,2\\pi,... \\}\\). The primary BLVs are thus given by</p> \\[ \\mathcal B_{\\textrm{per}}^{(1)} = \\{ a^{(1)} = 2\\pi,~ a^{(-1)} = -2\\pi \\} \\] <p>The reciprocal lattice is in this case simply \\(\\{ q^{(n)} \\} = \\{...,q^{(-2)} =-2,~ q^{(-1)} = -1,~ q^{(0)} = 0,~ q^{(1)} = 1,~ q^{(2)} =2,... \\}\\), the primary set being </p> \\[ \\mathcal R_{\\textrm{per}}^{(1)} = \\{ q^{(1)} = 1,~ q^{(-1)} = -1 \\} \\] <p>and any field with that periodicity can be expressed as a Fourier series in terms of these RLVs by</p> \\[ \\psi(x) = \\psi_0 + A (e^{\\mathfrak iq^{(1)} x} + e^{\\mathfrak i q^{(-1)} x}) + B (e^{\\mathfrak iq^{(2)} x} + e^{\\mathfrak i q^{(-2)} x}) + ..., \\] <p>Cutting the Fourier series off at the primary RLVs mode is called the one-mode approximation</p> \\[ \\psi^{\\textrm{eq}} \\approx \\psi_0 + A \\sum_{q^{(n)} \\in \\mathcal R^{(1)}} e^{\\mathfrak i q^{(n)} x}, \\] <p>where \\(\\mathcal R_{\\textrm{per}}^{(1)}\\) as the primary RLVs.</p> <p>Primitive vs primary LV</p> <p>Note the subtle difference between a primitive LV and a primary LV. The primitive BLVs generate the lattice and satisfy the orthogonal relationship with the primitive RLVs which generate the reciprocal lattice. There are only \\(d\\) primitive LVs in \\(d\\) dimensions whereas there may be any number of primary lattice vectors. For instance, there are six primary BLVs for the triangular lattice and four primary lattice vectors for the 2D square lattice. In the following, the primary BLVs and RLVs have been chosen so that the first \\(d\\) primary LVs are primitive LVs that satisfy the orthogonality relation.</p> <p>Below are all the lattice constants and primary RLVs and BLVs for the models we consider.</p> 1D periodic2D Triangular2D square3D body-centered cubic3D face-centered cubic3D simple cubic <p>Lattice constant</p> \\[ a_0 = 2\\pi \\] <p>Primary RLVs</p> \\[ \\mathcal R_{\\textrm{per}}^{(1)} = \\left \\lbrace \\begin{array}{l}     q^{(1)} = 1  \\\\     q^{(-1)}= - q^{(1)} \\end{array} \\right \\rbrace \\] <p>Primary BLVs</p> \\[ \\mathcal B_{\\textrm{per}}^{(1)} = \\left \\lbrace \\begin{array}{l}     a^{(1)} = a_0  \\\\     a^{(-1)} = -\\mathbf a^{(1)} \\end{array} \\right \\rbrace \\] <p>Lattice constant</p> \\[ a_0 = \\frac{4\\pi}{\\sqrt 3} \\] <p>Primary RLVs</p> \\[ \\mathcal R_{\\textrm{tri}}^{(1)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf q^{(1)} = (\\sqrt 3/2,-1/2)  \\\\     \\mathbf q^{(2)} = (0,1) \\\\     \\mathbf q^{(3)} = (-\\sqrt 3/2,-1/2) \\\\     \\mathbf q^{(-n)} = - \\mathbf q^{(n)}|_{n=1,2,3} \\\\ \\end{array} \\right \\rbrace } \\] <p>Primary BLVs</p> \\[ \\mathcal B_{\\textrm{tri}}^{(1)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf a^{(1)} = a_0(1,0)  \\\\     \\mathbf a^{(2)} = a_0(1/2,\\sqrt 3/2) \\\\     \\mathbf a^{(3)} = a_0(1/2,-\\sqrt 3/2) \\\\     \\mathbf a^{(-n)}=-\\mathbf a^{(n)}|_{n=1,2,3}  \\\\ \\end{array} \\right \\rbrace } \\] <p>Lattice constant $$ a_0 = 2\\pi $$</p> <p>Primary RLVs</p> \\[ \\mathcal B_{\\textrm{sq}}^{(1)} = \\left \\lbrace \\begin{array}{l}     \\mathbf a^{(1)} = a_0(1,0)  \\\\     \\mathbf a^{(2)} = a_0(0,1)  \\\\     \\mathbf a^{(-1)},\\mathbf a^{(-2)} \\end{array} \\right \\rbrace \\] <p>Primary Bravais Lattice vectors</p> \\[ \\mathcal R_{\\textrm{sq}}^{(1)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf q^{(1)} = (1,0)  \\\\     \\mathbf q^{(2)} = (0,1) \\\\     \\mathbf q^{(-n)} = - \\mathbf q^{(n)} |_{n=1,2} \\\\ \\end{array} \\right \\rbrace} \\] \\[ \\mathcal R_{\\textrm{sq}}^{(2)} = \\left \\lbrace \\begin{array}{l}     \\mathbf q^{(3)} = (1,-1)  \\\\     \\mathbf q^{(4)} = (1,1) \\\\     \\mathbf q^{(-n)} = - \\mathbf q^{(n)} |_{n=3,4} \\\\ \\end{array} \\right \\rbrace \\] <p>Lattice constant</p> \\[ a_0 = 2\\pi \\sqrt {2} \\] <p>Primary BLVs</p> \\[ \\mathcal B_{\\textrm{bcc}}^{(1)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf a^{(1)} = a_0(-1,1,1)/2  \\\\     \\mathbf a^{(2)} = a_0(1,-1,1)/2 \\\\     \\mathbf a^{(3)} = a_0(1,1,-1)/2\\\\     \\mathbf a^{(4)} = a_0(1,1,1)/2\\\\     \\mathbf a^{(-n)}=-\\mathbf a^{(n)}|_{n=1,...,4} \\\\ \\end{array} \\right \\rbrace } \\] <p>Primary RLVs</p> \\[ \\mathcal R_{\\textrm{bcc}}^{(1)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf q^{(1)} = (0,1,1)/\\sqrt 2  \\\\     \\mathbf q^{(2)} = (1,0,1)/\\sqrt 2 \\\\     \\mathbf q^{(3)} = (1,1,0)/\\sqrt 2\\\\     \\mathbf q^{(4)} = (0,-1,1)/\\sqrt 2\\\\     \\mathbf q^{(5)} = (-1,0,1)/\\sqrt 2\\\\     \\mathbf q^{(6)} = (-1,1,0)/\\sqrt 2\\\\     \\mathbf q^{(-n)} = - \\mathbf q^{(n)}|_{n=1,...6} \\\\ \\end{array} \\right \\rbrace } \\] <p>Lattice constant</p> \\[ a_0 = 2\\pi \\sqrt 3 \\] <p>Primary BLVs</p> \\[ \\mathcal B_{\\textrm{fcc}}^{(1)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf a^{(1)} = a_0(0,1,1)/2  \\\\     \\mathbf a^{(2)} = a_0(1,0,1)/2 \\\\     \\mathbf a^{(3)} = a_0(1,1,0)/2\\\\     \\mathbf a^{(4)} = a_0(0,-1,1)/2\\\\     \\mathbf a^{(5)} = a_0(-1,0,1)/2\\\\     \\mathbf a^{(6)} = a_0(-1,1,0)/2\\\\     \\mathbf a^{(-n)}=-\\mathbf a^{(n)}|_{n=1,...,6} \\\\ \\end{array} \\right \\rbrace } \\] <p>Primary RLVs</p> \\[ \\mathcal R_{\\textrm{fcc}}^{(1)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf q^{(1)} = (-1,1,1)/\\sqrt 3  \\\\     \\mathbf q^{(2)} = (1,-1,1)/\\sqrt 3 \\\\     \\mathbf q^{(3)} = (1,1,-1)/\\sqrt 3\\\\     \\mathbf q^{(4)} = (1,1,1)/\\sqrt 3\\\\     \\mathbf q^{(-n)} = - \\mathbf q^{(n)}|_{n=1,...,4}\\\\ \\end{array} \\right \\rbrace } \\] \\[ \\mathcal R_{\\textrm{fcc}}^{(4/3)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf q^{(5)} = (2,0,0)/\\sqrt 3  \\\\     \\mathbf q^{(6)} = (0,2,0)/\\sqrt 3 \\\\     \\mathbf q^{(7)} = (0,0,2)/\\sqrt 3\\\\     \\mathbf q^{(-n)} = - \\mathbf q^{(n)} |_{n=5,6,7} \\\\ \\end{array} \\right \\rbrace } \\] <p>Lattice constant</p> \\[ a_0 = 2\\pi \\] <p>Primary BLVs</p> \\[ \\mathcal B_{\\textrm{sc}}^{(1)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf a^{(1)} = a_0(1,0,0)  \\\\     \\mathbf a^{(2)} = a_0(0,1,0) \\\\     \\mathbf a^{(3)} = a_0(0,0,1)\\\\     \\mathbf a^{(-n)} = - \\mathbf a^{(n)}|_{n=1,2,3} \\\\ \\end{array} \\right \\rbrace } \\] <p>Primary RLVs</p> \\[ \\mathcal R_{\\textrm{sc}}^{(1)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf q^{(1)} = (1,0,0)  \\\\     \\mathbf q^{(2)} = (0,1,0) \\\\     \\mathbf q^{(3)} = (0,0,1)\\\\     \\mathbf q^{(-n)} = - \\mathbf q^{(n)} |_{n=1,2,3}\\\\ \\end{array} \\right \\rbrace } \\] \\[ \\mathcal R_{\\textrm{sc}}^{(2)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf q^{(4)} = (0,1,1)  \\\\     \\mathbf q^{(5)} = (1,0,1) \\\\     \\mathbf q^{(6)} = (1,1,0)\\\\     \\mathbf q^{(7)} = (0,-1,1)  \\\\     \\mathbf q^{(8)} = (-1,0,1) \\\\     \\mathbf q^{(9)} = (-1,1,0)\\\\     \\mathbf q^{(-n)} = - \\mathbf q^{(n)}|_{n=4,...,9} \\\\\\\\ \\end{array} \\right \\rbrace } \\] \\[\\mathcal R_{\\textrm{sc}}^{(3)} = { \\left \\lbrace \\begin{array}{l}     \\mathbf q^{(10)} = (-1,1,1)  \\\\     \\mathbf q^{(11)} = (1,-1,1) \\\\     \\mathbf q^{(12)} = (1,1,-1)\\\\     \\mathbf q^{(13)} = (1,1,1)\\\\     \\mathbf q^{(-n)} = - \\mathbf q^{(n)}|_{n=10,...,13} \\\\ \\end{array} \\right \\rbrace } \\]"},{"location":"ClassPhaseFieldCrystal/#the-ground-state","title":"The ground state","text":"<p>To find the ground state of a PFC, one inserts a particular mode approximation into the free energy density, average over a unit cell (coarse-grain) and minimizes it with respect to the amplitudes.</p> Example: The 1D PFC - Ground state <p>To find the ground state of the 1D PFC, we assume that we can express the field in the one-mode approximation, i.e.,</p> \\[ \\psi^{\\textrm{eq}}(x) = \\psi_0 + A (e^{\\mathfrak i q x} + e^{\\mathfrak i q x}), \\] <p>where \\(q\\) is, for now, an arbitrary wave vector which we will show to be the primary RLV of the lattice.  We want to insert this into the free energy density \\(\\tilde f\\) and integrate over a unit cell (UC), which in this case is simply \\([0,2\\pi]\\)</p> \\[ \\frac{1}{2\\pi} \\mathcal F_{UC} =  \\frac{1}{2\\pi} \\int_0^{2\\pi} \\tilde f(\\psi^{\\textrm{eq}}) dx \\equiv \\langle \\tilde f(\\psi^{\\textrm{eq}}) \\rangle_{UC} = \\frac{1}{2} \\langle (\\mathcal L {\\psi^{\\textrm{eq}}})^2 \\rangle_{UC} + \\frac{1}{2} \\texttt{r} \\langle {\\psi^{\\textrm{eq}}}^2 \\rangle_{UC} + \\frac{1}{4} \\langle {\\psi^{\\textrm{eq}}}^4 \\rangle_{UC} \\] <p>To insert this into the free energy density, we need to calculate some auxiliary quantities.</p> \\[ \\mathcal L \\psi^{\\textrm{eq}} = (1+\\nabla^2) \\psi^{\\textrm{eq}} = \\psi_0 + (1-q^2) A (e^{\\mathfrak i q x} + e^{\\mathfrak i q x}) \\] <p>so </p> \\[ \\langle (\\mathcal L \\psi^{\\textrm{eq}})^2 \\rangle_{UC} = \\langle (\\psi_0 + (1-q^2) A (e^{\\mathfrak i q x} + e^{\\mathfrak i q x})(\\psi_0 + (1-q^2) A (e^{\\mathfrak i q x} + e^{\\mathfrak i q x})) \\rangle_{UC} \\] <p>Now, to calculate this, we need to make use of a condition of resonance, which is that under the coarse-graining operation, terms with periodicity average to zero<sup>2</sup>. So we get </p> \\[ \\langle (\\mathcal L \\psi^{\\textrm{eq}})^2 \\rangle_{UC} = \\psi_0^2 + 2 A^2 (1-q^2)^2 \\] <p>Similarly, the other terms give</p> \\[ \\langle {\\psi^{\\textrm{eq}}}^2 \\rangle_{UC} = \\psi_0^2 + 2 A^2 \\] \\[ \\langle {\\psi^{\\textrm{eq}}}^3 \\rangle_{UC} = \\psi_0^3 + 6 \\psi_0 A^2 \\] \\[ \\langle {\\psi^{\\textrm{eq}}}^4 \\rangle_{UC} = \\psi_0^4 + 12 \\psi_0^2 A^2 + 6 A^4 \\] <p>which gives </p> \\[ \\mathcal F_{UC} = 2\\pi \\left( \\frac{1}{2} (\\psi_0^2 + 2 A^2 (1-q^2)^2)  + \\frac{1}{2} \\texttt{r} (\\psi_0^2 + 2 A^2) + \\frac{1}{3} \\texttt t (\\psi_0^3 + 6 \\psi_0 A^2) + \\frac{1}{4} \\texttt v (\\psi_0^4 + 12 \\psi_0^2 A^2 + 6 A^4) \\right ) \\] <p>First of all, we see that the equilibrium value must have \\(q=1\\), since the free energy is minimized by this choice. Now, if the PFC is evolving according to conservative dynamics \\(\\partial_t \\psi = \\nabla^2 (\\delta \\mathcal F/\\delta \\psi)\\) (which is the standard PFC evolution equation as explained further down in the document), the average value \\(\\psi_0\\) will be conserved and therefore considered a simulation constant.  In this case, we find the equilibrium value of \\(A\\), by differentiating wrt. \\(A\\) and setting to zero.</p> \\[ \\partial_A \\mathcal F_{UC} =  2 \\texttt{r} A + 4 \\texttt t \\psi_0 A + 6 \\texttt v \\psi_0^2 A + 6\\texttt v A^3 = 0, \\] <p>which gives \\(A=0\\) or</p> \\[  \\texttt{r} + 2 \\texttt t \\psi_0 + 3 \\texttt v \\psi_0^2 + 3 \\texttt v A^2 = 0, \\] \\[ A^2 = \\frac{1}{3\\texttt v} (-\\texttt{r}  - 2 \\texttt t \\psi_0 - 3\\texttt v \\psi_0^2)  \\] \\[ A = \\pm \\frac{1}{\\sqrt{3\\texttt v}} \\sqrt{- \\texttt{r} - 2 \\texttt t \\psi_0 - 3 \\psi_0^2} \\] <p>The sign does not matter in the case of the 1D PFC, since it will only affect the global sign of the amplitude, flipping the cosine wave. In higher dimensions, however, it requires more subtle treatment, and typically, one inserts both solutions into the free energy \\(\\mathcal F_{UC}\\) to see which is lower</p> <p>If instead, we are evolving the PFC under not conserved dynamics \\(\\partial_t \\psi = - \\delta \\mathcal F/\\delta \\psi\\), also the zero mode \\(\\psi_0\\) will reach an equilibrium value. In this case, then, we need to solve the system of equations given by</p> \\[ \\left \\lbrace         \\begin{array}{lrl}         \\partial_{\\psi_0} \\mathcal F_{UC} = 0: &amp; \\psi_0 + \\texttt r \\psi_0 + \\texttt t \\psi_0^2 + 2 \\texttt t A^2 + \\texttt v \\psi_0^3 + 6\\texttt v \\psi_0 A^2 &amp;=0 \\\\         \\partial_{A} \\mathcal F_{UC} = 0: &amp;  \\texttt{r} + 2 \\texttt t \\psi_0 + 3 \\texttt v \\psi_0^2 + 3 \\texttt v A^2 &amp;= 0\\\\         \\end{array} \\right \\rbrace \\] <p>The <code>pfc</code> instance will be initialized with a list called <code>eta0</code>, which consists of the equilibrium values of the amplitudes to begin with.</p> 1D periodic2D triangular2D square3D body-centered cubic3D face-centered cubic3D simple cubic <p>Default resolution:</p> <p>Default model parameters \\((r,\\psi_0)\\): \\((-0.3,-0.3)\\)</p> <p>Free energy per unit cell (calculation document):</p> \\[ \\mathcal F_{UC} = \\frac{1}{2} \\psi_0^2 + \\frac{1}{2} \\texttt{r} (\\psi_0^2 + 2 A^2) + \\frac{1}{3} \\texttt t (\\psi_0^3 + 6 \\psi_0 A^2) + \\frac{1}{4} \\texttt v (\\psi_0^4 + 12 \\psi_0^2 A^2 + 6 A^4) \\] <p>Equilibrium amplitude  (conserved)</p> \\[ \\partial_{A} \\mathcal F_{UC} = 0: \\quad A =\\pm \\frac{1}{\\sqrt {3\\texttt v}} \\sqrt{ -\\texttt r - 2 \\texttt t \\psi_0 - 3 \\texttt v \\psi_0^2} \\] <p>Equilibrium amplitude equations (unconserved)</p> \\[ \\left \\lbrace         \\begin{array}{lrl}         \\partial_{\\psi_0} \\mathcal F_{UC} = 0: &amp; 2 A^2 (\\texttt t + 3 \\texttt v \\psi_0) + \\psi_0 (1 + \\texttt r + \\texttt t \\psi_0 + \\texttt v \\psi_0^2) &amp;=0 \\\\         \\partial_{A} \\mathcal F_{UC} = 0: &amp; \\texttt r + 3 A^2 \\texttt v + \\psi_0 (2 \\texttt t + 3 \\texttt v \\psi_0)  &amp;= 0\\\\         \\end{array} \\right \\rbrace \\] <p>Default resolution: \\([7,12]^{-1}a_0\\)</p> <p>Default model parameters \\((r,\\psi_0)\\): \\((-0.3,-0.3)\\)</p> <p>Free energy per unit cell (calculation document.):</p> \\[ \\mathcal F_{UC} = \\frac{\\pi^2}{3\\sqrt 3} \\left (270 A^4 \\texttt v + 48 A^3 (\\texttt t + 3 \\texttt v \\psi_0) + \\psi_0^2 (6 + 6 \\texttt r + 4 \\texttt t \\psi_0 + 3 \\texttt v \\psi_0^2) + 36 A^2 (\\texttt r + \\psi_0 (2 \\texttt t + 3 \\texttt v \\psi_0))\\right) \\] <p>Equilibrium amplitude equations (conserved)</p> \\[ \\left \\lbrace \\partial_{A} \\mathcal F_{UC} = 0: A=0 ~ \\textrm{or} ~ \\quad  A= \\frac{1}{15\\texttt v} \\left ( -\\texttt t - 3 \\texttt v \\psi_0 \\pm \\sqrt{ \\texttt t^2 - 15 \\texttt r \\texttt v - 24 \\texttt t \\texttt v \\psi_0 - 36 \\texttt v^2 \\psi_0^2} \\right ) \\right \\rbrace \\] <p>Equilibrium amplitude equations (unconserved) </p> \\[ \\left \\lbrace         \\begin{array}{lrl}         \\partial_{\\psi_0} \\mathcal F_{UC} = 0: &amp; 12 A^3 \\texttt v + 6 A^2 (\\texttt t + 3 \\texttt v \\psi_0) + \\psi_0 (1 + \\texttt r + \\texttt t \\psi_0 + \\texttt v \\psi_0^2) &amp;=0 \\\\         \\partial_{A} \\mathcal F_{UC} = 0: &amp; A(\\texttt r + 15 A^2 \\texttt v + 2 A (\\texttt t + 3 \\texttt v \\psi_0) + \\psi_0 (2 \\texttt t + 3 \\texttt v \\psi_0))  &amp;= 0\\\\         \\end{array} \\right \\rbrace \\] <p>Default resolution: \\([7,7]^{-1}a_0\\)</p> <p>Default model parameters \\((\\texttt r,\\psi_0)\\): \\((-0.3,-0.3)\\)</p> <p>Free energy per unit cell (calculation document):</p> \\[ \\mathcal F_{UC} = \\frac{\\pi^2}{3} (108 A^4 \\texttt v + 108 B^4 \\texttt v + \\psi_0^2 (24 + 6 \\texttt r + 4 \\texttt t \\psi_0 + 3 \\texttt v \\psi_0^2) + 24 B^2 (\\texttt r + \\psi_0 (2 \\texttt t + 3 \\texttt v \\psi_0)) + 24 A^2 (\\texttt r + 18 B^2 \\texttt v + 4 B (t + 3 \\texttt v \\psi_0) + \\psi_0 (2 \\texttt t + 3 \\texttt v \\psi_0))) \\] <p>Equilibrium amplitude equations</p> \\[ \\left \\lbrace         \\begin{array}{lrl}         \\partial_{\\psi_0} \\mathcal F_{UC} = 0: &amp; 4 B^2 (\\texttt t + 3 \\texttt v \\psi_0) + \\psi_0 (4 + \\texttt r + \\texttt t \\psi_0 + \\texttt v \\psi_0^2) + 4 A^2 (\\texttt t + 3 \\texttt v (2 B + \\psi_0)) &amp;= 0 \\\\         \\partial_{A} \\mathcal F_{UC} = 0: &amp; A (\\texttt r + 9 A^2 \\texttt v + 18 B^2 \\texttt v + 2 \\texttt t \\psi_0 + 3 \\texttt v \\psi_0^2 + 4 B (\\texttt t + 3 \\texttt v \\psi_0)) &amp;= 0 \\\\         \\partial_{B} \\mathcal F_{UC} = 0: &amp; 9 B^3 \\texttt v + 2 A^2 (t + 3 \\texttt v \\psi_0) + B (\\texttt r + 18 A^2 \\texttt v + 2 \\texttt \\texttt t \\psi_0 + 3 \\texttt v \\psi_0^2) &amp;= 0\\\\         \\end{array} \\right \\rbrace \\] <p>Default resolution: \\([7,7,7]^{-1}a_0\\)</p> <p>Default model parameters \\((\\texttt r,\\psi_0)\\): \\((-0.3,-0.325)\\)</p> <p>Free energy per unit cell (calculation document):</p> \\[ \\mathcal F_{UC} = \\frac{4 \\sqrt 2 \\pi^3}{3} \\left (1620 A^4 \\texttt v + 192 A^3 (t + 3 \\texttt v \\psi_0) + \\psi_0^2 (6 + 6 \\texttt r + 4 t \\psi_0 + 3 \\texttt v \\psi_0^2) + 72 A^2 (\\texttt r + \\psi_0 (2 t + 3 \\texttt v \\psi_0)) \\right ) \\] <p>Equilibrium amplitude (conserved)</p> \\[ \\left \\lbrace \\partial_{A} \\mathcal F_{UC} = 0:  A=0 ~ \\textrm{or} ~ \\quad A = \\frac{1}{45\\texttt v} \\left ( -2 \\texttt t - 6 \\texttt v \\psi_0 \\pm \\sqrt{ 4 \\texttt t^2 - 45 \\texttt r \\texttt v - 66 \\texttt t \\texttt v \\psi_0 - 99 \\texttt v^2 \\psi_0^2} \\right) \\right \\rbrace \\] <p>Equilibrium amplitude equations (unconserved)</p> \\[ \\left \\lbrace         \\begin{array}{lrl}         \\partial_{\\psi_0} \\mathcal F_{UC} = 0: &amp; 48 A^3 \\texttt v + 12 A^2 (\\texttt t + 3 \\texttt v \\psi_0) + \\psi_0 (1 + \\texttt r + \\texttt t \\psi_0 + \\texttt v \\psi_0^2) &amp;=0 \\\\         \\partial_{A} \\mathcal F_{UC} = 0: &amp; A (\\texttt r + 45 A^2 \\texttt v + 4 A (\\texttt t + 3 \\texttt v \\psi_0) + \\psi_0 (2 \\texttt t + 3 \\texttt v \\psi_0)) &amp;= 0\\\\         \\end{array} \\right \\rbrace \\] <p>Default resolution: \\([11,11,11]^{-1}a_0\\)</p> <p>Default model parameters \\((\\texttt r,\\psi_0)\\): \\((-0.3,-0.325)\\)</p> <p>Free energy per unit cell (calculation document):</p> \\[ \\mathcal F_{UC} = \\frac{2 \\pi^3}{\\sqrt 3} (1944 A^4 \\texttt v + 810 B^4 \\texttt v + \\psi_0^2 (32 + 18 \\texttt r + 12 \\texttt t \\psi_0 + 9 \\texttt v \\psi_0^2) + 108 B^2 (r + \\psi_0 (2 \\texttt t + 3 \\texttt v \\psi_0)) + 144 A^2 (\\texttt r + 36 B^2 \\texttt v + 6 B (t + 3 \\texttt v \\psi_0) + \\psi_0 (2 \\texttt t + 3 \\texttt v \\psi_0))) \\] <p>Equilibrium amplitude equations </p> \\[ \\left \\lbrace         \\begin{array}{lrl}         \\partial_{\\psi_0} \\mathcal F_{UC} = 0: &amp; 54 B^2 (t + 3 \\texttt v \\psi_0) + \\psi_0 (16 + 9 \\texttt r + 9 t \\psi_0 + 9 \\texttt v \\psi_0^2) + 72 A^2 (t + 3 \\texttt v (3 B + \\psi_0)) &amp;= 0 \\\\         \\partial_{A} \\mathcal F_{UC} = 0: &amp; A (\\texttt r + 27 A^2 \\texttt v + 36 B^2 \\texttt v + 2 t \\psi_0 + 3 \\texttt v \\psi_0^2 + 6 B (t + 3 \\texttt v \\psi_0)) &amp;= 0 \\\\         \\partial_{B} \\mathcal F_{UC} = 0: &amp; 15 B^3 \\texttt v + 4 A^2 (t + 3 \\texttt v \\psi_0) + B (\\texttt r + 48 A^2 \\texttt v + 2 t \\psi_0 + 3 \\texttt v \\psi_0^2) &amp;= 0\\\\         \\end{array} \\right \\rbrace \\] <p>Default resolution: \\([5,5,5]^{-1}a_0\\)</p> <p>Default model parameters \\((\\texttt r,\\psi_0)\\): \\((-0.3,-0.325)\\)</p> <p>Free energy per unit cell (calculation document):</p> \\[ \\mathcal F_{UC} = \\frac{2\\pi^3}{3} \\left (48 C^2 \\texttt r + 270 A^4 \\texttt v + 1620 B^4 \\texttt v + 576 A^3 C \\texttt v + 648 C^4 \\texttt v + 96 C^2 \\texttt t \\psi_0 + 6 (36 + \\texttt r + 24 C^2 \\texttt v) \\psi_0^2 + 4 \\texttt t \\psi_0^3 + 3 \\texttt v \\psi_0^4 + 192 B^3 (\\texttt t + 3 \\texttt v \\psi_0) + 576 A B C (t + 3 \\texttt v (3 B + \\psi_0)) + 36 A^2 (\\texttt r + 96 B^2 \\texttt v + 36 C^2 \\texttt v + 2 \\texttt t \\psi_0 + 3 \\texttt v \\psi_0^2 + 8 B (\\texttt t + 3 \\texttt v \\psi_0)) + 72 B^2 (r + 54 C^2 \\texttt v + \\psi_0 (2 \\texttt t + 3 \\texttt v \\psi_0)) \\right ) \\] <p>Equilibrium amplitude equations:</p> \\[ \\left \\lbrace         \\begin{array}{lrl}         \\partial_{\\psi_0} \\mathcal F_{UC} = 0: &amp; 8 C^2 \\texttt t + 48 B^3 \\texttt v + 144 A B C \\texttt v + 36 \\psi_0 + \\texttt r \\psi_0 + 24 C^2 \\texttt v \\psi_0 + \\texttt t \\psi_0^2 + \\texttt v \\psi_0^3 + 12 B^2 (t + 3 \\texttt v \\psi_0) + 6 A^2 (t + 3 \\texttt v (4 B + \\psi_0)) &amp;= 0 \\\\         \\partial_{A} \\mathcal F_{UC} = 0: &amp; 15 A^3 \\texttt v + 24 A^2 C \\texttt v + 8 B C (t + 3 \\texttt v (3 B + \\psi_0)) + A (\\texttt r + 96 B^2 \\texttt v + 36 C^2 \\texttt v + 2 \\texttt t \\psi_0 + 3 \\texttt v \\psi_0^2 + 8 B (t + 3 \\texttt v \\psi_0)) &amp;= 0 \\\\         \\partial_{B} \\mathcal F_{UC} = 0: &amp; 45 B^3 \\texttt v + 4 B^2 (t + 3 \\texttt v \\psi_0) + 2 A (A + 2 C) (t + 3 \\texttt v \\psi_0) + B (\\texttt r + 48 A^2 \\texttt v + 72 A C \\texttt v + 54 C^2 \\texttt v + 2 \\texttt t \\psi_0 + 3 \\texttt v \\psi_0^2) &amp;= 0\\\\         \\partial_{C} \\mathcal F_{UC} = 0: &amp; 27 C^3 \\texttt v + C (\\texttt r + 27 A^2 \\texttt v + 81 B^2 \\texttt v + 2 \\texttt t \\psi_0 + 3 \\texttt v \\psi_0^2) + 6 A (A^2 \\texttt v + 9 B^2 \\texttt v + B (t + 3 \\texttt v \\psi_0)) &amp;= 0\\\\         \\end{array} \\right \\rbrace \\] <p>We refer to these amplitudes \\(A,B,C\\) as proto amplitudes and they are calculated by the functions <code>calc_proto_amplitudes_conserved</code> (by default) and <code>calc_proto_amplitudes_unconserved</code> in the <code>pfc</code> class. The proto amplitudes are saved in the <code>pfc</code> instance as <code>eta0</code>. The function <code>calc_free_energy_from_proto_amplitudes</code> calculates the free energy \\(\\mathcal F_{UC}\\) from the proto amplitudes, including \\(\\psi_0\\).</p>"},{"location":"ClassPhaseFieldCrystal/#straining-the-ground-state-to-equilibrium","title":"Straining the ground state to equilibrium","text":"<p>While the q-vector given above and the proto amplitudes are good approximations to the ground state, they are not exact. In fact, if the PFC is initialized with these values, it will experience a slight residual stress <sup>10</sup>. To account for this, when initializing a PFC, the code will automatically strain the field to find the optimal value of \\(q_0\\), which is typically a few percent off the primary RLV. This is done numerically by simulating a \\(1\\times 1\\) unit cell and using the function <code>self.conf_strain_to_equilibrium</code> in the <code>pfc</code> class.</p> <p>In this function, we apply the following distortion</p> \\[ \\mathcal u_{ij} = \\epsilon \\delta_{ij} \\] <p>Given the equilibrium configuration, we can find more accurate estimates for the equilibrium amplitudes, but evolving the PFC for a few time steps and calculating the amplitudes from the demodulation of the field with the primary RLVs. This is done in the <code>calc_strained_amplitudes</code> function in the <code>pfc</code> class, which also calculates new values for the elastic constants (see below).</p>"},{"location":"ClassPhaseFieldCrystal/#the-amplitude-approximation-deviations-from-the-ground-state","title":"The amplitude approximation - deviations from the ground state","text":"<p>So far, we have only looked at the equilibrium state of the PFC, which has a specific symmetry, and the few-mode approximations that can be used to describe the PFC in this state. For small deviations from the equilibrium state, like in the presence of few dislocations and small strains, we can use the amplitude approximation, in which we assume that the field can be written as</p> <p>The amplitude approximation</p> \\[ \\psi \\approx \\bar \\psi + \\sum_{\\mathbf q^{(n)} \\in \\mathcal R^{(1)}} \\eta_n(\\mathbf r) e^{\\mathfrak i \\mathbf q^{(n)} \\cdot \\mathbf r}, \\] <p>where \\(\\eta_n\\) are slowly varying complex fields. These fields can be found by demodulating the field \\(\\psi\\) with the primary RLVs, i.e.,</p> <p>Demodulation</p> \\[ \\eta_n = \\langle \\psi e^{- \\mathfrak i \\boldsymbol{q}^{(n)} \\cdot \\boldsymbol{r}} \\rangle \\] <p>The figure below shows an example of the evolution of the PFC for a triangular lattice and the corresponding amplitude fields.</p> <p> </p> <p>Figure: Snapshots of an example evolution of the 2D triangular PFC model at (top row) \\(t=0\\) and (bottom row) \\(t=600\\). Parameters used were \\((r,\\psi_0) = (-0.3,-0.3)\\). The columns show the demodulated fields \\(\\bar \\psi\\) and \\(\\{ \\eta_n \\}_{n=1}^{3}\\), where the complex fields are shown by their phase \\(\\theta_n\\) and brightness corresponding to the magnitude \\(|\\eta_n|\\). Taken from Ref. <sup>2</sup> with permission.</p>"},{"location":"ClassPhaseFieldCrystal/#elasticity","title":"Elasticity","text":"<p>This quantity is the Poisson ratio, under some conditions. I think.  To be fixed.  \\(\\(\\nu = \\frac{\\lambda}{(d-1)\\lambda + 2\\mu + \\gamma}\\)\\)</p> <p>Elastic constants are saved in these quantities</p> <pre><code>pfc.el_mu\npfc.el_lambda\npfc.el_gamma\npfc.el_nu\n</code></pre>"},{"location":"ClassPhaseFieldCrystal/#stress-tensor","title":"Stress tensor","text":"<p>The equations for calculating the stress tensor are found in Ref. <sup>6</sup>, but we list them below, together wtih the elastic constants for each of the models. The stress tensor \\(h_{ij}\\) and its associated elastic constants interms of amplitudes (\\(A,B,C\\)) of the mode expansion for different PFCmodels. Here, \\(\\mathcal L_X = X+\\nabla^2\\). The elastic constants canbe expressed in Voigt notation by \\(C_{11} = \\lambda+2\\mu+\\gamma\\),\\(C_{12} = \\lambda\\), \\(C_{44}=\\mu\\).</p> Example: The 1D PFC - Stress tensor <p>In order to derive the stress tensor, suppose we have a state of the PFC given by \\(\\psi\\). We may deform this state in a mass-conserving fashion by a displacement field \\(u\\) (which is a scalar field in one dimension) as follows</p> \\[ \\psi' = \\psi - \\partial_x (\\psi u) \\] <p>We insert this into the expression for the free energy giving a new free energy \\(\\mathcal F'\\).</p> \\[ \\mathcal F' = \\int dx \\left ( \\frac{1}{2} ((1+\\partial_x^2) \\psi'))^2 + \\frac{1}{2} \\texttt r \\psi'^2 + \\frac{1}{3} \\texttt t \\psi'^3 + \\frac{1}{4} \\texttt v \\psi'^4 \\right )  \\] <p>If we take \\(u\\) to be an infinitesimal exploratory field, we can expand in \\(u\\), which gives</p> \\[ \\mathcal F' = \\mathcal F[\\psi] - \\int dx (1+\\partial_x^2)\\psi (1+\\partial_x^2) \\partial_x (\\psi u_x) - \\texttt r \\psi \\partial_x (\\psi u_x) - \\texttt t \\psi^2 \\partial_x (\\psi u_x) - \\texttt v \\psi^3 \\partial_x (\\psi u_x)  \\] \\[ = \\mathcal F[\\psi] - \\int dx (1+\\partial_x^2)\\psi (1+\\partial_x^2) \\partial_x (\\psi u_x) + (\\tilde \\mu_c - \\mathcal L^2) \\partial_x (\\psi u_x)  \\] \\[ \\nabla \\cdot  h  = \\left \\langle \\tilde \\mu_c \\nabla \\psi - \\nabla \\tilde f \\right \\rangle \\] 1D periodic2D triangular2D square3D body-centered cubic3D face-centered cubic3D simple cubic <p>Stress tensor</p> <p>Elastic constants</p> \\[ \\lambda = \\] \\[ \\mu = \\] \\[ \\gamma = \\] <p>Stress tensor</p> \\[ h_{ij} = -2\\left \\langle (\\mathcal L_1 \\psi) \\partial_{ij} \\psi \\right \\rangle \\] <p>Elastic constants</p> \\[\\lambda = 3A^2\\] \\[\\mu = 3A^2\\] \\[\\gamma = 0\\] <p>Stress tensor $$ h_{ij} = -2\\left \\langle (\\mathcal L_1 \\mathcal L_2 \\psi)(\\mathcal L_1 + \\mathcal L_2) \\partial_{ij} \\psi \\right \\rangle$$</p> <p>Elastic constants</p> \\[\\lambda = 16B^2\\] \\[\\mu = 16B^2\\] \\[\\gamma = 8A^2-32B^2\\] <p>Stress tensor</p> \\[h_{ij} = -2\\left \\langle (\\mathcal L_1 \\psi) \\partial_{ij} \\psi \\right \\rangle\\] <p>Elastic constants</p> \\[\\lambda = 4 A^2\\] \\[\\mu = 4 A^2\\] \\[\\gamma = -4A^2\\] <p>Stress tensor</p> \\[h_{ij} = -2\\left \\langle (\\mathcal L_1 \\mathcal L_{\\frac 4 3} \\psi)(\\mathcal L_1 + \\mathcal L_{\\frac 4 3}) \\partial_{ij} \\psi \\right \\rangle\\] <p>Elastic constants</p> \\[\\lambda = \\frac{32}{81} A^2\\] \\[\\mu = \\frac{32}{81} A^2\\] \\[\\gamma = \\frac{32}{81} (2B^2 - A^2)\\] <p>Stress tensor</p> \\[h_{ij} = -2\\left \\langle (\\mathcal L_1 \\mathcal L_2 \\mathcal L_3 \\psi)(\\mathcal L_2 \\mathcal L_3 + \\mathcal L_1 \\mathcal L_3 + \\mathcal L_1 \\mathcal L_2) \\partial_{ij} \\psi \\right \\rangle\\] <p>Elastic constants</p> \\[\\lambda = 16 B^2 + 128 C^2\\] \\[\\mu = 16 B^2 + 128 C^2\\] \\[\\gamma = 32 A^2 - 16 B^2 - 256 C^2\\] <p>As one sees, the expressions for the stress tensor all on the format</p> \\[ h_{ij} = -2\\left \\langle (\\mathcal L \\psi)(\\mathcal L_{\\sum} \\partial_{ij} \\psi \\right \\rangle, \\] <p>where \\(\\mathcal L\\) is as defined previously (as the product \\(\\mathcal L_1 ...\\)), and \\(\\mathcal L_{\\sum}\\) is a particular sum of \\(\\mathcal L_i\\) operators. \\(\\mathcal L\\) is calculated (in Fourier space) by the function <code>calc_L_f</code>, and the \\(\\mathcal L_{\\sum}\\) is calculated by the function <code>calc_L_sum_f</code> in the <code>pfc</code> class. The stress tensor is then calculated by the function <code>calc_microscopic_stress_tensor</code> in the <code>pfc</code> class. </p>"},{"location":"ClassPhaseFieldCrystal/#equilibrium-elastic-constants","title":"Equilibrium elastic constants","text":"<p>As mentioned above, the equilbrium state of the PFC is not exactly given by \\(q_0=1\\), and the proto amplitudes are not exact. However, in the process of deriving the equilibrium amplitudes after straining, we can also use the \\(1\\times 1\\) unit cell to calculate the elastic constants. This is done numerically by deforming the unit cell and calculating the increase in the elastic energy.  To illustrate this, consider a distortion of pure shear, i.e., </p> \\[ \\mathfrak u = \\begin{pmatrix} 0 &amp; \\epsilon &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}. \\] <p>The corresponding strain is given by</p> \\[ \\varepsilon = \\begin{pmatrix} 0 &amp; \\frac 1 2 \\epsilon &amp; 0 \\\\ \\frac 1 2 \\epsilon &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}. \\] <p>Under this deformation, the elastic energy </p> \\[ F_{el} = \\frac{1}{2} \\mathcal C_{ijkl} \\varepsilon_{ij} \\varepsilon_{kl} \\] <p>is given by</p> \\[ F_{el} =  \\mu e_{ij} e_{ij} = \\frac{1}{2} \\mu \\epsilon^2. \\] <p>We can apply the distortion \\(\\mathfrak u\\) with the function <code>conf_apply_distortion</code> in the <code>pfc</code> class. The result of this procedure for a \\(4\\times 4\\) square PFC is shown in the figure below</p> <p> </p> <p>Figure: The elastic constants of a 2D square PFC model as a function of the strain \\(\\epsilon\\) in the \\(x\\)-direction. The fit shows the numerical fit of the elastic constant \\(\\mu\\) to the applied strain, showing excellent agreement.</p> <p>While this works for the elastic constant \\(\\mu\\), the full elastic free energy is determined by three elastic constants, \\(\\lambda\\), \\(\\mu\\), and \\(\\gamma\\)</p> \\[ F_{el} = F_{el} = \\frac{1}{2} \\lambda (\\varepsilon_{kk})^2 + \\mu \\varepsilon_{ij} \\varepsilon_{ij} + \\frac{1}{2} \\gamma (\\varepsilon_{11}^2 + \\varepsilon_{22}^2 + \\varepsilon_{33}^2). \\] <p>To find these, we apply a series of deformations to the unit cell and use <code>scipy.optimize.curve_fit</code> to fit the elastic energy to the applied strain. This is done in the <code>calc_strained_amplitudes</code> and set to the <code>pfc</code> instance as <code>el_lambda</code>, <code>el_mu</code>, and <code>el_gamma</code> upon initialization.  The values are also printed to the terminal at initialization.</p> <p>The expression for the elastic constants in terms of the proto amplitudes were derived by inserting the amplitude approximation into the expression for the stress tensor. It is interesting to see that elastic constants obtained by using the equilibrium values of amplitudes match the elastic constants obtained by straining the PFC to equilibrium and performing the fit. </p>"},{"location":"ClassPhaseFieldCrystal/#strains","title":"Strains","text":"<p>In order to calculate the strain of a PFC configuration, we follow a generalized procedure as that outlined in Ref. <sup>2</sup>.  The ground state of the PFC can be written as </p> \\[ \\psi = \\psi_0 + \\eta_1 \\sum_{\\mathbf q^{(n)} \\in \\mathcal R^{(1)}} e^{i \\mathbf q^{(n)} \\cdot \\mathbf r} +  \\eta_2 \\sum_{\\mathbf q^{(n)} \\in \\mathcal R^{(2)}} e^{i \\mathbf q^{(n)} \\cdot \\mathbf r} +..., \\] <p>where \\(\\mathcal R^{(n)}\\) is the nth closest modes, i.e., the full reciprocal lattice can be written as </p> \\[ \\mathcal R = \\{\\mathbf 0 \\} \\cup \\left (\\cup_{n=1}^\\infty \\mathcal R^{(n)} \\right) \\] <p>We define the following quantity</p> \\[ \\Phi = N_1q_1^2\\eta_1^2 + N_2q_2^2\\eta_2^2 + ...  = \\sum_{\\mathbf q^{(n)} \\in \\mathcal R} \\eta_{n,0}^2|\\mathbf q^{(n)}|^2 \\] <p>Assuming that the mode-approximations hold, we can calculate \\(\\Phi\\) from the equilibrium amplitudes which are stored in the <code>PhaseFieldCrystal</code> instance, which is done routinely in the initialization of the class and stored in <code>pfc.Phi</code>. Consider now the structure function of the equilibrium state</p> \\[ \\mathcal S_{ij}  = \\langle \\partial_i \\psi \\partial_j \\psi\\rangle \\] \\[ = \\eta_1^2 \\sum_{\\mathbf q^{(n)} \\in \\mathcal R^{(1)}} q^{(n)}_iq^{(n)}_j +  \\eta_2^2 \\sum_{\\mathbf q^{(n)} \\in \\mathcal R^{(2)}} q_i^{(n)}q_j^{(n)}+... \\] \\[ = \\eta_1^2 \\frac{N_1 q_1^2}{d} \\delta_{ij} + \\eta_2^2 \\frac{N_2 q_2^2}{d} \\delta_{ij}+...  \\] \\[ = \\frac{\\Phi}{d}\\delta_{ij} \\] <p>The strain of the phase-field crystal can be calculated using the following formula The strain of the phase-field crystal can be calculated using the following formula<sup>2</sup></p> \\[ \\varepsilon_{ij} = \\frac{1}{2}\\delta_{ij} - \\frac{d}{2\\Phi} \\mathcal S_{ij}, \\] <p>where \\(\\mathcal S = \\langle \\nabla \\psi \\nabla \\psi \\rangle\\) is called the structure function <sup>7</sup> and is implemented in the <code>calc_strain_tensor</code> method of the <code>PhaseFieldCrystal</code> class. It should be noted that there is some residual strain due to the equilibrium periodicity of the lattice not matching exactly the periodicity of the simulation domain <sup>10</sup>. It is therefore often useful to subtract the mean value for visualization purposes.</p> <pre><code>strain = pfc.calc_strain_tensor()\nstrain = strain - np.mean(strain, axis=0)\n</code></pre>"},{"location":"ClassPhaseFieldCrystal/#dislocations","title":"Dislocations","text":"<p>The Burgers vector is defined by</p> <p>Burgers vector definition</p> \\[ \\oint_{\\partial \\mathcal M} d \\boldsymbol{u} = -\\boldsymbol{b}. \\] <p>The minus sign in this convention reflects the fact that we consider the Burgers vector to be the disconnection error from the ending point to the starting point, when going an oriented path around the dislocation,</p> <p> </p> <p>Burgers vector definition: (a) The one-body density of a crystalline solid containing an edge dislocation in a 2D square lattice (superimposed), (b) a 3D simple cubic lattice with an edge dislocation (\\(\\mathbf b \\perp \\mathbf t\\)), and (c) a 3D simple cubic lattice with a screw dislocation (\\(\\mathbf b \\parallel \\mathbf t)\\). In all cases, a circulation (green) that is right-handed with respect to the tangent vector \\(\\mathbf t\\), i.e., following a path around the dislocation, gives rise to a connection error: the Burgers vector \\(\\mathbf b\\). Reprinted from Ref. <sup>2</sup> with permission.</p> <p>In three dimensions, the path defining the dislocation is given by the direction of the dislocation line tangent \\(\\boldsymbol{t}\\). Multiplying this equation by the reciprocal lattice vector \\(-\\boldsymbol{q}^{(n)}\\), we get</p> \\[\\oint_{\\partial \\mathcal M} d (-\\boldsymbol{q}^{(n)} \\cdot \\boldsymbol{u}) = (\\boldsymbol{b} \\cdot \\boldsymbol{q}^{(n)}) \\equiv 2\\pi s_n,\\] <p>where \\(s_n\\) is the charge associated with the Burgers vector \\(\\boldsymbol{b}\\)</p> <p>Dislocation charge</p> \\[ s_n = \\frac{1}{2\\pi} \\boldsymbol{b} \\cdot \\boldsymbol{q}^{(n)}. \\] <p>Using the primary BLVs we get the charges summarized below</p> 2D triangular Burgers vector \\(\\mathbf b\\) \\(s_1\\) \\(s_2\\) \\(s_3\\) \\(\\mathbf a^{(1)} = a_0 (1,0)\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{blue}-1\\) \\(\\mathbf a^{(2)} = a_0 (1/2,\\sqrt 3/2)\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{blue}-1\\) \\(\\mathbf a^{(3)} = a_0 (1/2,-\\sqrt 3/2)\\) \\(\\color{red} 1\\) \\(\\color{blue}-1\\) \\(0\\) 2D square Burgers vector \\(\\mathbf b\\) \\(s_1\\) \\(s_2\\) \\(s_3\\) \\(s_4\\) \\(\\mathbf a^{(1)} = a_0 (1,0)\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\mathbf a^{(2)} = a_0(0,1)\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{blue}-1\\) \\(\\color{red} 1\\) 3D body-centered cubic Burgers vector \\(\\mathbf b\\) \\(s_1\\) \\(s_2\\) \\(s_3\\) \\(s_4\\) \\(s_5\\) \\(s_6\\) \\(\\mathbf a^{(1)} = a_0/2 (-1,1,1)\\) \\(\\color{red} 1\\) \\(0\\) \\(0\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\mathbf a^{(2)} = a_0/2 (1,-1,1)\\) \\(0\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{blue}-1\\) \\(\\mathbf a^{(3)} = a_0/2 (1,1,-1)\\) \\(0\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{blue}-1\\) \\(\\color{blue}-1\\) \\(0\\) \\(\\mathbf a^{(4)} = a_0/2 (1,1,1)\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(0\\) \\(0\\) \\(0\\) 3D face-centered cubic Burgers vector \\(\\mathbf b\\) \\(s_1\\) \\(s_2\\) \\(s_3\\) \\(s_4\\) \\(s_5\\) \\(s_6\\) \\(s_7\\) \\(\\mathbf a^{(1)} = a_0/2(0,1,1)\\) \\(\\color{red} 1\\) \\(0\\) \\(0\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\mathbf a^{(2)} = a_0/2(1,0,1)\\) \\(0\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{red} 1\\) \\(\\mathbf a^{(3)} = a_0/2 (1,1,0)\\) \\(0\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(0\\) \\(\\mathbf a^{(4)} = a_0/2(0,-1,1)\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{blue}-1\\) \\(0\\) \\(0\\) \\(\\color{blue}-1\\) \\(\\color{red} 1\\) \\(\\mathbf a^{(5)} = a_0/2 (-1,0,1)\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{blue}-1\\) \\(0\\) \\(\\color{blue}-1\\) \\(0\\) \\(\\color{red} 1\\) \\(\\mathbf a^{(6)} = a_0/2(-1,1,0)\\) \\(\\color{red} 1\\) \\(\\color{blue}-1\\) \\(0\\) \\(0\\) \\(\\color{blue}-1\\) \\(\\color{red} 1\\) \\(0\\) 3D simple cubic Burgers vector \\(\\mathbf b\\) \\(s_1\\) \\(s_2\\) \\(s_3\\) \\(s_4\\) \\(s_5\\) \\(s_6\\) \\(s_7\\) \\(s_8\\) \\(s_9\\) \\(s_{10}\\) \\(s_{11}\\) \\(s_{12}\\) \\(s_{13}\\) \\(\\mathbf a^{(1)} = a_0(1,0,0)\\) \\(\\color{red} 1\\) \\(0\\) \\(0\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{blue}-1\\) \\(\\color{blue}-1\\) \\(\\color{blue}-1\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\mathbf a^{(2)} = a_0 (0,1,0)\\) \\(0\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{blue}-1\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\color{blue}-1\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\mathbf a^{(3)} = a_0(0,0,1)\\) \\(0\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(0\\) \\(\\color{red} 1\\) \\(\\color{red} 1\\) \\(\\color{blue}-1\\) \\(\\color{red} 1\\)"},{"location":"ClassPhaseFieldCrystal/#the-dislocation-density-tensor","title":"The dislocation density tensor","text":"<p>Given a PFC configuration, the dislocation density tensor may be calculated as <sup>8</sup></p> <p>The dislocation density tensor</p> \\[ \\alpha_{ij} = \\frac{2d}{N\\eta_0^2} \\sum_{n=1}^N D_i^{(n)} q_j^{(n)} = \\frac{2 \\pi d}{N} \\sum_{n=1}^N \\rho_i^{(n)} q_j^{(n)} \\] <p>where \\(\\boldsymbol{D}^{(n)}\\) is calculated from \\(\\boldsymbol{\\psi }= (\\Re(\\eta_n), \\Im(\\eta_n))\\) from the \\(N\\) primary reciprocal lattice vectors \\(\\boldsymbol{q}^{(n)}\\) and</p> \\[ \\rho^{(n)}_i = \\frac{1}{\\pi \\eta_0^2} D^{(n)}_i \\] <p>In the language of this</p>"},{"location":"ClassPhaseFieldCrystal/#equations-of-motion","title":"Equations of motion","text":""},{"location":"ClassPhaseFieldCrystal/#conserved-evolution","title":"Conserved evolution","text":"<p>The basic equation motion presented in Ref. <sup>1</sup> can be derived by postulating a simple mechanism for free energy minimzation under the constraint of mass conservation.</p> <p>The PFC evolution equation (<code>evolve_PFC</code>)</p> \\[ \\partial_t \\psi = \\nabla^2 \\tilde \\mu_c, \\] <p>The linear part \\(\\mathcal L^2  + \\texttt r\\) of the chemical potential (not multiplied by psi) is calculated by </p> <pre><code>pfc.calc_chemical_potential_linear_part_f()\n</code></pre> <p>The PFC chemical potential</p> <p>which gives</p> \\[ {{\\omega }_{\\mathfrak f}}= -\\boldsymbol{k}^2 (\\texttt r + {{\\mathcal L}_{\\mathfrak f}}^2) \\] \\[ N = \\nabla^2 (\\psi^3) \\]"},{"location":"ClassPhaseFieldCrystal/#unconserved-dynamics","title":"Unconserved dynamics","text":"<p>The unconserved PFC evolution equation (<code>evolve_PFC_unconserved</code>)</p> \\[ \\partial_t \\psi = - \\tilde \\mu_c \\]"},{"location":"ClassPhaseFieldCrystal/#evolution-at-mechanical-equilibrium","title":"Evolution at mechanical equilibrium","text":"<p>The PFC evolution at mechanical equilibrium (<code>evolve_PFC_mechanical_equilibrium</code>)</p> <p>Step 1:</p> \\[\\psi(t+\\Delta t) = \\textrm{Integrate($\\Delta t$):} (\\partial_t \\psi)\\] <p>Step 2:</p> \\[\\psi(t + \\Delta t, \\boldsymbol{r}) \\leftarrow \\psi(t + \\Delta t, \\boldsymbol{r} - \\boldsymbol{u}^\\delta),\\] <p>where \\(\\boldsymbol{u}^\\delta\\) is the solution to</p> \\[ \\partial_{j} \\mathcal C_{ijkl} \\partial_l u_k = - g^\\psi_i, \\] <p>where</p> \\[ g^\\psi_i = -\\partial_j \\mathfrak h_{ij}^\\psi, \\] <p>and the elastic constants tensor \\(\\mathcal C\\) is given by</p> \\[ \\mathcal C_{ijkl} = \\lambda \\delta_{ij}\\delta_{kl} + 2\\mu \\delta_{k(i} \\delta_{j)l} + \\gamma \\delta_{ijkl}. \\] <p>This equation is solved in Fourier space by</p> \\[ {u}_{\\mathfrak f ~ i}^\\delta = G_{\\mathfrak f ~ ij} g_{\\mathfrak f ~ j}^\\psi, \\] <p>where the Greens function \\(G_{\\mathfrak f ~ ij}\\) is given in Ref. <sup>9</sup> as</p> \\[ {G_{\\mathfrak f ~ij}} (\\mathbf k) =\\frac{1}{\\mathbf k^2}\\left ( \\frac{\\delta_{ij}}{\\mu + \\gamma \\kappa_{(i)}^2} - \\frac{\\kappa_i \\kappa_j}{(\\mu +  \\gamma \\kappa_{(i)}^2 )(\\mu +  \\gamma \\kappa_{(j)}^2 )} \\frac{\\mu+\\lambda}{1+ \\sum_{l=1}^3 \\frac{\\mu + \\lambda}{\\mu+\\gamma \\kappa_l^2} \\kappa_l^2 }\\right ), \\] <p>with \\(\\boldsymbol \\kappa = \\mathbf k/|\\mathbf k|\\) there is no implicit summation over indices \\((i),(j)\\). By defining \\(k_3=0\\), this equation is also valid for the triangular and square symmetry in two dimensions.</p> <p>Note that due to the asymmetry of the elastic constants, this method can only be used for small deviations of the lattice orientation.</p>"},{"location":"ClassPhaseFieldCrystal/#hydrodynamic-pfc-evolution","title":"Hydrodynamic PFC evolution","text":"<p>In Ref. <sup>7</sup>, a hydrodynamic approach was derived.  A simplified two-parameter model was proposed</p> <p>The hydrodynamic PFC model (<code>evolve_PFC_hydrodynamic</code>)</p> \\[ \\partial_t \\psi = \\nabla^2 \\tilde \\mu_c - \\boldsymbol{v} \\cdot \\nabla \\psi \\] \\[ \\partial_t \\boldsymbol{v} = \\frac{1}{\\rho_0} (\\nabla \\cdot  h + \\Gamma_S \\nabla^2 \\boldsymbol{v} + \\boldsymbol{f}^{\\textrm(ext)}) \\] <p>We insert for \\(\\tilde \\mu_c\\) and write it in matrix form to emphasize the linear and non-linear parts</p> \\[ \\partial_t \\begin{pmatrix}  \\psi \\\\  v_1 \\\\  v_2 \\\\  v_3 \\end{pmatrix} = \\begin{pmatrix}  \\nabla^2 (r + \\mathcal L^2) \\psi \\\\  \\frac{1}{\\rho_0}\\Gamma_S \\nabla^2 v_1 \\\\  \\frac{1}{\\rho_0}\\Gamma_S \\nabla^2 v_2 \\\\  \\frac{1}{\\rho_0}\\Gamma_S \\nabla^2 v_3 \\end{pmatrix} + \\begin{pmatrix}  \\nabla^2 ( \\psi^3)  - \\boldsymbol{v} \\cdot \\nabla \\psi \\\\  \\frac{1}{\\rho_0} \\left (  \\left \\langle \\tilde \\mu_c \\partial_x \\psi - \\partial_x \\tilde f \\right \\rangle  + f_x^{(ext)}\\right )\\\\  \\frac{1}{\\rho_0} \\left (  \\left \\langle \\tilde \\mu_c \\partial_y \\psi - \\partial_y \\tilde f \\right \\rangle  + f_y^{(ext)}\\right ) \\\\  \\frac{1}{\\rho_0} \\left (  \\left \\langle \\tilde \\mu_c \\partial_z \\psi - \\partial_z \\tilde f \\right \\rangle  +  f_z^{(ext)} \\right ) \\end{pmatrix} \\]"},{"location":"ClassPhaseFieldCrystal/#configurations","title":"Configurations","text":"<p>The PFC class has a number of methods for generating initial conditions.</p>"},{"location":"ClassPhaseFieldCrystal/#dislocation-dipoles-and-loops","title":"Dislocation dipoles and loops","text":"<p>The simplest setup for the PFC is to insert a dislocation dipole or dislocation loop.</p>"},{"location":"ClassPhaseFieldCrystal/#polycrystal-configurations","title":"Polycrystal configurations","text":"<p>To set a polycrystal configuration, one typically calculates the PFC from a set of rotated reciprocal lattices. This is done in the <code>calc_PFC_from_amplitudes</code> method, using the <code>rotation</code> keyword argument. Then, one constructs a field with the desired orientation by setting the field in the regions corresponding to the rotated reciprocal lattice to the rotated field. In order to avoid numerical artifacts with the interface, it is recommended to smooth the interface by evolving the PFC for a few time steps according to classical PFC dynamics.</p> Example: Creating a circular inclusion <p>To create a circular inclusion in 2 dimensions, you can run the following code.</p> <pre><code>import comfit as cf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy as sp\n\npfc = cf.PhaseFieldCrystal2DSquare(30,30)\npfc.dt=0.05\n\n# This creates a standard orientation of the crystal\npfc.conf_PFC_from_amplitudes()\n\n# Create the rotated field\npsi_rotated = pfc.calc_PFC_from_amplitudes(rotation=np.pi/6)\n\n# Specify the region centered at the mid position with radius 6 a0.\ninclusion_region = pfc.calc_region_disk(pfc.rmid, 6*pfc.a0)\n\n# Set the rotated field in the inclusion region\npfc.psi[inclusion_region] = psi_rotated[inclusion_region]\npfc.psi_f = sp.fft.fftn(pfc.psi)\n\n#Smooth the interface\ntau = 10\npfc.evolve_PFC(round(tau/pfc.dt)) \n\npfc.plot_field(pfc.psi)\nplt.show()\n</code></pre> <p>This will produce the following image.</p> <p> </p> <p>The class comes with a variety of pre-configured setups for polycrystalline configurations, which are created using the <code>conf_create_polycrystal</code> method. This function takes as argument a keyword argument <code>type</code>, which is a string specifying the type of polycrystal to create. The available types are</p> <code>circular</code><code>four_grain</code> <p>This creates a circular inclusion valid in 2 and 3 dimensions.  The type opens for two additional keywords:</p> <ul> <li> <p><code>radius</code> which specifies the radius of the inclusion (default <code>self.size_min/4</code>).</p> </li> <li> <p><code>position</code> which specifies the position of the center of the inclusion (default <code>self.rmid</code>).</p> </li> <li> <p><code>rotation</code> a float specifying the rotation of the inclusion wrt. the z-axis (default <code>np.pi/6</code>).</p> </li> </ul> <p>If initialized in 3 dimensions, the inclusion will be a cylinder extended along the z-axis.</p> <p> </p> <p>This creates a four-grain configuration valid in 2 and 3 dimensions. The type allows for no additional keywords.</p> <p>If initialized in 3 dimensions, the four grains will be extended along the z-axis.</p> <p> </p>"},{"location":"ClassPhaseFieldCrystal/#calculating-the-orientation-field","title":"Calculating the orientation field","text":"<p>In many simulations with polycrystals, it is useful to calculate the orientation field. This is a vector field that points in the direction of the crystal orientation. To calculate the orientation field, we rely on the amplitude approximation of the PFC field, demodulate with respect to different orientations and estimate the orientation based on the magnitude of these amplitudes.</p> <p>Consider the 2D case for a triangular PFC, in which the rotation angle \\(\\theta\\) is given with respect to the z-axis. For a given rotation, we can demodulate the PFC with respect to a triplet of reciprocal lattice vectors.</p> \\[ \\{ R(\\theta) \\mathbf q^{(n)} \\}, \\] <p>where \\(R(\\theta)\\) is the rotation matrix and \\(\\mathbf q^{(n)}\\) is the primary reciprocal lattice vector of the unrotated PFC. This will give three amplitudes \\(\\eta_n\\), the combined magnitude   </p> \\[ \\Phi^2 = \\sum_{n=1}^3 |\\eta_n|^2 \\] <p>of which will indicate to which degree the orientation of the PFC aligns with that direction.</p>"},{"location":"ClassPhaseFieldCrystal/#straining-the-pfc","title":"Straining the PFC","text":"<p>In some simulations, it is useful to prescribe a strain to the PFC. This is done by updating the grid on which the PFC is defined.</p> <p>In one dimension, the only strain that can be applied is a compression or expansion of the grid, given by \\(\\mathfrak e_{xx}\\).</p> <p>In this case, these variables are updated according to </p> <pre><code>self.k[0] = self.k[0]/(1+strain)\nself.dif[0] = self.dif[0]/(1+strain)\nself.x = self.x*(1+strain)\n</code></pre> <p>In two dimensions, the strain tensor is given by three components \\(\\mathfrak e_{xx}\\), \\(\\mathfrak e_{xy}\\), and \\(\\mathfrak e_{yy}\\). In principles, these components cannot be set arbitrarily, since the components must satisfy the compatibilit equations</p> \\[ \\partial_y^2 \\mathfrak e_{xx} + \\partial_x^2 \\mathfrak e_{yy} = 2 \\partial_x \\partial_y \\mathfrak e_{xy}. \\] <p>In this case, however, we are limiting ourselves to a constant strain, in which case the compatibility equation is automatically satisfied and the deformation is given by</p> \\[ \\begin{array}{ll} u_x = \\mathfrak e_{xx} x + \\mathfrak e_{xy} y, \\\\ u_y = \\mathfrak e_{xy} x + \\mathfrak e_{yy} y. \\end{array} \\] <p>The coordinates will transform according to</p> \\[ \\begin{array}{ll} x \\rightarrow x + u_x, \\\\ y \\rightarrow y + u_y. \\end{array} \\] <p>which is is given by </p> \\[ \\begin{array}{ll} x' \\\\ y' \\end{array} = \\begin{array}{ll} 1 + \\mathfrak e_{xx} &amp; \\mathfrak e_{xy} \\\\ \\mathfrak e_{xy} &amp; 1 + \\mathfrak e_{yy} \\\\ \\end{array} \\begin{array}{ll} x \\\\ y \\end{array} \\] <p>We save the components of the strain matrix \\(T = \\begin{array}{ll} 1 + \\mathfrak e_{xx} &amp; \\mathfrak e_{xy} \\\\ \\mathfrak e_{xy} &amp; 1 + \\mathfrak e_{yy} \\\\ \\end{array} \\begin{array}{ll}\\) in the <code>distortion_matrix</code> variable. The wave vectors are updated according to</p> \\[ \\begin{array}{ll} k_x' \\\\ k_y' \\end{array} = T^{-1} \\begin{array}{ll} k_x \\\\ k_y \\end{array} \\] <p>The grid components</p> <p>Normally, the grid components <code>x</code>, <code>y</code>, and <code>z</code> are set as 1-dimensional arrays, and the same with <code>self.k[0]</code>, <code>self.k[1]</code>, and <code>self.k[2]</code>. When applying an external strain, however, the grid components will vary in the different directions and will become multi-dimensional arrays. This increases the memory usage of the simulation. </p> <p>The strain thus contains three components <code>strain[0]</code>, <code>strain[1]</code>, and <code>strain[2]</code>.</p> <p>, and the grid is updated according to</p> <pre><code>\n</code></pre> <ol> <li> <p>Elder, K. R., &amp; Grant, M. (2004). Modeling elastic and plastic deformations in nonequilibrium processing using phase field crystals. Physical Review E, 70(5), 051605. https://doi.org/10.1103/PhysRevE.70.051605 \u21a9\u21a9</p> </li> <li> <p>Skogvoll, V. (2023). Symmetry, topology, and crystal deformations: a phase-field crystal approach. Doctoral Thesis. University of Oslo https://www.duo.uio.no/handle/10852/102731 \u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>Emdadi, A., Asle Z., Mohsen and Asadi, E. (2016). Revisiting Phase Diagrams of Two-Mode Phase-Field Crystal Models. Computational Materials Science. 123, 139-147. https://doi.org/10.1016/j.commatsci.2016.06.018 \u21a9</p> </li> <li> <p>Wu, K. A., Adland, A. and Karma, A. (2010). Phase-Field-Crystal Model for Fcc Ordering. Physical Review E. 81, 6, 06101. https://doi.org/10.1103/PhysRevE.81.061601 \u21a9</p> </li> <li> <p>Wu, K-A. and Karma, A. (2007). Phase-Field Crystal Modeling of Equilibrium Bcc-Liquid Interfaces. Physical Review B. 76, 18, 184107. https://doi.org/10.1103/PhysRevB.76.184107 \u21a9</p> </li> <li> <p>Skogvoll, V., Skaugen, A. and Angheluta, L. (2021). Stress in Ordered Systems: Ginzburg-Landau-type Density Field Theory. Physical Review B. 103, 22, 224107. https://doi.org/10.1103/PhysRevB.103.224107 \u21a9</p> </li> <li> <p>Skogvoll, V., Salvalaglio, M. and Angheluta, L. (2022). Hydrodynamic Phase Field Crystal Approach to Interfaces, Dislocations and Multi-Grain Networks. Modelling and Simulation in Materials Science and Engineering. https://doi.org/10.1088/1361-651X/ac9493 \u21a9\u21a9</p> </li> <li> <p>Skogvoll, V., Angheluta, L., Skaugen, A., Salvalaglio, M. and Vi\u00f1als, J. (2022). A Phase Field Crystal Theory of the Kinematics of Dislocation Lines. Journal of the Mechanics and Physics of Solids. 166, 104932. https://doi.org/10.1016/j.jmps.2022.104932 \u21a9</p> </li> <li> <p>Dederichs, P. H. and Leibfried, G. (1969). Elastic Green's function for anisotropic cubic crystals. Physical Review. 188, 3, 1175. https://doi.org/10.1103/PhysRev.188.1175 \u21a9</p> </li> <li> <p>Punke, M., Skogvoll, V., &amp; Salvalaglio, M. (2023). Evaluation of the elastic field in phase-field crystal simulations. PAMM, 23(3), e202300213. https://doi.org/10.1002/pamm.202300213 \u21a9\u21a9</p> </li> </ol>"},{"location":"ClassQuantumMechanics/","title":"Class: Quantum Mechanics","text":"<p>Quantum mechanics describes the behavior of nature at the scale of atoms and subatomic particles. The Schr\u00f6dinger equation is a fundamental partial differential equation that governs how the quantum state of a physical system evolves over time.</p> <p>This class simulates quantum mechanics by evolving the Schr\u00f6dinger equation.</p> <pre><code>file: comfit/quantum_mechanics/quantum_mechanics.py \nclass: QuantumMechanics\n</code></pre> <p>See the ComFiT Library Reference below for a complete list of class methods and their usage.</p>  ComFiT Library Reference"},{"location":"ClassQuantumMechanics/#example","title":"Example","text":"<p>The following example demonstrates how to set up a 1D quantum system with a Gaussian wave packet and a potential barrier. It runs smoothly with <code>comfit 1.8.4</code>.</p> <pre><code>import comfit as cf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Set up a 1D quantum system\nqm = cf.QuantumMechanics(1, xlim=[-50,50], xRes=1001, dt=0.1)\n\n# Initialize a Gaussian wavepacket at x=5 with velocity=1\nqm.conf_initial_condition_Gaussian(position=5, width=1, initial_velocity=1)\n\n# Add a potential barrier (optional)\nqm.V_ext = 0.5 * (qm.x &gt; 10) * (qm.x &lt; 12)  # Barrier from x=10 to 12\n\nheight = np.max(abs(qm.psi))  # Get the maximum value of the wavefunction for plotting limits\n\n# Optional: Animate it\nfor n in range(61):\n    qm.evolve_schrodinger(5)\n    fig, ax = qm.plot_complex_field(qm.psi)\n    qm.plot_field(qm.V_ext, fig=fig, ax=ax, ylim=[0,height], xlim=[0,20])\n    qm.plot_save(fig, n)\ncf.tool_make_animation_gif(n)  # Creates animation.gif\n</code></pre> <p> </p>"},{"location":"ClassQuantumMechanics/#the-schrodinger-equation","title":"The Schr\u00f6dinger equation","text":"<p>The time-dependent Schr\u00f6dinger equation for a particle of mass \\(m_e\\) in a potential \\(V\\) is given by:</p> \\[ \\mathfrak i \\hbar \\partial_t \\psi = \\left [-\\frac{\\hbar^2}{2m_e} \\nabla^2 + V \\right ] \\psi. \\] <p>where \\(\\psi\\) is the wave function, \\(\\hbar\\) is the reduced Planck constant.</p> <p>To simplify the equation for numerical simulation, we can introduce dimensionless units. Dividing by the Hartree energy \\(E_h = \\frac{\\hbar^2}{m_e a_0^2}\\) (where \\(a_0\\) is the Bohr radius) yields:</p> \\[ \\mathfrak i \\frac{\\hbar}{E_h} \\partial_t \\psi = \\frac{1}{E_h}\\left [-\\frac{\\hbar^2}{2m_e} \\nabla^2 + V \\right ] \\psi. \\] <p>Expressing time in units of \\(\\tau = \\frac{\\hbar}{E_h}\\), potential energy \\(V\\) in units of \\(E_h\\), and length squared in units of \\(a_0^2\\), we obtain the dimensionless Schr\u00f6dinger equation:</p> \\[ \\partial_t \\psi = \\mathfrak i\\left [\\frac{1}{2} \\nabla^2 - V \\right ] \\psi. \\] <p>This is the form implemented in the <code>QuantumMechanics</code> class. The linear operator \\(\\omega\\) and its Fourier space representation \\(\\omega_{\\mathfrak f}\\) are:</p> \\[ \\omega = \\mathfrak i\\frac{1}{2} \\nabla^2 \\quad \\Rightarrow \\quad \\omega_{\\mathfrak f}(\\mathbf{k}) = -\\mathfrak i \\frac{1}{2} \\mathbf k^2 \\] <p>The non-linear part (in this context, the potential term which depends on \\(\\psi\\) only through multiplication) is \\(N = -\\mathfrak i V \\psi\\).</p> Atomic unit of Value Length (\\(a_0\\)) 0.529 \u00c5 (Angstrom) Energy (\\(E_h\\)) 27.2 eV (electron volts) Time (\\(\\tau\\)) 24.2 as (attoseconds)"},{"location":"ClassQuantumMechanics/#the-born-rule","title":"The Born rule","text":"<p>The Born rule states that the probability density of finding the particle at position \\(\\mathbf{r}\\) at time \\(t\\) is given by \\(|\\psi(\\mathbf{r}, t)|^2\\). Consequently, the probability \\(P\\) of finding the particle within a volume \\(\\mathcal{V}\\) is:</p> \\[ P = \\int_{\\mathcal{V}} d^d r |\\psi(\\mathbf{r}, t)|^2. \\] <p>The total probability of finding the particle anywhere in space must be 1, leading to the normalization condition:</p> \\[ \\int d^d r |\\psi(\\mathbf{r}, t)|^2 = 1. \\]"},{"location":"ClassQuantumMechanics/#the-momentum-representation","title":"The Momentum representation","text":"<p>In quantum mechanics, the Fourier transform provides the connection between the position representation (\\(\\psi(\\mathbf{r})\\)) and the momentum representation (\\(\\phi(\\mathbf{k})\\)) of a quantum state. This relationship highlights the wave-particle duality inherent in quantum theory.</p> <p>The momentum-space wave function \\(\\phi(\\mathbf{k})\\), where \\(|\\phi(\\mathbf{k})|^2\\) represents the probability density of finding the particle with wave vector \\(\\mathbf{k}\\) (momentum \\(\\mathbf{p} = \\hbar \\mathbf{k}\\)), is related to the position-space wave function \\(\\psi(\\mathbf{r})\\) via the Fourier transform:</p> \\[\\phi(\\mathbf{k}) = \\sqrt{(2\\pi)^d} \\, \\psi_{\\mathfrak f} (\\mathbf{k})\\] <p>where \\(\\psi_{\\mathfrak f} (\\mathbf{k})\\) is the Fourier transform of \\(\\psi(\\mathbf{r})\\) as defined in the Base System documentation, and \\(d\\) is the spatial dimension. The factor \\(\\sqrt{(2\\pi)^d}\\) ensures that if \\(\\psi(\\mathbf{r})\\) is normalized in position space, then \\(\\phi(\\mathbf{k})\\) is normalized in momentum space:</p> \\[ \\int d^d k |\\phi(\\mathbf{k})|^2 = 1. \\]"},{"location":"ClassQuantumMechanics/#physical-significance-of-the-fourier-transform-in-qm","title":"Physical Significance of the Fourier Transform in QM","text":"<ol> <li>Complementarity: The Fourier transform relationship mathematically embodies Heisenberg's uncertainty principle. A wave function highly localized in position space (narrow \\(\\psi(\\mathbf{r})\\)) corresponds to a widely spread momentum distribution (broad \\(\\phi(\\mathbf{k})\\)), and vice versa.</li> <li>Operator Correspondence: In the position representation, the momentum operator is \\(\\hat{\\mathbf{p}} = -\\mathfrak i\\hbar\\nabla\\). The Fourier transform maps this differential operator in position space to a simple multiplicative operator (\\(\\hbar \\mathbf{k}\\)) in momentum space.</li> <li>Energy Eigenstates: For a free particle (\\(V=0\\)), the energy eigenstates are plane waves, \\(\\psi(\\mathbf r) \\propto e^{\\mathfrak i \\mathbf k \\cdot \\mathbf r}\\), which are also momentum eigenstates.</li> </ol>"},{"location":"ClassQuantumMechanics/#a-wave-packet","title":"A wave packet","text":"<p>A Gaussian wave function, often referred to as a wave packet, provides a localized representation of a particle in quantum mechanics, balancing position and momentum uncertainty. A normalized Gaussian wave packet centered at \\(\\mathbf{r}_0\\) with width \\(\\sigma\\) is given by:</p> \\[ \\psi(\\mathbf r) = \\sqrt{( 2\\pi \\sigma )^{-d/2} \\exp\\left ({-\\frac{(\\mathbf r - \\mathbf r_0)^2} {(2\\sigma^2)}}\\right )} , \\] <p>such that the probability density \\(|\\psi(\\mathbf{r})|^2 = (2\\pi \\sigma^2)^{-d/2} \\exp\\left ({-\\frac{(\\mathbf r - \\mathbf r_0)^2} {2\\sigma^2}}\\right )\\) is a Gaussian distribution with standard deviation \\(\\sigma\\).</p> <p>An initial average velocity \\(\\mathbf v_0\\) (corresponding to an average momentum \\(\\hbar \\mathbf{k}_0 = m_e \\mathbf{v}_0\\)) can be imparted to the wave packet by multiplying it with a complex phase factor \\(e^{\\mathfrak i \\mathbf{k}_0 \\cdot \\mathbf r} = e^{\\mathfrak i (m_e/\\hbar)\\mathbf v_0 \\cdot \\mathbf r}\\). In dimensionless units where \\(m_e=\\hbar=1\\), this simplifies to \\(e^{\\mathfrak i \\mathbf v_0 \\cdot \\mathbf r}\\).</p> <p>Such an initial condition can be configured using the function <code>qm.conf_initial_condition_Gaussian</code>.</p>"},{"location":"Conventions/","title":"Conventions","text":"<p>In this section, we will describe the conventions used in the documentation and code.</p>"},{"location":"Conventions/#folders-and-file-types","title":"Folders and file types","text":"<ul> <li>Documentation is written in markdown.</li> <li>Tutorials are written in markdown.</li> </ul>"},{"location":"Conventions/#file-naming-conventions","title":"File naming conventions","text":"<ul> <li>Documentation files are named using CamelCase.</li> <li>Image files in the docs folder are named using <code>snake_case</code></li> </ul>"},{"location":"Conventions/#mathematical-conventions","title":"Mathematical conventions","text":"<p>The imaginary unit will be denoted \\(\\mathfrak i\\), <code>\\mathfrak i</code> to avoid confusion with the index \\(i\\). Index symmetrization \\(()\\) and anti-symmetrization \\([]\\) will be used throughout. They are defined for an tensor \\(A\\) with two indices by</p> \\[ A_{(ij)} = \\frac{1}{2} (A_{ij} + A_{ji}), \\] \\[ A_{[ij]} = \\frac{1}{2} (A_{ij} - A_{ji}) \\] <p>The Fourier transform of a field \\(\\psi\\) will be denoted \\(\\psi_{\\mathfrak f}\\), <code>\\psi_{\\mathfrak f}</code>, and is defined as</p> \\[ \\psi_{\\mathfrak f} (\\mathbf k) = \\int d^d r e^{-\\mathfrak i \\mathbf k \\cdot \\mathbf r} f(\\mathbf r), \\] <p>and the inverse is given by</p> \\[ \\psi(\\mathbf r) = \\frac{1}{(2\\pi)^d} \\int d^d k e^{\\mathfrak i\\mathbf k\\cdot \\mathbf r} \\psi_{\\mathfrak f}(\\mathbf k), \\] <p>where \\(d\\) is the spatial dimension.</p> <p>Vectors \\(\\mathbf a, \\mathbf b, \\mathbf c, \\boldsymbol \\Omega\\) are denoted using boldfont (<code>\\mathbf</code>, <code>\\boldsymbol</code>) , while rank 2 tensors vary more. Typical choices however are non-bold greek letters (\\(\\sigma\\)) lower case Fraktur letters (\\(\\mathfrak h\\), <code>\\mathfrak h</code>) or capital letters (\\(Q\\)).</p> <p>The dot product (\\(\\cdot\\)) is a contraction over the last index</p> <pre><code>(\\nabla \\cdot \\sigma)_i = \\partial_j {\\sigma}_{ij}\n</code></pre> <p>while the double dot product \\(\\dot \\cdot\\) is a contraction over the last two indices</p> \\[ (\\mathcal C \\dot \\cdot \\mathfrak e)_ {ij} = \\mathcal C_ {ijkl} \\mathfrak e_ {kl} \\]"},{"location":"Conventions/#programming-notation-conventions","title":"Programming notation conventions","text":"<ul> <li>PEP8 for python programming</li> <li>NumPy docstring format for documentation strings</li> <li>Import ordering should follow this pattern:</li> <li>Standard library imports</li> <li>Third-party library imports</li> <li>Local application imports</li> <li>Each group should be separated by a blank line</li> </ul> <p>Stand-alone functions are documented as follows:</p> <pre><code>def function_name(\n        arg1: arg1_type, \n        arg2: arg2_type, \n        arg3: Optional[arg3_type] = None,\n        **kwargs: Any\n        ) -&gt; return_type:\n    \"\"\"Short description of the function (in the imperative mood).\n\n    Optional longer description of the function.\n\n    Parameters\n    ----------\n    arg1 : arg1_type\n        Description of arg1. No need to state default values.\n    arg2 : arg2_type\n        Description of arg2.\n    arg3 : arg3_type, optional\n        Description of arg3. Defaults to None.\n    kwargs : Any\n        Description of additional keyword arguments.\n\n\n    Returns\n    -------\n    return_type\n        Description of the return value.\n\n    Raises\n    ------\n    Exception\n        Description of the exception.\n\n    Examples\n    --------\n    &gt;&gt;&gt; function_name(1, 2)\n    3       \n    \"\"\"\n    pass\n</code></pre> <p>If the function is a method of a <code>comfit</code> model, it should be documented as follows:</p> <pre><code>from typing import TYPE_CHECKING # Import necessary typing packages\n\nif TYPE_CHECKING:\n    from comfit.core.base_system import BaseSystem\n\n# General packages\n# Import necessary packages from the standard library, e.g.\n# import numpy as np\n\n# Comfit packages\n# Import necessary packages from comfit from the subpackages, e.g. \n# from comfit.core import BaseSystem\n\ndef function_name(\n        self: 'BaseSystem',\n        arg1: arg1_type, \n        arg2: arg2_type, \n        arg3: Optional[arg3_type] = None\n        ) -&gt; return_type:\n    \"\"\"Short description of the function (in the imperative mood).\n\n    Optional longer description of the function.\n\n    Parameters\n    ----------\n    arg1 : arg1_type\n        Description of arg1. No need to state default values.\n    arg2 : arg2_type\n        Description of arg2.\n    arg3 : arg3_type, optional\n        Description of arg3. Defaults to None.\n    kwargs : Any (use backslash to escape the asterisk)\n        Description of additional keyword arguments.\n\n    Returns\n    -------\n    return_type\n        Description of the return value.\n\n    Raises\n    ------\n    Exception\n        Description of the exception.\n\n    Examples\n    --------\n    &gt;&gt;&gt; function_name(1, 2)\n    3       \n    \"\"\"\n    pass\n</code></pre> <ul> <li>markdownlint for markdown documents.</li> </ul>"},{"location":"Plotting/","title":"Plotting","text":"<p>See the ComFiT Library Reference below for a complete list of class methods and their usage.</p>  ComFiT Library Reference  <p>The <code>ComFiT</code> package supports both the <code>plotly</code> (default) and <code>matplotlib</code>  plotting libraries.  You can easily switch between the two by setting the <code>plot_lib</code> attribute of the  <code>BaseSystem</code> class to either <code>plotly</code> or <code>matplotlib</code>, <code>plot_lib</code> can also be  passed as an argument to the plotting functions.</p> <p>Every plotting function returns a tuple containing a <code>fig</code> and an <code>ax</code> object.</p> <code>matplotlib</code><code>plotly</code> <p>The <code>fig</code> object is the figure object of the plot, while the <code>ax</code> object represents the individual axes of the plot.</p> <p>The <code>fig</code> object is the figure for the plot, and the <code>ax</code> object is a dictionary containing properties necessary for correct placement of subplots.  Default is <code>ax = {'row': 1, 'col': 1, 'nrows': 1, 'ncols': 1}</code>.</p> <p>To show the plot, use the <code>show</code> function, which takes the <code>fig</code> object as an argument</p> <pre><code>cfi.show(fig)\n</code></pre>"},{"location":"Plotting/#plotting-keywords","title":"Plotting keywords","text":"<p>The following list gives the keyword arguments that determine the layout of the resulting plot. These keywords can be passed to any plot function. <code>bs</code> refers to an instance of the <code>BaseSystem</code> class. In some cases, default values of other parameter depend on the value of <code>dim</code>, and are represented by curly brackets:</p> \\[ \\left \\lbrace \\begin{array}{l} \\textrm{default value if } \\texttt{dim }= 1 \\\\ \\textrm{default value if } \\texttt{dim }= 2  \\\\ \\textrm{default value if } \\texttt{dim }= 3  \\\\ \\end{array} \\right \\rbrace \\] Keyword Definition Default value <code>xlabel</code> The label on the x-axis \\(x/a_0\\) <code>ylabel</code> The label on the y-axis \\(\\left \\lbrace \\begin{array}{c} \\texttt{none} \\\\ y/a_0 \\\\  y/a_0 \\\\ \\end{array} \\right \\rbrace\\) <code>zlabel</code> The label on the z-axis \\(\\left \\lbrace \\begin{array}{c} \\texttt{none} \\\\ \\texttt{none} \\\\  z/a_0 \\\\ \\end{array} \\right \\rbrace\\) <code>suptitle</code> The figure title None <code>title</code> The axes title None <code>xmin</code> The lower limit on the x-axis <code>bs.xmin</code> <code>xmax</code> The upper limit on the x-axis <code>bs.xmax - bs.dx</code> <code>xlim</code> A list or tuple consisting of the lower and upper limit on the x-axis. If <code>xlim</code> is provided, it trumps any provided <code>xmin</code> or <code>xmax</code>. None <code>ymin</code> The lower limit on the y-axis \\(\\left \\lbrace \\begin{array}{c} \\texttt{none} \\\\ \\texttt{bs.ymin} \\\\  \\texttt{bs.ymin} \\\\ \\end{array} \\right \\rbrace\\) <code>ymax</code> The upper limit on the y-axis \\(\\left \\lbrace \\begin{array}{c} \\texttt{none} \\\\ \\texttt{bs.ymax-bs.dy} \\\\  \\texttt{bs.ymax-bs.dy} \\\\ \\end{array} \\right \\rbrace\\) <code>ylim</code> A list or tuple consisting of the lower and upper limit on the y-axis. If <code>ylim</code> is provided, it trumps any provided <code>ymin</code> or <code>ymax</code>. None <code>zmin</code> The lower limit on the z-axis \\(\\left \\lbrace \\begin{array}{c} \\texttt{none} \\\\ \\texttt{none} \\\\  \\texttt{bs.zmin} \\\\ \\end{array} \\right \\rbrace\\) <code>zmax</code> The upper limit on the z-axis \\(\\left \\lbrace \\begin{array}{c} \\texttt{none} \\\\ \\texttt{none} \\\\  \\texttt{bs.zmax-bs.dz} \\\\ \\end{array} \\right \\rbrace\\) <code>zlim</code> List or tuple consisting of the lower and upper limit on the z-axis. If <code>zlim</code> is provided, it trumps any provided <code>zmin</code> or <code>zmax</code>. None <code>vmin</code> Lower limit on the field to be plotted. In the case of a complex function, this is the lower limit of the absolute value of the field to be plotted. None <code>vmax</code> Upper limit on the value of field to be plotted. In the case of a complex function, this is the upper limit of the absolute value of the field to be plotted. None <code>vlim</code> List or tuple consisting of the lower and upper limit of the value to be plotted. Only relevant for <code>plot_field</code>. None <code>vlim_symmetric</code> A Boolean parameter specifying whether the value limits should be symmetric. Only relevant for <code>plot_field</code>. <code>False</code> <code>colorbar</code> Boolean parameter indicating whether or not to plot the colorbar <code>True</code> (if applicable) <code>colormap</code> String specifying the colormap to be used Varies <code>grid</code> Boolean parameter indicating whether or not to plot the axes grid <code>False</code> <code>hold</code> Boolean parameter indicating whether or not to hold the current plot <code>False</code> <code>opacity</code> The opacity of the plot (only sometimes relevant) 1 <code>plot_shadows</code> Boolean parameter indicating whether or not to plot the shadows of the objects. Only applicable for <code>plot_complex_field</code>. <code>True</code> <code>fig</code> <code>plotly</code> or <code>matplotlib</code> figure handle None <code>ax</code> <code>matplotlib</code> axis handle or dictionary with subplot properties None <code>xticks</code> List of ticks on the x-axis None <code>xticklabels</code> List of labels for the ticks on the x-axis None <code>yticks</code> List of ticks on the y-axis None <code>yticklabels</code> List of labels for the ticks on the y-axis None <code>zticks</code> List of ticks on the z-axis None <code>zticklabels</code> List of labels for the ticks on the z-axis None <code>cticks</code> List of ticks on the colorbar None <code>cticklabels</code> List of labels for the ticks on the colorbar None <code>alpha</code> The alpha value of the plot 0.5 <code>spacing</code> The spacing between the arrows in a vector field plot Varies <code>x</code> A custom 1D x-coordinate array with the same shape as <code>bs.x</code>. <code>bs.x</code> <code>y</code> A custom 1D y-coordinate array with the same shape as <code>bs.y</code>. <code>bs.y</code> <code>z</code> A custom 1D z-coordinate array with the same shape as <code>bs.z</code>. <code>bs.z</code> <code>X</code> A custom nD x-coordinate array. None <code>Y</code> A custom nD y-coordinate array. None <code>Z</code> A custom nD z-coordinate array. None <code>fourier</code> Boolean parameter indicating whether or not the field to plot is in Fourier space <code>False</code>"},{"location":"Plotting/#subplots","title":"Subplots","text":"<p>To plot multiple graphs in the same figure, use the <code>plot_subplots</code> function before any plotting functions. This function accepts the following arguments:</p> <ul> <li><code>nrows</code> (int): The number of rows in the subplot grid.</li> <li><code>ncols</code> (int): The number of columns in the subplot grid.</li> <li><code>figsize</code> (tuple): The size of the figure.</li> </ul> <p>The function returns a tuple <code>(fig, axs)</code>, where <code>fig</code> is the figure object and <code>axs</code> is a list of axis objects. Following <code>matplotlib</code> conventions, if the subplot grid is one-dimensional, <code>axs</code> is a one-dimensional list of axis objects; otherwise, <code>axs</code> is a two-dimensional list of lists (so <code>axs[i][j]</code> is the axis object at the ith row and jth column).</p> <code>matplotlib</code><code>plotly</code> <p>The <code>axs</code> object is a list (or array) of axis objects.</p> <p>The <code>axs</code> object is a list of <code>(row, col)</code> tuples; thus, <code>axs[i][j]</code> corresponds to the <code>(row, col)</code> position of the axis object in the ith row and jth column.</p> <p>When plotting, pass the <code>fig</code> and <code>ax</code> objects to the plotting functions, e.g.</p> <pre><code>import comfit as cf\nimport numpy as np\n\ncfi = cf.BoseEinsteinCondensate(2)\ncfi.psi = cfi.x + 1j * cfi.y\ncfi.plot_lib = 'matplotlib'\n\nfig, axs = cfi.plot_subplots(2, 2, figsize=(10, 10))\n\ncfi.plot_complex_field(cfi.psi, fig=fig, ax=axs[0][0])\ncfi.plot_field(abs(cfi.psi), fig=fig, ax=axs[0][1])\ncfi.plot_angle_field(np.angle(cfi.psi), fig=fig, ax=axs[1][0])\ncfi.show(fig)\n</code></pre>"},{"location":"Plotting/#matplotlib-convention","title":"Matplotlib convention","text":"<p>The convention followed in <code>ComFiT</code> are as follows:</p> <ul> <li>When a plotting function is called without a keyword argument specifying the current figure or axes, then the current figure will be cleared and potential axes (in the case of matplotlib) will be created onto it. This is because with no reference to which axes the plot is meant to go ontop, there is no way of knowing.</li> <li>If a figure is provided by the keyword <code>fig=myfig</code> with, then it will be cleared and the new plot will be plotted on <code>myfig</code>. This is because with no reference to which axes the plot is meant to go ontop, there is no way of knowing.</li> <li>If an axes object is provided by the keyword <code>ax</code>, then the <code>ax</code> instance will be cleared and the new plot will be plotted on <code>ax</code>, unless the keyword <code>hold=True</code> is provided, in which case the new plot will be plotted ontop of the old plot.</li> </ul> <p>To show the current plot, one writes</p> <pre><code>plt.show()\n</code></pre> <p>which will pause the simulation until the plot window has been closed. In order to draw the image and continue the simulation, as for instance when viewing a simulation live, one needs to write</p> <pre><code>plt.pause(0.01)\n</code></pre>"},{"location":"Plotting/#plotly-3d-properties","title":"Plotly 3D properties","text":""},{"location":"Plotting/#plotly-3d-properties_1","title":"Plotly 3D properties","text":"<p>Plotly handles manipulating figures differently in 2D and 3D dimensions. In the <code>tool_set_plot_axis_properties_plotly</code> function, several helper dictionaries are constructed to set the proper plotting properties.</p>"},{"location":"Plotting/#properties-of-the-ax-object","title":"Properties of the <code>ax</code> object","text":"<p>The <code>ax</code> object contains the following properties:</p> <pre><code>row, nrows   # Row position and total number of rows\ncol, ncols   # Column position and total number of columns\nxaxis = 'xaxis1'  # Axis identifier\nyaxis = 'yaxis1'  # Axis identifier  \nplot_dimension   # Dimension of the plot\n</code></pre>"},{"location":"Plotting/#2d-updates","title":"2D updates","text":"<p>For 2D plots, updates are saved in the <code>layout_updates</code> dictionary:</p> <pre><code>layout_updates = {\n    'xaxis_range': [0, 10],  # Same format for y-axis\n    'xaxis_title': 'x/a0'    # Title for x-axis\n}\n</code></pre>"},{"location":"Plotting/#3d-updates","title":"3D updates","text":"<p>For 3D plots, updates are organized in separate dictionaries for each axis:</p> <pre><code>xaxis_updates = {\n    'range': [0, 10],\n    'title': 'x/a0',\n    'tickvals': [0, 1, 2, ...],\n    'ticktext': ['0', 'pi', ...]\n}\n</code></pre> <p>Similar dictionaries exist for <code>yaxis_updates</code> and <code>zaxis_updates</code>.</p> <p>These are combined in the <code>scene_updates</code> dictionary:</p> <pre><code>scene_updates = {\n    'xaxis': xaxis_updates,\n    'yaxis': yaxis_updates,\n    'zaxis': zaxis_updates\n}\n</code></pre>"},{"location":"Plotting/#understanding-kwargs-vs-ax-dictionary","title":"Understanding <code>kwargs</code> vs <code>ax</code> dictionary","text":"<p>In all plot functions, there's an important distinction between the <code>kwargs</code> and <code>ax</code> dictionaries:</p> <ul> <li><code>kwargs</code>: Contains settings specific to the current plot</li> <li><code>ax</code>: Contains settings that apply to all plots in a given subplot</li> </ul>"},{"location":"Plotting/#colormaps","title":"Colormaps","text":"<p>There is a large overlap of colormaps between <code>matplotlib</code> and <code>plotly</code>, but there are some differences. Here is an overview over some of the available colormaps in <code>ComFiT</code>.</p> <p></p> <p>All the colormaps can be reversed by adding the <code>_r</code> suffix, e.g., <code>viridis_r</code>. The colormaps <code>sunburst</code>, <code>bluewhitered</code> and <code>angle</code> have been custom made for ComFiT. The colormap <code>winter</code> is not native in <code>plotly</code> but has been ported.</p> <p><code>colormap</code>: Strings describing the colormap.</p> <p><code>colorbar</code>: Boolean parameter indicating whether or not to plot the colorbar.</p> <p><code>colormap_object</code>: The colormap object, which is called in plot commands.</p>"},{"location":"Plotting/#plotting-functions","title":"Plotting functions","text":"<p>The <code>BaseSystem</code> class comes pre-packaged with a number of plotting functions to plot four different types of fields.</p>"},{"location":"Plotting/#real-fields","title":"Real fields","text":"<p>Real fields are fields that take real values, for example the temperature in a room.</p>"},{"location":"Plotting/#plot_field","title":"<code>plot_field</code>","text":"<p>The <code>plot_field</code> function is used to plot a real field.</p> Example <pre><code>import comfit as cf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure()\n\nax1 = fig.add_subplot(131)\nbs = cf.BaseSystem(1,xRes=31)\nfield = bs.x**2\nbs.plot_field(field,ax=ax1)\n\nax2 = fig.add_subplot(132)\nbs = cf.BaseSystem(2,xRes=31,yRes=31)\nfield = bs.x**2 + bs.y**2\nbs.plot_field(field,ax=ax2)\n\nax3 = fig.add_subplot(133, projection='3d')\nbs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)\nfield = bs.x**2 + bs.y**2 + bs.z**2\nbs.plot_field(field,ax=ax3)\n\nplt.show()\n</code></pre> <p> </p>"},{"location":"Plotting/#plot_field_in_plane","title":"<code>plot_field_in_plane</code>","text":"<p>The <code>plot_field_in_plane</code> function is used to plot a real field in a plane.</p> Example <pre><code>import comfit as cf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nfig = plt.figure()\n\nax1 = fig.add_subplot(121, projection='3d')\nbs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)\nfield = (bs.x**2 + bs.y**2 + bs.z**2)\nbs.plot_field_in_plane(field, ax=ax1)\n\nax2 = fig.add_subplot(122, projection='3d')\nbs.plot_field_in_plane(field, ax=ax2, normal_vector=[1,1,0],position=[10,10,10])\n\nplt.show()\n</code></pre> <p> </p>"},{"location":"Plotting/#complex-fields","title":"Complex fields","text":"<p>Complex fields are fields that take complex values, for example the electric field in a light wave.</p>"},{"location":"Plotting/#plot_complex_field","title":"<code>plot_complex_field</code>","text":"<p>The <code>plot_complex_field</code> function is used to plot a complex field.</p> Example <pre><code>import comfit as cf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure()\n\nax1 = fig.add_subplot(231)\nbs = cf.BaseSystem(1,xRes=31)\nfield = bs.x**2*np.exp(1j*bs.x/3)\nbs.plot_complex_field(field,ax=ax1)\n\nax2 = fig.add_subplot(232)\nbs = cf.BaseSystem(2,xRes=31,yRes=31)\nfield = (bs.x**2 + bs.y**2)*np.exp(1j*bs.x/3)\nbs.plot_complex_field(field,ax=ax2,plot_method='phase_angle')\n\nax3 = fig.add_subplot(233, projection='3d')\nbs = cf.BaseSystem(2,xRes=31,yRes=31)\nfield = (bs.x**2 + bs.y**2)*np.exp(1j*bs.x/3)\nbs.plot_complex_field(field,ax=ax3,plot_method='3Dsurface')\n\nax5 = fig.add_subplot(235, projection='3d')\nbs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)\nfield = (bs.x**2 + bs.y**2 + bs.z**2)*np.exp(1j*bs.x/3)\nbs.plot_complex_field(field,ax=ax5,plot_method='phase_angle')\n\nax6 = fig.add_subplot(236, projection='3d')\nbs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)\nfield = (bs.x**2 + bs.y**2 + bs.z**2)*np.exp(1j*bs.x/3)\nbs.plot_complex_field(field,ax=ax6,plot_method='phase_blob')\n\nplt.show()\n</code></pre> <p> </p>"},{"location":"Plotting/#plot_complex_field_in_plane","title":"<code>plot_complex_field_in_plane</code>","text":"<p>The <code>plot_complex_field_in_plane</code> function is used to plot a complex field in a plane. The modulus of the complex field is shown as the alpha channel, where the minimum modulus value is transparent and the maximum modulus value is opaque. The phase of the complex field is shown as the color of the field, where the color is determined by the angle color scheme.</p> Example <pre><code>import comfit as cf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure()\n\nax1 = fig.add_subplot(121, projection='3d')\nbs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)\ncomplex_field = (bs.x**2 + bs.y**2 + bs.z**2)*np.exp(1j*bs.y/3)\nbs.plot_complex_field_in_plane(complex_field, ax=ax1)\n\nax2 = fig.add_subplot(122, projection='3d')\nbs.plot_complex_field_in_plane(complex_field, ax=ax2, normal_vector=[0,0,1],position=[10,10,10])\n\nplt.show()\n</code></pre> <p> </p>"},{"location":"Plotting/#angle-fields","title":"Angle fields","text":"<p>Angle fields are fields that take values in the interval \\([-\\pi,\\pi]\\), for example the phase of a complex field.</p>"},{"location":"Plotting/#plot_angle_field","title":"<code>plot_angle_field</code>","text":"<p>The <code>plot_angle_field</code> function is used to plot an angle field.</p> Example <pre><code>import comfit as cf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure()\n\nax1 = fig.add_subplot(131)\nbs = cf.BaseSystem(1,xRes=31)\nangle_field = np.mod((bs.x)/5,2*np.pi)-np.pi\nbs.plot_angle_field(angle_field,ax=ax1)\n\nax2 = fig.add_subplot(132)\nbs = cf.BaseSystem(2,xRes=31,yRes=31)\nangle_field = np.mod((bs.x + 2*bs.y)/5,2*np.pi)-np.pi\nbs.plot_angle_field(angle_field,ax=ax2)\n\nax3 = fig.add_subplot(133, projection='3d')\nbs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)\nangle_field = np.mod((bs.x + 2*bs.y + 3*bs.z)/5,2*np.pi)-np.pi\nbs.plot_angle_field(angle_field,ax=ax3)\n\nplt.show()\n</code></pre> <p> </p>"},{"location":"Plotting/#plot_angle_field_in_plane","title":"<code>plot_angle_field_in_plane</code>","text":"<p>The <code>plot_angle_field_in_plane</code> function is used to plot an angle field in a plane.</p> Example <pre><code>import comfit as cf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure()\n\nax1 = fig.add_subplot(121, projection='3d')\nbs = cf.BaseSystem(3,xRes=31,yRes=31,zRes=31)\nangle_field = np.mod((bs.x + 2*bs.y + 3*bs.z)/5,2*np.pi)-np.pi\nbs.plot_angle_field_in_plane(angle_field, ax=ax1)\n\nax2 = fig.add_subplot(122, projection='3d')\nbs.plot_angle_field_in_plane(angle_field, ax=ax2, normal_vector=[0,0,1],position=[10,10,10])\n\nplt.show()\n</code></pre> <p> </p>"},{"location":"Plotting/#vector-fields","title":"Vector fields","text":""},{"location":"Plotting/#plot_vector_field","title":"<code>plot_vector_field</code>","text":"<p>The <code>plot_vector_field</code> function is used to plot a vector field \\(\\mathbf v = (v_x,v_y,v_z)\\). Vector fields are usually plotted blue. Together with the typical keyword arguments, the <code>plot_vector_field</code> function has the kewyword <code>spacing</code> which determines the spacing between the arrows in the plot.</p> <p>The behavior of this plot function is dependent on the interplay between the dimension of the system and the dimension \\(n\\) of the vector field. In cases where <code>dim</code> \\(+ n &gt; 3\\), it is not possible to plot the vector field in a quantitatively accurate (QA) way. In such cases, different scalings which results in not quantitatively accurate representations (not QA) are taken to visualize the vector field, as described in the table below, and the user is encouraged to plot the vector field components individually for quantitative analysis. The scaling used is can be seen in the code of the <code>plot_vector_field</code> function, and a custom scaling can be provided by the user by setting the <code>vx_scale</code>, <code>vy_scale</code> and <code>vz_scale</code> keyword arguments.  These factors scale the normalized vector field (\\(\\frac{\\mathbf v = \\mathbf v }{|\\mathbf v|}\\)) components in the x-, y- and z-axes, respectively, as shown for \\(n=3\\) below.</p> <pre><code># Normalizing\nU = U / max_vector\nV = V / max_vector\nW = W / max_vector\n\n# Scale factors\nvx_scale = kwargs.get('vx_scale', 2*spacing*self.size_x/max_vector)\nvy_scale = kwargs.get('vy_scale', 2*spacing*self.size_y/max_vector)\nvz_scale = kwargs.get('vz_scale', spacing)\n\n# Scaling\nU = vx_scale*U\nV = vy_scale*V\nW = vz_scale*W\n</code></pre> <p>The following table summarizes the behavior of the <code>plot_vector_field</code> function.</p> System dimension \\(n=1\\) \\(n=2\\) \\(n=3\\) <code>dim=1</code> \\(v_x\\) on y-axis (QA). \\(v_x\\) on y-axis, \\(v_y\\) on z-axis (QA). \\(v_x, v_y\\) and \\(v_z\\) along x-, y- and z-axes, respectively (not QA). <code>dim=2</code> \\(v_x\\) on the x-axis. (not QA) \\(v_x\\) and \\(v_y\\) on x- and y-axes, respectively (not QA). \\(v_x\\), \\(v_y\\) and \\(v_z\\) on the x-, y- and z-axes, respectively (not QA). <code>dim=3</code> \\(v_x\\) on the x-axis (not QA) \\(v_x\\), \\(v_y\\) on the x-, and y-xes, respectively (not QA). \\(v_x\\), \\(v_y\\) and \\(v_z\\) on the x-, y- and z-axes, respectively (not QA). Example <pre><code>import comfit as cf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure()\n\n#1D system\nbs = cf.BaseSystem(1,xRes=31)\n\n# 1D vector field\nax1 = fig.add_subplot(331)\nvector_field = np.array([bs.x*np.cos(bs.x/5)])\nbs.plot_vector_field(vector_field,ax=ax1, spacing=1)\n\n# 2D vector field\nax2 = fig.add_subplot(332, projection='3d')\nvector_field = np.array([bs.x*np.cos(bs.x/5), bs.x*np.sin(bs.x/5)])\nbs.plot_vector_field(vector_field,ax=ax2, spacing=2)\n\n# 3D vector field\nax3 = fig.add_subplot(333, projection='3d')\nvector_field = np.array([bs.x*np.cos(bs.x/5), bs.x*np.sin(bs.x/5), bs.x*np.cos(bs.x/5)])\nbs.plot_vector_field(vector_field,ax=ax3, spacing=3)\n\n#2D system\nbs = cf.BaseSystem(2,xRes=31,yRes=31)\n\n# 1D vector field\nax4 = fig.add_subplot(334)\nvector_field = np.array([bs.x*np.cos(bs.y/5)])\nbs.plot_vector_field(vector_field,ax=ax4,spacing=3)\n\n# 2D vector field\nax5 = fig.add_subplot(335)\nvector_field = np.array([bs.x*np.cos(bs.y/5), bs.y*np.sin(bs.x/5)])\nbs.plot_vector_field(vector_field,ax=ax5,spacing=5)\n\n# 3D vector field\nax6 = fig.add_subplot(336, projection='3d')\nvector_field = np.array([bs.x*np.cos(bs.y/5), bs.y*np.sin(bs.x/5), bs.x*np.cos(bs.y/5)])\nbs.plot_vector_field(vector_field,ax=ax6, spacing=3)\n\n# 3D system\nbs = cf.BaseSystem(3,xRes=11,yRes=11,zRes=11)\n\n# 1D vector field\nax7 = fig.add_subplot(337, projection='3d')\nvector_field = np.array([bs.z+bs.x*np.cos(bs.y/5)])\nbs.plot_vector_field(vector_field,ax=ax7,spacing=3)\n\n# 2D vector field\nax8 = fig.add_subplot(338, projection='3d')\nvector_field = np.array([bs.z+ bs.x*np.cos(bs.y/5), bs.z + bs.y*np.sin(bs.x/5)])\nbs.plot_vector_field(vector_field,ax=ax8,spacing=5)\n\n# 3D vector field\nax9 = fig.add_subplot(339, projection='3d')\nvector_field = np.array([bs.z+ bs.x*np.cos(bs.y/5), bs.z + bs.y*np.sin(bs.x/5), -bs.z + bs.x*np.cos(bs.y/5)])\nbs.plot_vector_field(vector_field,ax=ax9,spacing=3)\n\nplt.show()\n</code></pre> <p> </p>"},{"location":"Plotting/#plot_vector_field_in_plane","title":"<code>plot_vector_field_in_plane</code>","text":"<p>The <code>plot_vector_field_in_plane</code> function is used to plot a vector field in a plane.</p> Example <pre><code>import comfit as cf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure()\n\nax1 = fig.add_subplot(121, projection='3d')\nbs = cf.BaseSystem(3,xRes=11,yRes=11,zRes=11)\nvector_field = np.array([bs.z+bs.x*np.cos(bs.y/5), bs.z+bs.y*np.sin(bs.x/5), -bs.z+bs.x*np.cos(bs.y/5)])\nbs.plot_vector_field_in_plane(vector_field, ax=ax1)\n\nax2 = fig.add_subplot(122, projection='3d')\nbs = cf.BaseSystem(3,xRes=11,yRes=11,zRes=11)\nvector_field = np.array([bs.z+bs.x*np.cos(bs.y/5), bs.z+bs.y*np.sin(bs.x/5)])\nbs.plot_vector_field_in_plane(vector_field, ax=ax2, normal_vector=[0,1,1],position=[2,3,3])\n\nplt.show()\n</code></pre> <p> </p>"},{"location":"Plotting/#animation","title":"Animation","text":"<p>Creating animations are typically done by exporting each frame to a <code>png</code>-file and then combining the frames together. For a ComFiT instance <code>cfi</code>, the command to export a frame is given by</p> <pre><code>cfi.save_plot(n, fig)\n</code></pre> <p>where <code>n</code> is the frame number (assumed to start at <code>0</code>) and <code>fig</code> is the output of a plotting function. If <code>plot_lib</code> is set to <code>matplotlib</code>, then <code>fig</code> is a tuple of the <code>matplotlib</code> figure and axes objects and if <code>plot_lib</code> is set to <code>plotly</code>, then <code>fig</code> is a <code>plotly</code> figure object. An optional keyword argument <code>ID</code> can be given, which assigns a unique identifier to the plot, which is useful in case of running multiple simulations in parallel.</p> <p>After producing the individual figures, they can be combined into an animation using the command</p> <pre><code>cf.tool_make_animation_gif(n)\n</code></pre> <p>where <code>n</code> is the last frame number.</p> Example <p>Here is how one would create an animation of a field.</p> <pre><code># Initialize the field and the ComFiT instance cfi\n\nfor n in range(100):\n    # Update the field\n    # Plot the field and save in fig\n    cfi.save_plot(n, fig)\ncf.tool_make_animation_gif(n)\n</code></pre>"},{"location":"Plotting/#angle-color-scheme","title":"Angle color scheme","text":"<p>In many of the plotting functions, we are plotting angles, for example in plotting the phase of a complex number or the value of an order parameter on S1 . In these cases, all values modulus 2\u03c0 are eqvuivalent, but if one uses a regular color scheme, this equivalence is not readily visible. Therefore, when expressing angles, we use the color scheme shown in Fig. 1.1. This has the benefit of wrapping around itself at \u03b8 = \u00b1\u03c0, stressing that these correspond</p> <p> </p> <p>Angle color scheme. The color scheme follows the hsv color circle going through  \\(\\theta=0\\) (Red), \\(\\theta=\\pi/3\\) (Yellow), \\(\\theta=2\\pi/3\\) (Lime), \\(\\theta = \\pm \\pi\\) (Aqua), \\(\\theta = -2\\pi/3\\) (Blue), \\(\\theta = -\\pi/3\\) (Fuchsia).</p>"},{"location":"Plotting/#technicality-the-marching_cubes-function-and-interpolation","title":"Technicality: The <code>marching_cubes</code> function and interpolation","text":"<p>The marching cubes algorithm is used to create a 3D surface from a 3D field and is used in creating many of the plots in three dimensions. If you are going to make changes to the codebase, then it is useful to have an idea of how it works and what the resulting quantities are.</p> <p>Typically, we have our 3D system with a total resolution of, say 300, and a field <code>field</code>, of which we want to extract the values on some specific isosurface <code>iso_value</code>. The <code>marching_cubes</code> function is called as follows</p> <pre><code>verts, faces, _, _ = marching_cubes(field,iso_value)\n</code></pre> <p><code>verts</code> is a list of the (integer) positions of the vertices of the surfaces, e.g.,</p> <pre><code>verts = \n[[x0i,y0i,z0i],\n [x1i,y1i,z1i],\n [x2i,y2i,z2i],\n [x3i,y3i,z3i],\n [x4i,y4i,z4i]]\n\nverts = \n[[ 0.  5.  1.]\n [ 0.  5.  0.]\n [ 1.  5.  1.]\n [ 1.  5.  0.]\n [ 0.  5.  2.]]\n</code></pre> <p>if the surface has five vertices. <code>faces</code> is a list of the indices of the vertices that make up the triangles of the surface.</p> <pre><code>faces = \n[[v0i,v1i,v2i],\n [v3i,v4i,v5i],\n ... #3 hidden rows\n [v2i,v1i,v0i]]\n\nfaces =\n[[  2   1   0]\n [  2   3   1]\n [  1   3   2]\n [  0   4   2]\n [  2   3   1]\n [  0   1   2]]\n</code></pre> <p>if the surface has six faces. In other words, if <code>faces[0] = [2, 1, 0]</code>, then it represents the triangle given by the three vertices</p> <pre><code>verts[2] = [ 1.  5.  1.]\nverts[1] = [ 0.  5.  1.]\nverts[0] = [ 0.  5.  0.]\n</code></pre> <p>Now, it is useful to calculate the position of a point located on the surface, which is calculated by the line</p> <pre><code>centroids = np.mean(verts[faces], axis=1)\n</code></pre> <p>which gives the position of the centroids of the triangles that make up the surface.</p> <pre><code>centroids = \n[[x0c,y0c,z0c],\n [x1c,y1c,z1c],\n [x2c,y2c,z2c],\n [x3c,y3c,z3c],\n [x4c,y4c,z4c]\n [x5c,y5c,z5c]]\n\ncentroids =\n[[0.33333334 5.         0.6666667 ]\n [0.6666667  5.         0.33333334]\n [0.33333334 5.         1.6666666 ]\n [0.6666667  5.         1.3333334 ]\n [0.33333334 5.         2.6666667 ]\n [0.6666667  5.         2.3333333 ]]\n</code></pre> <p>As we see, the centroids array consists of as many rows as there are faces (naturally), and each row consists of the x-, y- and z-coordinates of the centroid of the corresponding face.</p> <p>In the next line, we typically create the <code>points</code> array, as follows:</p> <pre><code>x, y, z = np.mgrid[0:field.shape[0], 0:field.shape[1], 0:field.shape[2]]\npoints = np.c_[x.ravel(), y.ravel(), z.ravel()]\n</code></pre> <p>The <code>points</code> array is a list of the (integer) positions of all the points in the full 3D grid.</p> <pre><code>points = \n[[x0i,y0i,z0i],\n [x1i,y1i,z1i],\n [x2i,y2i,z2i],\n [x3i,y3i,z3i],\n [x4i,y4i,z4i],\n ... # 300 rows total\n [x299i,y299i,z299i]]\n\n points = \n [[ 0  0  0]\n [ 0  0  1]\n [ 0  0  2]\n ... # 300 rows total\n [10 10  8]\n [10 10  9]\n [10 10 10]]\n</code></pre> <p>Then, we create the <code>field_values</code> array by </p> <pre><code>field_values = field.ravel()\n</code></pre> <p>which is a <code>(300,)</code>-shaped array of the values of the field at the points in the <code>points</code> array, i.e., in the full grid.</p> <p>Now we get to the interpolation, which happens by the command</p> <pre><code>field_verts = sp.interpolate.griddata(points, field_values,centroids, method='nearest')\n</code></pre> <p>which uses the information in <code>points</code> and <code>field_values</code> to interpolate the field values at the centroids of the faces of the surface. It returns thus a <code>(6,)</code>-array containing the field values to be used in the plotting of the surface. The <code>nearest</code> method is used to interpolate the field values, which means that the field value at the centroid of a face is the field value of the point in the full grid that is closest to the centroid of the face.</p>"},{"location":"Templates/","title":"Templates","text":"<p>Card template:</p>  Heading 1 <p> </p> <p>     Description 1     </p> Heading 2 <p> </p> <p>     Description 2     </p>"},{"location":"TopologicalDefects/","title":"Topological defects","text":"<p>Topological defects are defects that appear due to imposed constraints by boundary conditions<sup>1</sup>. In this work, we will track topological defects as entities derivable from a coarse defect density field<sup>2</sup>. In short, for a system containing topological defects, it is possible to derive a defect density field \\(\\rho\\), which upon suitable spatial integration gives the charge of the defects contained in that region.</p>"},{"location":"TopologicalDefects/#the-algorithm-for-tracking-topological-defects","title":"The algorithm for tracking topological defects","text":"<p>The algorithm for identifying topological defects is implemented in the method <code>BaseSystem.calc_defect_nodes</code>. It requires an input of a positive real scalar field <code>defect_density</code>, which upon integration over a region gives a number proportional to the number of defects in that region.</p> <p>Note</p> <p>The <code>defect_density</code> field is not necessarily the same as the defect density field \\(\\rho\\) alluded to above. Whereas \\(\\rho\\) might be a vector- or tensor-valued field, <code>defect_density</code> is a real and positive scalar field. They are, however, related, and the exact connection depends on the model in question.  For example, in the case of a 2D Bose-Einstein condensate, the <code>defect_density</code> is given by \\(|\\rho|\\), and in three dimension, where \\(\\vec \\rho\\) is a vector field, <code>defect_density</code> is given by \\(\\vec \\rho\\). </p> <p>The algorithm takes<code>charge_tolerance</code> and <code>integration_radius</code> as inputs, and then follows these steps:</p> Step Illustration 1. Identify the <code>position_index</code> corresponding to <code>max(defect_density)</code>. 2. Calculate the integral <code>charge</code> of <code>defect_density</code> in a ball <code>region_to_integrate</code> of radius <code>integration_radius</code> around the point corresponding to <code>position_index</code>. If <code>charge&gt;charge_tolerance</code>, then the point will be added to the identified defect nodes. <code>while</code> <code>charge&gt;charge_tolerance</code> \u00a0\u00a0 3.1 Store <code>position_index</code> in the dictionary <code>defect_node</code>. \u00a0\u00a0 3.2 Calculate position \\(\\mathbf r_0\\) of <code>defect_note</code> as the expectation value of \\((x,y,z)\\) by using <code>defect_density</code> as a probability distribution function in <code>region_to_integrate</code>. \u00a0\u00a0 3.3 Add <code>defect_node</code> to the list <code>defect_nodes</code>. \u00a0\u00a0 3.4 Remove a ball of radius <code>2*integration_radius</code> around <code>position_index</code> from the region <code>region_to_search</code> in which to search for new defect nodes. \u00a0\u00a0 3.5 Identify the <code>position_index</code> corresponding to <code>max(defect_density)</code> in the region <code>region_to_search</code>. \u00a0\u00a0 3.6 Calculate the integral <code>charge</code> of <code>defect_density</code> in a ball <code>region_to_integrate</code> of radius <code>integration_radius</code> around the point corresponding to <code>position_index</code>. <p>The value of <code>charge_tolerance</code> and <code>integration_radius</code> must be set depending on the particular system and the nature of defect density. For example, in the case of a 2D phase-field crystal, the defect density will be \\(\\sqrt{\\alpha_{ij} \\alpha_{ij}}\\), which is the density of Burgers vectors. Upon integration over a defect node, it is expected to give the absolute value of the Burgers vector of the defect, which is expressed in units of \\(a_0\\), the lattice constant. Therefore, the input charge tolerance is given in units of \\(a_0\\), e.g., <code>charge_tolerance=0.2*self.a0</code>. In the case of the 2D Bose-Einstein condensate, however, the integral over the defect density will be a unitless number equal to \\(1\\) if integrated over a defect node. Thus, the input charge tolerance is a unitless number, e.g., <code>charge_tolerance=0.2</code>.</p> <p>Even though it was exemplified in two dimensions, the same algorithm is readily usable in three dimensions, but care needs to be taken to set the proper <code>charge_tolerance</code>. For example, in a 3D Bose-Einstein condensate, the charge density provided is a 2D charge density in 3D space (for details, see Ref.<sup>2</sup>). The integral over the defect density will then no longer be a unitless number, but scale with <code>integration_radius</code>, so one might set both <code>charge_tolerance=0.2*self.a0</code> and <code>integration_radius=self.a0</code> to scale with <code>a0</code>.</p>"},{"location":"TopologicalDefects/#properties-of-the-defect-nodes","title":"Properties of the defect nodes","text":"<p>Typically, <code>BaseSystem.calc_defect_nodes</code> is used to make the list of defect nodes, which is then used to calculate the node properties in the model-specific classes. For instance, <code>BoseEinsteinCondensate.calc_vortex_nodes</code> first calls <code>BaseSystem.calc_defect_nodes</code> to get the list of defect nodes, and then calculates the properties of the defect nodes, such as their charge. To calculate the velocity of defects using the method outlined in Ref.<sup>2</sup>, one must formulate the order parameter as an \\(n\\)-component vector field \\(\\vec \\psi\\) and provide both <code>psi</code> (the vector field) and <code>dt_psi</code> as an input to <code>BaseSystem.calc_defect_velocity_field</code>. This will return a vector field describing the velocity of the full defect density field, which can be evaluated at the defect nodes to get the velocity of the nodes. See an example of how this is done in <code>BoseEinsteinCondensate.calc_vortex_nodes</code>.</p> <ol> <li> <p>Mermin, N. D. (1979). The topological theory of defects in ordered media. Reviews of Modern Physics, 51(3), 591\u2013648. https://doi.org/10.1103/RevModPhys.51.591 \u21a9</p> </li> <li> <p>Skogvoll, V., R\u00f8nning, J., Salvalaglio, M., &amp; Angheluta, L. (2023). A unified field theory of topological defects and non-linear local excitations. Npj Computational Materials, 9(1), Article 1. https://doi.org/10.1038/s41524-023-01077-6 \u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"compiled_document/","title":"Compiled Markdown Document","text":""},{"location":"compiled_document/#unnamed-section","title":"Unnamed Section","text":"<p>Note that \\(N_{\\mathfrak f}\\) is a non-linear function of the field variable \\(\\psi\\), but can also be an explicit variable of time \\(t\\), i.e. \\(N_{\\mathfrak f}(\\psi,t)\\). Therefore, in the code, it has to be encoded as a function of these two variables <code>calc_nonlinear_evolution_function_f(self, psi, t)</code>.</p> <p>For numerical purposes, it is useful to calculate the small \\(\\omega_{\\mathfrak f}\\) limit. We expand the exponential in its Taylor series and keep the leading order term to get:</p> \\[ I_{\\mathfrak f 0} \\approx 1 \\] \\[ I_{\\mathfrak f 1} \\approx   \\frac{1}{\\omega_{\\mathfrak f}} (1 + \\omega_{\\mathfrak f} \\Delta t - 1) = \\Delta t \\] \\[ I_{\\mathfrak f 2} \\approx \\frac{1}{\\omega_{\\mathfrak f}^2 \\Delta t}  \\left ( 1 + \\omega_{\\mathfrak f} \\Delta t + \\frac{1}{2} ( \\omega_{\\mathfrak f} \\Delta t )^2  -1 - \\omega_{\\mathfrak f} \\Delta t \\right ) = \\frac{1}{2} \\Delta t \\] <p>In \\(I_{\\mathfrak f 1}\\), and \\(I_{\\mathfrak f 2}\\) there is a division by \\(0\\) when \\(\\omega_{\\mathfrak f} = 0\\). To avoid numerical issues related to this we use the above limits when \\(|\\omega_{\\mathfrak f}|\\) is smaller than a tolerance. We don't use the limit for \\(I_{\\mathfrak f 0}\\) since it doesn't contain a division by \\(0\\). The function <code>evolve_ETD2RK_loop</code> defined in the base system class performs an ETD2RK step. This function is called by the evolvers discussed in the model chapter if the method is defined as <code>method = \"ETD2RK\"</code>. This is the default solver if <code>method</code> is not set. The integrating factors for a given \\(\\omega_{\\mathfrak f}(\\mathbf{k})\\) can be found with the function <code>calc_evolution_integrating_factors_ETD2RK</code> where the variable <code>tol</code> gives when the factors should be replaced by their leading order Taylor expansion. Note that all solvers defined in the  class \\lstinline{BaseSystem} updates the time variable <code>self.t</code> to allow for time-dependents in the non-linear term.</p>"},{"location":"compiled_document/#the-etd4rk-scheme","title":"The ETD4RK scheme","text":"<p>Following Ref.[^coxExponentialTimeDifferencing2002], we may generalize the method to a fourth order Runge-Kutta as follows</p>"}]}